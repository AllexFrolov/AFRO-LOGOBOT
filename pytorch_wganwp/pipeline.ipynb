{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torch\n",
    "import cv2\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad as torch_grad\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations import pytorch as AT\n",
    "\n",
    "\n",
    "import utils\n",
    "from models import Generator, Discriminator\n",
    "from wgan import GoodGenerator, GoodDiscriminator, kaiming_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'LLD-icon-sharp.hdf5'\n",
    "\n",
    "hdf5_file = h5py.File(dataset_path, 'r')\n",
    "images, labels = (hdf5_file['data'], hdf5_file['labels/resnet/rc_128'])\n",
    "\n",
    "\n",
    "cleaned_dataset = np.load(\"cleaned_dataset.npy\")\n",
    "\n",
    "#params section\n",
    "batch_size = 256\n",
    "num_workers = 0\n",
    "img_size = (32, 32, 1)\n",
    "img_size_2 = (64, 64, 3)\n",
    "generator = Generator(img_size, latent_dim=128, dim=32)\n",
    "#generator = GoodGenerator(dim=32, latent_dim = 128,  output_dim=3*32*32)\n",
    "discriminator = Discriminator(img_size=img_size, dim=32)\n",
    "lr = 1e-4\n",
    "betas = (0.5, .99)\n",
    "weight_decay = 1e-04\n",
    "G_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=betas )\n",
    "D_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=betas, weight_decay = weight_decay )\n",
    "G_sheduler = optim.lr_scheduler.StepLR(G_optimizer, step_size= 40, gamma=0.8)\n",
    "D_sheduler = optim.lr_scheduler.StepLR(D_optimizer, step_size= 40, gamma=0.8)\n",
    "epochs = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('clusters.pickle', 'rb') as handle:\n",
    "    clusters = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = np.vstack([clusters[\"array_70\"],clusters[\"array_58\"]])\n",
    "test_dataset = np.vstack([test_dataset,clusters[\"array_65\"]])\n",
    "test_dataset = np.vstack([test_dataset,clusters[\"array_79\"]])\n",
    "test_dataset = np.vstack([test_dataset,clusters[\"array_91\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8157, 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa593f83898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_dataset[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IconsDataset(Dataset):\n",
    "    def __init__(self, h5py_dataset, transforms = None):\n",
    "        self.dataset = h5py_dataset\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.dataset[idx].transpose(1,2,0)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=img)\n",
    "            image = sample['image']\n",
    "        \n",
    "        return image.reshape(-1, 32, 32)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = albu.Compose([ \n",
    "    #albu.Resize(32 ,32),\n",
    "    #albu.Normalize((0.5, 0.5, 0.5), (0.5,0.5,0.5)),\n",
    "    albu.Normalize((0.5), (0.5)),\n",
    "                           AT.ToTensor(),\n",
    "                          \n",
    "                          ])\n",
    "\n",
    "trainset = IconsDataset(images, transforms=transforms)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 32, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainloader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, generator, discriminator, gen_optimizer, dis_optimizer, gen_sch, dis_sch,\n",
    "                 gp_weight=10, critic_iterations=5, print_every=300,\n",
    "                 use_cuda=False):\n",
    "        self.G = generator\n",
    "        self.G_opt = gen_optimizer\n",
    "        self.D = discriminator\n",
    "        self.D_opt = dis_optimizer\n",
    "        self.G_sch = gen_sch\n",
    "        self.D_sch = dis_sch\n",
    "        self.losses = {'G': [], 'D': [], 'GP': [], 'gradient_norm': []}\n",
    "        self.num_steps = 0\n",
    "        self.use_cuda = use_cuda\n",
    "        self.gp_weight = gp_weight\n",
    "        self.critic_iterations = critic_iterations\n",
    "        self.print_every = print_every\n",
    "\n",
    "        if self.use_cuda:\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "\n",
    "    def _critic_train_iteration(self, data):\n",
    "        \"\"\" \"\"\"\n",
    "        # Get generated data\n",
    "        batch_size = data.size()[0]\n",
    "        generated_data = self.sample_generator(batch_size)\n",
    "\n",
    "        # Calculate probabilities on real and generated data\n",
    "        data = Variable(data)\n",
    "        if self.use_cuda:\n",
    "            data = data.cuda()\n",
    "        d_real = self.D(data)\n",
    "        d_generated = self.D(generated_data)\n",
    "\n",
    "        # Get gradient penalty\n",
    "        gradient_penalty = self._gradient_penalty(data, generated_data)\n",
    "        self.losses['GP'].append(gradient_penalty.data)\n",
    "\n",
    "        # Create total loss and optimize\n",
    "        self.D_opt.zero_grad()\n",
    "        d_loss = d_generated.mean() - d_real.mean() + gradient_penalty\n",
    "        d_loss.backward()\n",
    "\n",
    "        self.D_opt.step()\n",
    "\n",
    "        # Record loss\n",
    "        self.losses['D'].append(d_loss.data)\n",
    "\n",
    "    def _generator_train_iteration(self, data):\n",
    "        \"\"\" \"\"\"\n",
    "        self.G_opt.zero_grad()\n",
    "\n",
    "        # Get generated data\n",
    "        batch_size = data.size()[0]\n",
    "        generated_data = self.sample_generator(batch_size)\n",
    "\n",
    "        # Calculate loss and optimize\n",
    "        d_generated = self.D(generated_data)\n",
    "        g_loss = - d_generated.mean()\n",
    "        g_loss.backward()\n",
    "        self.G_opt.step()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Record loss\n",
    "        self.losses['G'].append(g_loss.data)\n",
    "\n",
    "    def _gradient_penalty(self, real_data, generated_data):\n",
    "        batch_size = real_data.size()[0]\n",
    "\n",
    "        # Calculate interpolation\n",
    "        alpha = torch.rand(batch_size, 1, 1, 1)\n",
    "        alpha = alpha.expand_as(real_data)\n",
    "        if self.use_cuda:\n",
    "            alpha = alpha.cuda()\n",
    "        interpolated = alpha * real_data.data + (1 - alpha) * generated_data.data\n",
    "        interpolated = Variable(interpolated, requires_grad=True)\n",
    "        if self.use_cuda:\n",
    "            interpolated = interpolated.cuda()\n",
    "\n",
    "        # Calculate probability of interpolated examples\n",
    "        prob_interpolated = self.D(interpolated)\n",
    "\n",
    "        # Calculate gradients of probabilities with respect to examples\n",
    "        gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                               grad_outputs=torch.ones(prob_interpolated.size()).cuda() if self.use_cuda else torch.ones(\n",
    "                               prob_interpolated.size()),\n",
    "                               create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "        # so flatten to easily take norm per example in batch\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        self.losses['gradient_norm'].append(gradients.norm(2, dim=1).mean().data)\n",
    "\n",
    "        # Derivatives of the gradient close to 0 can cause problems because of\n",
    "        # the square root, so manually calculate norm and add epsilon\n",
    "        gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "\n",
    "        # Return gradient penalty\n",
    "        return self.gp_weight * ((gradients_norm - 1) ** 2).mean()\n",
    "\n",
    "    def _train_epoch(self, data_loader):\n",
    "        for i, data in enumerate(data_loader):\n",
    "            self.num_steps += 1\n",
    "            self._critic_train_iteration(data)\n",
    "            # Only update generator every |critic_iterations| iterations\n",
    "            if self.num_steps % self.critic_iterations == 0:\n",
    "                self._generator_train_iteration(data)\n",
    "                \n",
    "            \n",
    "                \n",
    "            \n",
    "\n",
    "            if i % self.print_every == 0:\n",
    "                print(\"Iteration {}\".format(i + 1))\n",
    "                print(\"D: {}\".format(self.losses['D'][-1]))\n",
    "                print(\"GP: {}\".format(self.losses['GP'][-1]))\n",
    "                print(\"Gradient norm: {}\".format(self.losses['gradient_norm'][-1]))\n",
    "                if self.num_steps > self.critic_iterations:\n",
    "                    print(\"G: {}\".format(self.losses['G'][-1]))\n",
    "\n",
    "    def train(self, data_loader, epochs, save_training_gif=True):\n",
    "        if save_training_gif:\n",
    "            # Fix latents to see how image generation improves during training\n",
    "            fixed_latents = Variable(self.G.sample_latent(64))\n",
    "            if self.use_cuda:\n",
    "                fixed_latents = fixed_latents.cuda()\n",
    "            training_progress_images = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\nEpoch {}\".format(epoch + 1))\n",
    "            self._train_epoch(data_loader)\n",
    "            self.G_sch.step()\n",
    "            self.D_sch.step()\n",
    "\n",
    "            if save_training_gif:\n",
    "                # Generate batch of images and convert to grid\n",
    "                img_grid = make_grid(self.G(fixed_latents).cpu().data)\n",
    "                # Convert to numpy and transpose axes to fit imageio convention\n",
    "                # i.e. (width, height, channels)\n",
    "                img_grid = np.transpose(img_grid.numpy(), (1, 2, 0))\n",
    "                # Add image grid to training progress\n",
    "                training_progress_images.append(img_grid)\n",
    "            if epoch == int(epochs/2):\n",
    "                name = 'logo_model'\n",
    "                torch.save(self.G.state_dict(), './gen_' + name + '.pt')\n",
    "                torch.save(self.D.state_dict(), './dis_' + name + '.pt')\n",
    "                \n",
    "                \n",
    "\n",
    "        if save_training_gif:\n",
    "            imageio.mimsave('./training_{}_epochs.gif'.format(epochs),\n",
    "                            training_progress_images)\n",
    "\n",
    "    def sample_generator(self, num_samples):\n",
    "        latent_samples = Variable(self.G.sample_latent(num_samples))\n",
    "        if self.use_cuda:\n",
    "            latent_samples = latent_samples.cuda()\n",
    "        generated_data = self.G(latent_samples)\n",
    "        return generated_data\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        generated_data = self.sample_generator(num_samples)\n",
    "        # Remove color channel\n",
    "        return generated_data.data.cpu().numpy()[:, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Iteration 1\n",
      "D: 9.520402908325195\n",
      "GP: 9.521985054016113\n",
      "Gradient norm: 0.024193990975618362\n",
      "Iteration 301\n",
      "D: 0.6268367171287537\n",
      "GP: 1.5061066150665283\n",
      "Gradient norm: 0.7462074756622314\n",
      "G: -0.05482346564531326\n",
      "Iteration 601\n",
      "D: -0.16717314720153809\n",
      "GP: 0.7371512651443481\n",
      "Gradient norm: 0.8396009206771851\n",
      "G: -0.06128846853971481\n",
      "\n",
      "Epoch 2\n",
      "Iteration 1\n",
      "D: -0.5464252233505249\n",
      "GP: 0.4133366048336029\n",
      "Gradient norm: 0.941683828830719\n",
      "G: -0.013287665322422981\n",
      "Iteration 301\n",
      "D: -0.8214536905288696\n",
      "GP: 0.13444332778453827\n",
      "Gradient norm: 0.9992259740829468\n",
      "G: -0.02859351597726345\n",
      "Iteration 601\n",
      "D: -0.883704423904419\n",
      "GP: 0.07338617742061615\n",
      "Gradient norm: 1.0308853387832642\n",
      "G: -0.017944445833563805\n",
      "\n",
      "Epoch 3\n",
      "Iteration 1\n",
      "D: -0.8754560947418213\n",
      "GP: 0.0719267874956131\n",
      "Gradient norm: 1.0476698875427246\n",
      "G: -0.013402239419519901\n",
      "Iteration 301\n",
      "D: -0.9137744307518005\n",
      "GP: 0.049461908638477325\n",
      "Gradient norm: 1.0262281894683838\n",
      "G: -0.005049615167081356\n",
      "Iteration 601\n",
      "D: -0.8859264254570007\n",
      "GP: 0.06581383943557739\n",
      "Gradient norm: 1.0474894046783447\n",
      "G: -0.02650155872106552\n",
      "\n",
      "Epoch 4\n",
      "Iteration 1\n",
      "D: -0.5546128749847412\n",
      "GP: 0.23756471276283264\n",
      "Gradient norm: 0.8932352662086487\n",
      "G: -0.0688125267624855\n",
      "Iteration 301\n",
      "D: -0.8885865211486816\n",
      "GP: 0.04603884369134903\n",
      "Gradient norm: 0.9994481801986694\n",
      "G: -0.006017148960381746\n",
      "Iteration 601\n",
      "D: -0.8673622608184814\n",
      "GP: 0.07598749548196793\n",
      "Gradient norm: 0.9550296664237976\n",
      "G: -0.011574991047382355\n",
      "\n",
      "Epoch 5\n",
      "Iteration 1\n",
      "D: -0.6409462690353394\n",
      "GP: 0.07034499943256378\n",
      "Gradient norm: 1.0199825763702393\n",
      "G: -0.10435035824775696\n",
      "Iteration 301\n",
      "D: -0.7472181916236877\n",
      "GP: 0.16327422857284546\n",
      "Gradient norm: 0.8990397453308105\n",
      "G: -0.02258267253637314\n",
      "Iteration 601\n",
      "D: -0.7354394197463989\n",
      "GP: 0.08545765280723572\n",
      "Gradient norm: 0.9572635889053345\n",
      "G: -0.06679287552833557\n",
      "\n",
      "Epoch 6\n",
      "Iteration 1\n",
      "D: -0.6070343255996704\n",
      "GP: 0.14652082324028015\n",
      "Gradient norm: 0.9293232560157776\n",
      "G: -0.09522946178913116\n",
      "Iteration 301\n",
      "D: -0.7367890477180481\n",
      "GP: 0.062212057411670685\n",
      "Gradient norm: 0.982823371887207\n",
      "G: -0.09876365214586258\n",
      "Iteration 601\n",
      "D: -0.6912891864776611\n",
      "GP: 0.09947940707206726\n",
      "Gradient norm: 0.9430602788925171\n",
      "G: -0.0984211266040802\n",
      "\n",
      "Epoch 7\n",
      "Iteration 1\n",
      "D: -0.7177953720092773\n",
      "GP: 0.1027534157037735\n",
      "Gradient norm: 0.9546223878860474\n",
      "G: -0.08738628774881363\n",
      "Iteration 301\n",
      "D: -0.7453128099441528\n",
      "GP: 0.06260281801223755\n",
      "Gradient norm: 0.9847859144210815\n",
      "G: -0.08437609672546387\n",
      "Iteration 601\n",
      "D: -0.6235412955284119\n",
      "GP: 0.11474712193012238\n",
      "Gradient norm: 1.0117846727371216\n",
      "G: -0.12955568730831146\n",
      "\n",
      "Epoch 8\n",
      "Iteration 1\n",
      "D: -0.7748593688011169\n",
      "GP: 0.06866881996393204\n",
      "Gradient norm: 0.9727540016174316\n",
      "G: -0.09445501863956451\n",
      "Iteration 301\n",
      "D: -0.7745617628097534\n",
      "GP: 0.07048127055168152\n",
      "Gradient norm: 0.9787459373474121\n",
      "G: -0.09515380859375\n",
      "Iteration 601\n",
      "D: -0.6729937195777893\n",
      "GP: 0.10722847282886505\n",
      "Gradient norm: 0.959424614906311\n",
      "G: -0.15327070653438568\n",
      "\n",
      "Epoch 9\n",
      "Iteration 1\n",
      "D: -0.7985798120498657\n",
      "GP: 0.07343147695064545\n",
      "Gradient norm: 0.972907304763794\n",
      "G: -0.10582108795642853\n",
      "Iteration 301\n",
      "D: -0.7703740000724792\n",
      "GP: 0.05907782167196274\n",
      "Gradient norm: 0.988562822341919\n",
      "G: -0.045746225863695145\n",
      "Iteration 601\n",
      "D: -0.651197075843811\n",
      "GP: 0.09068313241004944\n",
      "Gradient norm: 0.9647637605667114\n",
      "G: -0.07824742794036865\n",
      "\n",
      "Epoch 10\n",
      "Iteration 1\n",
      "D: -0.7396778464317322\n",
      "GP: 0.0827229842543602\n",
      "Gradient norm: 1.0582276582717896\n",
      "G: -0.12792055308818817\n",
      "Iteration 301\n",
      "D: -0.7624714970588684\n",
      "GP: 0.06710244715213776\n",
      "Gradient norm: 0.9777016043663025\n",
      "G: -0.09346427023410797\n",
      "Iteration 601\n",
      "D: -0.6667091846466064\n",
      "GP: 0.08759164065122604\n",
      "Gradient norm: 0.9640084505081177\n",
      "G: -0.120903879404068\n",
      "\n",
      "Epoch 11\n",
      "Iteration 1\n",
      "D: -0.7416567802429199\n",
      "GP: 0.07746027410030365\n",
      "Gradient norm: 1.0409774780273438\n",
      "G: -0.0952911227941513\n",
      "Iteration 301\n",
      "D: -0.6570701003074646\n",
      "GP: 0.06830303370952606\n",
      "Gradient norm: 1.0044012069702148\n",
      "G: -0.1230190321803093\n",
      "Iteration 601\n",
      "D: -0.7642806172370911\n",
      "GP: 0.056327302008867264\n",
      "Gradient norm: 1.0174450874328613\n",
      "G: -0.10268187522888184\n",
      "\n",
      "Epoch 12\n",
      "Iteration 1\n",
      "D: 0.3542402982711792\n",
      "GP: 1.1030731201171875\n",
      "Gradient norm: 0.6916234493255615\n",
      "G: -0.3096524178981781\n",
      "Iteration 301\n",
      "D: -0.6944737434387207\n",
      "GP: 0.11249686777591705\n",
      "Gradient norm: 1.0752263069152832\n",
      "G: -0.15093371272087097\n",
      "Iteration 601\n",
      "D: -0.7245209813117981\n",
      "GP: 0.0942441076040268\n",
      "Gradient norm: 1.0678908824920654\n",
      "G: -0.054603807628154755\n",
      "\n",
      "Epoch 13\n",
      "Iteration 1\n",
      "D: -0.597974419593811\n",
      "GP: 0.16051790118217468\n",
      "Gradient norm: 0.9002755880355835\n",
      "G: -0.16119936108589172\n",
      "Iteration 301\n",
      "D: -0.22079595923423767\n",
      "GP: 0.29856768250465393\n",
      "Gradient norm: 0.8475671410560608\n",
      "G: -0.1072504073381424\n",
      "Iteration 601\n",
      "D: -0.7477516531944275\n",
      "GP: 0.06406984478235245\n",
      "Gradient norm: 1.0249736309051514\n",
      "G: -0.09809846431016922\n",
      "\n",
      "Epoch 14\n",
      "Iteration 1\n",
      "D: -0.6285966038703918\n",
      "GP: 0.059957265853881836\n",
      "Gradient norm: 0.9865735769271851\n",
      "G: -0.2625054121017456\n",
      "Iteration 301\n",
      "D: -0.7646769285202026\n",
      "GP: 0.062295105308294296\n",
      "Gradient norm: 0.9866259098052979\n",
      "G: -0.12549443542957306\n",
      "Iteration 601\n",
      "D: -0.7163592576980591\n",
      "GP: 0.06274333596229553\n",
      "Gradient norm: 0.9946967959403992\n",
      "G: -0.13786935806274414\n",
      "\n",
      "Epoch 15\n",
      "Iteration 1\n",
      "D: -0.5561635494232178\n",
      "GP: 0.16497722268104553\n",
      "Gradient norm: 1.1050567626953125\n",
      "G: -0.2458229660987854\n",
      "Iteration 301\n",
      "D: -0.7211845517158508\n",
      "GP: 0.061135027557611465\n",
      "Gradient norm: 1.0191171169281006\n",
      "G: -0.09902995824813843\n",
      "Iteration 601\n",
      "D: -0.7060059309005737\n",
      "GP: 0.06315705180168152\n",
      "Gradient norm: 1.0360987186431885\n",
      "G: -0.13040174543857574\n",
      "\n",
      "Epoch 16\n",
      "Iteration 1\n",
      "D: -0.6684491038322449\n",
      "GP: 0.14289726316928864\n",
      "Gradient norm: 0.9117839336395264\n",
      "G: -0.06428776681423187\n",
      "Iteration 301\n",
      "D: -0.6471823453903198\n",
      "GP: 0.09704676270484924\n",
      "Gradient norm: 1.066786766052246\n",
      "G: -0.1673227846622467\n",
      "Iteration 601\n",
      "D: -0.6267197728157043\n",
      "GP: 0.07079591602087021\n",
      "Gradient norm: 1.0497117042541504\n",
      "G: -0.23346096277236938\n",
      "\n",
      "Epoch 17\n",
      "Iteration 1\n",
      "D: -0.6988548040390015\n",
      "GP: 0.12616583704948425\n",
      "Gradient norm: 0.9130927324295044\n",
      "G: -0.11654119193553925\n",
      "Iteration 301\n",
      "D: -0.7598423361778259\n",
      "GP: 0.05883462727069855\n",
      "Gradient norm: 0.9920010566711426\n",
      "G: -0.10631756484508514\n",
      "Iteration 601\n",
      "D: -0.7986934185028076\n",
      "GP: 0.05954265967011452\n",
      "Gradient norm: 0.9828693866729736\n",
      "G: -0.11463148891925812\n",
      "\n",
      "Epoch 18\n",
      "Iteration 1\n",
      "D: -0.520237147808075\n",
      "GP: 0.2415180802345276\n",
      "Gradient norm: 0.8725754618644714\n",
      "G: -0.3282933831214905\n",
      "Iteration 301\n",
      "D: -0.7713213562965393\n",
      "GP: 0.06280450522899628\n",
      "Gradient norm: 1.030822992324829\n",
      "G: -0.10839289426803589\n",
      "Iteration 601\n",
      "D: -0.7638705372810364\n",
      "GP: 0.06121661514043808\n",
      "Gradient norm: 0.9642046093940735\n",
      "G: -0.18148556351661682\n",
      "\n",
      "Epoch 19\n",
      "Iteration 1\n",
      "D: -0.7908599376678467\n",
      "GP: 0.06111478433012962\n",
      "Gradient norm: 0.9914528727531433\n",
      "G: -0.07004165649414062\n",
      "Iteration 301\n",
      "D: -0.6707863807678223\n",
      "GP: 0.06937374174594879\n",
      "Gradient norm: 1.0470571517944336\n",
      "G: -0.08469658344984055\n",
      "Iteration 601\n",
      "D: -0.7522062659263611\n",
      "GP: 0.05021080747246742\n",
      "Gradient norm: 0.9703394174575806\n",
      "G: -0.056436337530612946\n",
      "\n",
      "Epoch 20\n",
      "Iteration 1\n",
      "D: -0.7172034978866577\n",
      "GP: 0.06174396723508835\n",
      "Gradient norm: 0.9939239025115967\n",
      "G: -0.19968214631080627\n",
      "Iteration 301\n",
      "D: -0.7595998644828796\n",
      "GP: 0.09189446270465851\n",
      "Gradient norm: 1.0687527656555176\n",
      "G: -0.08200892806053162\n",
      "Iteration 601\n",
      "D: -0.7129777669906616\n",
      "GP: 0.11243382096290588\n",
      "Gradient norm: 1.074818730354309\n",
      "G: -0.08373506367206573\n",
      "\n",
      "Epoch 21\n",
      "Iteration 1\n",
      "D: -0.7549692988395691\n",
      "GP: 0.07617859542369843\n",
      "Gradient norm: 0.956775963306427\n",
      "G: -0.042445436120033264\n",
      "Iteration 301\n",
      "D: -0.2802772521972656\n",
      "GP: 0.1921139359474182\n",
      "Gradient norm: 0.8974916338920593\n",
      "G: -0.444301038980484\n",
      "Iteration 601\n",
      "D: -0.7228865027427673\n",
      "GP: 0.07235688716173172\n",
      "Gradient norm: 1.0448002815246582\n",
      "G: -0.08454648405313492\n",
      "\n",
      "Epoch 22\n",
      "Iteration 1\n",
      "D: -0.5147263407707214\n",
      "GP: 0.26319432258605957\n",
      "Gradient norm: 0.8547916412353516\n",
      "G: -0.3554920554161072\n",
      "Iteration 301\n",
      "D: -0.8119162321090698\n",
      "GP: 0.04806928336620331\n",
      "Gradient norm: 0.9956847429275513\n",
      "G: -0.06472437083721161\n",
      "Iteration 601\n",
      "D: -0.7932795286178589\n",
      "GP: 0.05223340913653374\n",
      "Gradient norm: 1.0108318328857422\n",
      "G: -0.0582444965839386\n",
      "\n",
      "Epoch 23\n",
      "Iteration 1\n",
      "D: -0.7809564471244812\n",
      "GP: 0.07353047281503677\n",
      "Gradient norm: 1.0514212846755981\n",
      "G: -0.07113350927829742\n",
      "Iteration 301\n",
      "D: -0.244696706533432\n",
      "GP: 0.4108143150806427\n",
      "Gradient norm: 0.8173565864562988\n",
      "G: -0.05476783588528633\n",
      "Iteration 601\n",
      "D: -0.7956943511962891\n",
      "GP: 0.04502243548631668\n",
      "Gradient norm: 1.0050013065338135\n",
      "G: -0.08544914424419403\n",
      "\n",
      "Epoch 24\n",
      "Iteration 1\n",
      "D: -0.798916757106781\n",
      "GP: 0.047691985964775085\n",
      "Gradient norm: 0.9762130975723267\n",
      "G: -0.0888088122010231\n",
      "Iteration 301\n",
      "D: -0.8271101117134094\n",
      "GP: 0.05384540557861328\n",
      "Gradient norm: 1.0069302320480347\n",
      "G: -0.0924626961350441\n",
      "Iteration 601\n",
      "D: -0.6808852553367615\n",
      "GP: 0.09291200339794159\n",
      "Gradient norm: 0.9321407675743103\n",
      "G: -0.11439760029315948\n",
      "\n",
      "Epoch 25\n",
      "Iteration 1\n",
      "D: -0.7689114212989807\n",
      "GP: 0.08706481754779816\n",
      "Gradient norm: 0.9359048008918762\n",
      "G: -0.08257284760475159\n",
      "Iteration 301\n",
      "D: -0.7961351871490479\n",
      "GP: 0.05411173775792122\n",
      "Gradient norm: 1.02811598777771\n",
      "G: -0.08975426107645035\n",
      "Iteration 601\n",
      "D: -0.6972994208335876\n",
      "GP: 0.05991991236805916\n",
      "Gradient norm: 1.0042309761047363\n",
      "G: -0.26472416520118713\n",
      "\n",
      "Epoch 26\n",
      "Iteration 1\n",
      "D: -0.7868438363075256\n",
      "GP: 0.10953661054372787\n",
      "Gradient norm: 0.9197900295257568\n",
      "G: -0.05431954935193062\n",
      "Iteration 301\n",
      "D: -0.792311429977417\n",
      "GP: 0.050528399646282196\n",
      "Gradient norm: 0.9853827357292175\n",
      "G: -0.05949109047651291\n",
      "Iteration 601\n",
      "D: -0.7403054237365723\n",
      "GP: 0.07963534444570541\n",
      "Gradient norm: 1.0407447814941406\n",
      "G: -0.17602360248565674\n",
      "\n",
      "Epoch 27\n",
      "Iteration 1\n",
      "D: -0.8180403709411621\n",
      "GP: 0.05880891531705856\n",
      "Gradient norm: 0.9624075889587402\n",
      "G: -0.07561755925416946\n",
      "Iteration 301\n",
      "D: -0.8283057808876038\n",
      "GP: 0.0478937141597271\n",
      "Gradient norm: 1.0211656093597412\n",
      "G: -0.1477578580379486\n",
      "Iteration 601\n",
      "D: -0.744945764541626\n",
      "GP: 0.14937423169612885\n",
      "Gradient norm: 1.1005253791809082\n",
      "G: -0.015178737230598927\n",
      "\n",
      "Epoch 28\n",
      "Iteration 1\n",
      "D: -0.8332181572914124\n",
      "GP: 0.03845943138003349\n",
      "Gradient norm: 0.9962852001190186\n",
      "G: -0.08778642863035202\n",
      "Iteration 301\n",
      "D: -0.8036978244781494\n",
      "GP: 0.04727150872349739\n",
      "Gradient norm: 1.0189331769943237\n",
      "G: -0.05372297763824463\n",
      "Iteration 601\n",
      "D: -0.8468676209449768\n",
      "GP: 0.05665118992328644\n",
      "Gradient norm: 0.9702616930007935\n",
      "G: -0.057422421872615814\n",
      "\n",
      "Epoch 29\n",
      "Iteration 1\n",
      "D: -0.7947599291801453\n",
      "GP: 0.06977663934230804\n",
      "Gradient norm: 0.9512444734573364\n",
      "G: -0.03836267441511154\n",
      "Iteration 301\n",
      "D: -0.8321000933647156\n",
      "GP: 0.04408806189894676\n",
      "Gradient norm: 1.0119056701660156\n",
      "G: -0.06138187646865845\n",
      "Iteration 601\n",
      "D: -0.7797936201095581\n",
      "GP: 0.14232125878334045\n",
      "Gradient norm: 1.0977160930633545\n",
      "G: -0.046555206179618835\n",
      "\n",
      "Epoch 30\n",
      "Iteration 1\n",
      "D: -0.850811779499054\n",
      "GP: 0.0697360634803772\n",
      "Gradient norm: 1.049931526184082\n",
      "G: -0.04636956751346588\n",
      "Iteration 301\n",
      "D: -0.8406341671943665\n",
      "GP: 0.06781929731369019\n",
      "Gradient norm: 0.9496851563453674\n",
      "G: -0.052652496844530106\n",
      "Iteration 601\n",
      "D: -0.7707514762878418\n",
      "GP: 0.13358590006828308\n",
      "Gradient norm: 1.0962458848953247\n",
      "G: -0.05388170853257179\n",
      "\n",
      "Epoch 31\n",
      "Iteration 1\n",
      "D: -0.7942992448806763\n",
      "GP: 0.09232514351606369\n",
      "Gradient norm: 1.0662858486175537\n",
      "G: -0.06031956523656845\n",
      "Iteration 301\n",
      "D: -0.8496412038803101\n",
      "GP: 0.05422210320830345\n",
      "Gradient norm: 0.971503734588623\n",
      "G: -0.034559957683086395\n",
      "Iteration 601\n",
      "D: -0.7197816371917725\n",
      "GP: 0.1357896775007248\n",
      "Gradient norm: 1.0932300090789795\n",
      "G: -0.14412935078144073\n",
      "\n",
      "Epoch 32\n",
      "Iteration 1\n",
      "D: -0.7894273400306702\n",
      "GP: 0.10666294395923615\n",
      "Gradient norm: 1.0774943828582764\n",
      "G: -0.08684513717889786\n",
      "Iteration 301\n",
      "D: -0.8357606530189514\n",
      "GP: 0.08341459929943085\n",
      "Gradient norm: 1.061141014099121\n",
      "G: -0.018968479707837105\n",
      "Iteration 601\n",
      "D: -0.7327619791030884\n",
      "GP: 0.10848164558410645\n",
      "Gradient norm: 0.913596510887146\n",
      "G: -0.07729495316743851\n",
      "\n",
      "Epoch 33\n",
      "Iteration 1\n",
      "D: -0.8112518787384033\n",
      "GP: 0.053568035364151\n",
      "Gradient norm: 1.0266411304473877\n",
      "G: -0.0635174959897995\n",
      "Iteration 301\n",
      "D: -0.8670108318328857\n",
      "GP: 0.04011549428105354\n",
      "Gradient norm: 1.0033708810806274\n",
      "G: -0.05934516340494156\n",
      "Iteration 601\n",
      "D: -0.8062806129455566\n",
      "GP: 0.07933101058006287\n",
      "Gradient norm: 0.9402201771736145\n",
      "G: -0.037046901881694794\n",
      "\n",
      "Epoch 34\n",
      "Iteration 1\n",
      "D: -0.7573099732398987\n",
      "GP: 0.1367926001548767\n",
      "Gradient norm: 0.9064204096794128\n",
      "G: -0.06495318561792374\n",
      "Iteration 301\n",
      "D: -0.8163086771965027\n",
      "GP: 0.11158661544322968\n",
      "Gradient norm: 1.0854215621948242\n",
      "G: -0.028336629271507263\n",
      "Iteration 601\n",
      "D: -0.8930726647377014\n",
      "GP: 0.03933741897344589\n",
      "Gradient norm: 0.9841434955596924\n",
      "G: -0.03739575296640396\n",
      "\n",
      "Epoch 35\n",
      "Iteration 1\n",
      "D: -0.8070212602615356\n",
      "GP: 0.061645153909921646\n",
      "Gradient norm: 1.0447949171066284\n",
      "G: -0.046684883534908295\n",
      "Iteration 301\n",
      "D: -0.8607837557792664\n",
      "GP: 0.051506366580724716\n",
      "Gradient norm: 0.9685359001159668\n",
      "G: -0.04997095465660095\n",
      "Iteration 601\n",
      "D: -0.9165524244308472\n",
      "GP: 0.03557761013507843\n",
      "Gradient norm: 0.9915859699249268\n",
      "G: -0.018991820514202118\n",
      "\n",
      "Epoch 36\n",
      "Iteration 1\n",
      "D: -0.6026614904403687\n",
      "GP: 0.18171018362045288\n",
      "Gradient norm: 1.1136757135391235\n",
      "G: -0.12776334583759308\n",
      "Iteration 301\n",
      "D: -0.81158047914505\n",
      "GP: 0.06304565817117691\n",
      "Gradient norm: 0.973344624042511\n",
      "G: -0.11273393779993057\n",
      "Iteration 601\n",
      "D: -0.6840723752975464\n",
      "GP: 0.24963927268981934\n",
      "Gradient norm: 0.8641385436058044\n",
      "G: -0.04004007577896118\n",
      "\n",
      "Epoch 37\n",
      "Iteration 1\n",
      "D: -0.7864453792572021\n",
      "GP: 0.14677192270755768\n",
      "Gradient norm: 0.9073939323425293\n",
      "G: -0.14978575706481934\n",
      "Iteration 301\n",
      "D: -0.7906222939491272\n",
      "GP: 0.1572813242673874\n",
      "Gradient norm: 0.8955484628677368\n",
      "G: -0.08239179104566574\n",
      "Iteration 601\n",
      "D: -0.7789459228515625\n",
      "GP: 0.05436457321047783\n",
      "Gradient norm: 1.0099833011627197\n",
      "G: -0.17447420954704285\n",
      "\n",
      "Epoch 38\n",
      "Iteration 1\n",
      "D: -0.7722840309143066\n",
      "GP: 0.10156424343585968\n",
      "Gradient norm: 1.0785455703735352\n",
      "G: -0.0735621303319931\n",
      "Iteration 301\n",
      "D: -0.8532477021217346\n",
      "GP: 0.07073425501585007\n",
      "Gradient norm: 0.9544296264648438\n",
      "G: -0.1423868089914322\n",
      "Iteration 601\n",
      "D: -0.7548602819442749\n",
      "GP: 0.10999537259340286\n",
      "Gradient norm: 1.0801103115081787\n",
      "G: -0.08686386048793793\n",
      "\n",
      "Epoch 39\n",
      "Iteration 1\n",
      "D: -0.79221510887146\n",
      "GP: 0.06684021651744843\n",
      "Gradient norm: 1.0435376167297363\n",
      "G: -0.08262258768081665\n",
      "Iteration 301\n",
      "D: -0.6514223217964172\n",
      "GP: 0.0773264691233635\n",
      "Gradient norm: 1.0534234046936035\n",
      "G: -0.3290017247200012\n",
      "Iteration 601\n",
      "D: -0.6421276926994324\n",
      "GP: 0.05347669869661331\n",
      "Gradient norm: 0.9656590223312378\n",
      "G: -0.21124300360679626\n",
      "\n",
      "Epoch 40\n",
      "Iteration 1\n",
      "D: -0.794012188911438\n",
      "GP: 0.06100448966026306\n",
      "Gradient norm: 1.0385292768478394\n",
      "G: -0.14777137339115143\n",
      "Iteration 301\n",
      "D: -0.6501220464706421\n",
      "GP: 0.26537543535232544\n",
      "Gradient norm: 0.8548331260681152\n",
      "G: -0.06364614516496658\n",
      "Iteration 601\n",
      "D: -0.5374808311462402\n",
      "GP: 0.07206717133522034\n",
      "Gradient norm: 1.0498936176300049\n",
      "G: -0.33461499214172363\n",
      "\n",
      "Epoch 41\n",
      "Iteration 1\n",
      "D: -0.9082971811294556\n",
      "GP: 0.04606160521507263\n",
      "Gradient norm: 0.9814587235450745\n",
      "G: -0.02870834432542324\n",
      "Iteration 301\n",
      "D: -0.7197782397270203\n",
      "GP: 0.08309483528137207\n",
      "Gradient norm: 0.940401554107666\n",
      "G: -0.1671651303768158\n"
     ]
    }
   ],
   "source": [
    "kaiming_init(generator)\n",
    "#utils.gaussian_intiailize(generator, 0.02)\n",
    "kaiming_init(discriminator)\n",
    "                  \n",
    "trainer = Trainer(generator, discriminator, G_optimizer, D_optimizer, G_sheduler, D_sheduler,\n",
    "                  use_cuda=torch.cuda.is_available())\n",
    "trainer.train(trainloader, epochs, save_training_gif=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'logo_model'\n",
    "torch.save(trainer.G.state_dict(), './gen_' + name + '.pt')\n",
    "torch.save(trainer.D.state_dict(), './dis_' + name + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = \"200ep_gray/gen_logo_model.pt\"\n",
    "netG = Generator(img_size, latent_dim=100, dim=16)\n",
    "netG.load_state_dict(torch.load(weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG.eval()\n",
    "netG.cuda()\n",
    "\n",
    "# Get latent vector Z from unit normal distribution.\n",
    "noise = torch.randn(1, 100, device=\"cuda\")\n",
    "\n",
    "# Turn off gradient calculation to speed up the process.\n",
    "with torch.no_grad():\n",
    "\t# Get generated image from the noise vector using\n",
    "\t# the trained generator.\n",
    "    generated_img = netG(noise).detach().cpu()\n",
    "generated_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f102a41fe80>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(generated_img[0].cpu().detach().numpy().squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
