{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_gan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Hy7fIGqBBe",
        "outputId": "b8037268-d14b-4b0e-dcb0-df5f6319e3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!nvidia-smi\n",
        "import pickle \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Oct  3 19:56:59 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L9WYZMsrt05",
        "outputId": "642fbce4-c2b8-40e5-a6a1-9c53e080d0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "!unzip '/content/drive/My Drive/LLD-icon_PKL.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/LLD-icon_PKL.zip\n",
            "   creating: LLD-icon/\n",
            "  inflating: LLD-icon/LLD-icon_data_2.pkl  \n",
            "  inflating: LLD-icon/LLD-icon_data_0.pkl  \n",
            "  inflating: LLD-icon/LLD-icon_data_3.pkl  \n",
            "  inflating: LLD-icon/LLD-icon_data_4.pkl  \n",
            "  inflating: LLD-icon/LLD-icon_data_1.pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3R9oRv2sBAP"
      },
      "source": [
        "with open('/content/LLD-icon/LLD-icon_data_0.pkl', 'rb') as f:\n",
        "    part1 = pickle.load(f, encoding='ISO-8859-1')\n",
        "with open('/content/LLD-icon/LLD-icon_data_1.pkl', 'rb') as f:\n",
        "    part2 = pickle.load(f, encoding='ISO-8859-1')\n",
        "with open('/content/LLD-icon/LLD-icon_data_2.pkl', 'rb') as f:\n",
        "    part3 = pickle.load(f, encoding='ISO-8859-1')\n",
        "with open('/content/LLD-icon/LLD-icon_data_3.pkl', 'rb') as f:\n",
        "    part4 = pickle.load(f, encoding='ISO-8859-1')\n",
        "with open('/content/LLD-icon/LLD-icon_data_4.pkl', 'rb') as f:\n",
        "    part5 = pickle.load(f, encoding='ISO-8859-1')   "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIkPxbhts0er",
        "outputId": "81eb132a-b5b8-4a18-8086-7784ccf6cdda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "i=random.randint(0,10000)\n",
        "plt.imshow(part1[i,:,:])\n",
        "print(part1[i,:,:].shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG3QGoBatx2h"
      },
      "source": [
        "train_df=np.concatenate([part1,part2])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSYLVOCsvohD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUcG4swpu0Su"
      },
      "source": [
        "class WGAN():\n",
        "    def __init__(self):\n",
        "        self.img_rows = 32\n",
        "        self.img_cols = 32\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "\n",
        "        # Following parameter and optimizer set as recommended in paper\n",
        "        self.n_critic = 5\n",
        "        self.clip_value = 0.01\n",
        "        optimizer = RMSprop(lr=0.00005)\n",
        "\n",
        "        # Build and compile the critic\n",
        "        self.critic = self.build_critic()\n",
        "        self.critic.compile(loss=self.wasserstein_loss,\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generated imgs\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.critic.trainable = False\n",
        "\n",
        "        # The critic takes generated images as input and determines validity\n",
        "        valid = self.critic(img)\n",
        "\n",
        "        # The combined model  (stacked generator and critic)\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss=self.wasserstein_loss,\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "    def wasserstein_loss(self, y_true, y_pred):\n",
        "        return K.mean(y_true * y_pred)\n",
        "  \n",
        "\n",
        "    def build_generator(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((8, 8, 128)))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_critic(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "        \n",
        "    def train(self, epochs, train_df, batch_size=400, sample_interval=50):\n",
        "\n",
        "        # Load the dataset\n",
        "        X_train=train_df\n",
        "\n",
        "        # Rescale -1 to 1\n",
        "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "        #X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = -np.ones((batch_size, 1))\n",
        "        fake = np.ones((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            for _ in range(self.n_critic):\n",
        "\n",
        "                # ---------------------\n",
        "                #  Train Discriminator\n",
        "                # ---------------------\n",
        "\n",
        "                # Select a random batch of images\n",
        "                idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "                imgs = X_train[idx]\n",
        "                \n",
        "                # Sample noise as generator input\n",
        "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "                # Generate a batch of new images\n",
        "                gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "                # Train the critic\n",
        "                d_loss_real = self.critic.train_on_batch(imgs, valid)\n",
        "                d_loss_fake = self.critic.train_on_batch(gen_imgs, fake)\n",
        "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "\n",
        "                # Clip critic weights\n",
        "                for l in self.critic.layers:\n",
        "                    weights = l.get_weights()\n",
        "                    weights = [np.clip(w, -self.clip_value, self.clip_value) for w in weights]\n",
        "                    l.set_weights(weights)\n",
        "\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, 1 - d_loss[0], 1 - g_loss[0]))\n",
        "            self.critic.save(\"/content/drive/My Drive/discriminator.h5\")\n",
        "            self.generator.save(\"/content/drive/My Drive/generator.h5\")\n",
        "            self.combined.save(\"/content/drive/My Drive/combined.h5\")\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch)\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"/content/drive/My Drive/image_%d.png\" % epoch)\n",
        "        plt.close()\n",
        "\n",
        "   "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udbvtkUlu3NE",
        "outputId": "4ee24147-5a58-4923-cd74-90ff7558b49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "wgan = WGAN()\n",
        "wgan.train(epochs=4000, train_df=train_df, batch_size=40, sample_interval=50)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 16, 16, 16)        448       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)   (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPaddin (None, 9, 9, 32)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 9, 9, 32)          128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 9, 9, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 9, 9, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 5, 5, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 5, 5, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 5, 5, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 5, 5, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 3201      \n",
            "=================================================================\n",
            "Total params: 101,537\n",
            "Trainable params: 101,089\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 8192)              827392    \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 16, 16, 128)       262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 32, 32, 64)        131136    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 32, 32, 3)         3075      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 32, 32, 3)         0         \n",
            "=================================================================\n",
            "Total params: 1,224,643\n",
            "Trainable params: 1,224,259\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n",
            "0 [D loss: 0.999900] [G loss: 1.000109]\n",
            "1 [D loss: 0.999913] [G loss: 1.000207]\n",
            "2 [D loss: 0.999916] [G loss: 1.000219]\n",
            "3 [D loss: 0.999916] [G loss: 1.000224]\n",
            "4 [D loss: 0.999917] [G loss: 1.000222]\n",
            "5 [D loss: 0.999916] [G loss: 1.000231]\n",
            "6 [D loss: 0.999925] [G loss: 1.000214]\n",
            "7 [D loss: 0.999922] [G loss: 1.000241]\n",
            "8 [D loss: 0.999914] [G loss: 1.000231]\n",
            "9 [D loss: 0.999915] [G loss: 1.000228]\n",
            "10 [D loss: 0.999919] [G loss: 1.000206]\n",
            "11 [D loss: 0.999922] [G loss: 1.000213]\n",
            "12 [D loss: 0.999922] [G loss: 1.000200]\n",
            "13 [D loss: 0.999923] [G loss: 1.000188]\n",
            "14 [D loss: 0.999933] [G loss: 1.000170]\n",
            "15 [D loss: 0.999934] [G loss: 1.000177]\n",
            "16 [D loss: 0.999926] [G loss: 1.000160]\n",
            "17 [D loss: 0.999936] [G loss: 1.000149]\n",
            "18 [D loss: 0.999937] [G loss: 1.000130]\n",
            "19 [D loss: 0.999943] [G loss: 1.000127]\n",
            "20 [D loss: 0.999944] [G loss: 1.000115]\n",
            "21 [D loss: 0.999948] [G loss: 1.000107]\n",
            "22 [D loss: 0.999949] [G loss: 1.000109]\n",
            "23 [D loss: 0.999955] [G loss: 1.000103]\n",
            "24 [D loss: 0.999953] [G loss: 1.000096]\n",
            "25 [D loss: 0.999952] [G loss: 1.000094]\n",
            "26 [D loss: 0.999956] [G loss: 1.000092]\n",
            "27 [D loss: 0.999960] [G loss: 1.000084]\n",
            "28 [D loss: 0.999962] [G loss: 1.000082]\n",
            "29 [D loss: 0.999960] [G loss: 1.000083]\n",
            "30 [D loss: 0.999962] [G loss: 1.000074]\n",
            "31 [D loss: 0.999964] [G loss: 1.000076]\n",
            "32 [D loss: 0.999962] [G loss: 1.000067]\n",
            "33 [D loss: 0.999968] [G loss: 1.000071]\n",
            "34 [D loss: 0.999965] [G loss: 1.000067]\n",
            "35 [D loss: 0.999967] [G loss: 1.000067]\n",
            "36 [D loss: 0.999964] [G loss: 1.000072]\n",
            "37 [D loss: 0.999968] [G loss: 1.000066]\n",
            "38 [D loss: 0.999968] [G loss: 1.000061]\n",
            "39 [D loss: 0.999974] [G loss: 1.000064]\n",
            "40 [D loss: 0.999974] [G loss: 1.000058]\n",
            "41 [D loss: 0.999977] [G loss: 1.000068]\n",
            "42 [D loss: 0.999978] [G loss: 1.000059]\n",
            "43 [D loss: 0.999975] [G loss: 1.000077]\n",
            "44 [D loss: 0.999974] [G loss: 1.000060]\n",
            "45 [D loss: 0.999975] [G loss: 1.000064]\n",
            "46 [D loss: 0.999977] [G loss: 1.000056]\n",
            "47 [D loss: 0.999969] [G loss: 1.000060]\n",
            "48 [D loss: 0.999964] [G loss: 1.000068]\n",
            "49 [D loss: 0.999965] [G loss: 1.000063]\n",
            "50 [D loss: 0.999965] [G loss: 1.000064]\n",
            "51 [D loss: 0.999971] [G loss: 1.000065]\n",
            "52 [D loss: 0.999977] [G loss: 1.000056]\n",
            "53 [D loss: 0.999974] [G loss: 1.000068]\n",
            "54 [D loss: 0.999973] [G loss: 1.000073]\n",
            "55 [D loss: 0.999966] [G loss: 1.000066]\n",
            "56 [D loss: 0.999977] [G loss: 1.000063]\n",
            "57 [D loss: 0.999976] [G loss: 1.000061]\n",
            "58 [D loss: 0.999974] [G loss: 1.000075]\n",
            "59 [D loss: 0.999972] [G loss: 1.000079]\n",
            "60 [D loss: 0.999974] [G loss: 1.000073]\n",
            "61 [D loss: 0.999973] [G loss: 1.000077]\n",
            "62 [D loss: 0.999992] [G loss: 1.000073]\n",
            "63 [D loss: 0.999972] [G loss: 1.000064]\n",
            "64 [D loss: 0.999987] [G loss: 1.000073]\n",
            "65 [D loss: 0.999981] [G loss: 1.000068]\n",
            "66 [D loss: 0.999966] [G loss: 1.000077]\n",
            "67 [D loss: 0.999973] [G loss: 1.000081]\n",
            "68 [D loss: 0.999971] [G loss: 1.000082]\n",
            "69 [D loss: 0.999973] [G loss: 1.000065]\n",
            "70 [D loss: 0.999969] [G loss: 1.000075]\n",
            "71 [D loss: 0.999970] [G loss: 1.000082]\n",
            "72 [D loss: 0.999959] [G loss: 1.000069]\n",
            "73 [D loss: 0.999981] [G loss: 1.000072]\n",
            "74 [D loss: 0.999971] [G loss: 1.000072]\n",
            "75 [D loss: 0.999965] [G loss: 1.000071]\n",
            "76 [D loss: 0.999962] [G loss: 1.000066]\n",
            "77 [D loss: 0.999976] [G loss: 1.000079]\n",
            "78 [D loss: 0.999971] [G loss: 1.000074]\n",
            "79 [D loss: 0.999966] [G loss: 1.000074]\n",
            "80 [D loss: 0.999975] [G loss: 1.000079]\n",
            "81 [D loss: 0.999971] [G loss: 1.000080]\n",
            "82 [D loss: 0.999976] [G loss: 1.000073]\n",
            "83 [D loss: 0.999972] [G loss: 1.000066]\n",
            "84 [D loss: 0.999973] [G loss: 1.000066]\n",
            "85 [D loss: 0.999974] [G loss: 1.000062]\n",
            "86 [D loss: 0.999975] [G loss: 1.000067]\n",
            "87 [D loss: 0.999971] [G loss: 1.000071]\n",
            "88 [D loss: 0.999973] [G loss: 1.000082]\n",
            "89 [D loss: 0.999971] [G loss: 1.000079]\n",
            "90 [D loss: 0.999965] [G loss: 1.000080]\n",
            "91 [D loss: 0.999981] [G loss: 1.000077]\n",
            "92 [D loss: 0.999977] [G loss: 1.000075]\n",
            "93 [D loss: 0.999980] [G loss: 1.000080]\n",
            "94 [D loss: 0.999978] [G loss: 1.000068]\n",
            "95 [D loss: 0.999987] [G loss: 1.000065]\n",
            "96 [D loss: 0.999977] [G loss: 1.000071]\n",
            "97 [D loss: 0.999976] [G loss: 1.000068]\n",
            "98 [D loss: 0.999990] [G loss: 1.000065]\n",
            "99 [D loss: 0.999988] [G loss: 1.000067]\n",
            "100 [D loss: 0.999993] [G loss: 1.000073]\n",
            "101 [D loss: 1.000001] [G loss: 1.000080]\n",
            "102 [D loss: 1.000006] [G loss: 1.000088]\n",
            "103 [D loss: 1.000031] [G loss: 1.000103]\n",
            "104 [D loss: 1.000018] [G loss: 1.000103]\n",
            "105 [D loss: 1.000047] [G loss: 1.000098]\n",
            "106 [D loss: 1.000060] [G loss: 1.000127]\n",
            "107 [D loss: 1.000042] [G loss: 1.000117]\n",
            "108 [D loss: 1.000092] [G loss: 1.000141]\n",
            "109 [D loss: 1.000116] [G loss: 1.000132]\n",
            "110 [D loss: 1.000116] [G loss: 1.000138]\n",
            "111 [D loss: 1.000167] [G loss: 1.000154]\n",
            "112 [D loss: 1.000156] [G loss: 1.000149]\n",
            "113 [D loss: 1.000174] [G loss: 1.000138]\n",
            "114 [D loss: 1.000194] [G loss: 1.000123]\n",
            "115 [D loss: 1.000194] [G loss: 1.000136]\n",
            "116 [D loss: 1.000279] [G loss: 1.000097]\n",
            "117 [D loss: 1.000227] [G loss: 1.000071]\n",
            "118 [D loss: 1.000269] [G loss: 1.000032]\n",
            "119 [D loss: 1.000308] [G loss: 0.999980]\n",
            "120 [D loss: 1.000330] [G loss: 0.999952]\n",
            "121 [D loss: 1.000316] [G loss: 0.999911]\n",
            "122 [D loss: 1.000305] [G loss: 0.999856]\n",
            "123 [D loss: 1.000218] [G loss: 0.999838]\n",
            "124 [D loss: 1.000373] [G loss: 0.999814]\n",
            "125 [D loss: 1.000148] [G loss: 0.999761]\n",
            "126 [D loss: 1.000313] [G loss: 0.999742]\n",
            "127 [D loss: 1.000144] [G loss: 0.999769]\n",
            "128 [D loss: 1.000283] [G loss: 0.999770]\n",
            "129 [D loss: 1.000179] [G loss: 0.999719]\n",
            "130 [D loss: 1.000185] [G loss: 0.999699]\n",
            "131 [D loss: 0.999954] [G loss: 0.999763]\n",
            "132 [D loss: 1.000138] [G loss: 0.999801]\n",
            "133 [D loss: 1.000135] [G loss: 0.999846]\n",
            "134 [D loss: 1.000251] [G loss: 0.999743]\n",
            "135 [D loss: 1.000339] [G loss: 0.999720]\n",
            "136 [D loss: 1.000512] [G loss: 0.999602]\n",
            "137 [D loss: 1.000388] [G loss: 0.999628]\n",
            "138 [D loss: 1.000353] [G loss: 0.999577]\n",
            "139 [D loss: 1.000099] [G loss: 0.999709]\n",
            "140 [D loss: 1.000220] [G loss: 0.999702]\n",
            "141 [D loss: 1.000002] [G loss: 0.999782]\n",
            "142 [D loss: 1.000146] [G loss: 0.999844]\n",
            "143 [D loss: 0.999901] [G loss: 0.999836]\n",
            "144 [D loss: 1.000081] [G loss: 0.999810]\n",
            "145 [D loss: 1.000410] [G loss: 0.999831]\n",
            "146 [D loss: 1.000181] [G loss: 0.999863]\n",
            "147 [D loss: 1.000122] [G loss: 0.999873]\n",
            "148 [D loss: 1.000367] [G loss: 0.999901]\n",
            "149 [D loss: 0.999911] [G loss: 0.999950]\n",
            "150 [D loss: 1.000058] [G loss: 0.999959]\n",
            "151 [D loss: 1.000072] [G loss: 0.999970]\n",
            "152 [D loss: 1.000090] [G loss: 1.000110]\n",
            "153 [D loss: 1.000115] [G loss: 1.000082]\n",
            "154 [D loss: 1.000212] [G loss: 1.000075]\n",
            "155 [D loss: 1.000113] [G loss: 1.000175]\n",
            "156 [D loss: 1.000016] [G loss: 1.000239]\n",
            "157 [D loss: 0.999984] [G loss: 1.000171]\n",
            "158 [D loss: 1.000073] [G loss: 1.000234]\n",
            "159 [D loss: 1.000106] [G loss: 1.000152]\n",
            "160 [D loss: 0.999992] [G loss: 1.000162]\n",
            "161 [D loss: 1.000146] [G loss: 1.000175]\n",
            "162 [D loss: 1.000022] [G loss: 1.000268]\n",
            "163 [D loss: 1.000163] [G loss: 1.000113]\n",
            "164 [D loss: 1.000150] [G loss: 1.000120]\n",
            "165 [D loss: 1.000166] [G loss: 1.000083]\n",
            "166 [D loss: 1.000092] [G loss: 1.000197]\n",
            "167 [D loss: 1.000073] [G loss: 1.000192]\n",
            "168 [D loss: 1.000090] [G loss: 1.000236]\n",
            "169 [D loss: 1.000076] [G loss: 1.000309]\n",
            "170 [D loss: 1.000085] [G loss: 1.000291]\n",
            "171 [D loss: 1.000027] [G loss: 1.000445]\n",
            "172 [D loss: 1.000092] [G loss: 1.000349]\n",
            "173 [D loss: 1.000062] [G loss: 1.000508]\n",
            "174 [D loss: 1.000051] [G loss: 1.000462]\n",
            "175 [D loss: 0.999972] [G loss: 1.000541]\n",
            "176 [D loss: 1.000120] [G loss: 1.000389]\n",
            "177 [D loss: 0.999950] [G loss: 1.000543]\n",
            "178 [D loss: 1.000020] [G loss: 1.000413]\n",
            "179 [D loss: 0.999955] [G loss: 1.000449]\n",
            "180 [D loss: 0.999889] [G loss: 1.000465]\n",
            "181 [D loss: 1.000066] [G loss: 1.000325]\n",
            "182 [D loss: 1.000135] [G loss: 1.000308]\n",
            "183 [D loss: 1.000078] [G loss: 1.000317]\n",
            "184 [D loss: 1.000085] [G loss: 1.000275]\n",
            "185 [D loss: 0.999899] [G loss: 1.000280]\n",
            "186 [D loss: 1.000129] [G loss: 1.000146]\n",
            "187 [D loss: 1.000181] [G loss: 1.000098]\n",
            "188 [D loss: 1.000092] [G loss: 1.000140]\n",
            "189 [D loss: 1.000106] [G loss: 1.000117]\n",
            "190 [D loss: 1.000116] [G loss: 1.000103]\n",
            "191 [D loss: 1.000054] [G loss: 1.000147]\n",
            "192 [D loss: 1.000160] [G loss: 1.000067]\n",
            "193 [D loss: 0.999967] [G loss: 1.000125]\n",
            "194 [D loss: 0.999989] [G loss: 1.000129]\n",
            "195 [D loss: 1.000064] [G loss: 1.000191]\n",
            "196 [D loss: 1.000055] [G loss: 1.000199]\n",
            "197 [D loss: 1.000025] [G loss: 1.000304]\n",
            "198 [D loss: 1.000066] [G loss: 1.000295]\n",
            "199 [D loss: 1.000092] [G loss: 1.000259]\n",
            "200 [D loss: 0.999887] [G loss: 1.000217]\n",
            "201 [D loss: 1.000001] [G loss: 1.000200]\n",
            "202 [D loss: 0.999953] [G loss: 1.000298]\n",
            "203 [D loss: 0.999949] [G loss: 1.000177]\n",
            "204 [D loss: 1.000034] [G loss: 1.000179]\n",
            "205 [D loss: 0.999966] [G loss: 1.000197]\n",
            "206 [D loss: 1.000000] [G loss: 1.000265]\n",
            "207 [D loss: 1.000054] [G loss: 1.000167]\n",
            "208 [D loss: 1.000043] [G loss: 1.000202]\n",
            "209 [D loss: 1.000044] [G loss: 1.000180]\n",
            "210 [D loss: 1.000055] [G loss: 1.000223]\n",
            "211 [D loss: 1.000072] [G loss: 1.000263]\n",
            "212 [D loss: 1.000067] [G loss: 1.000190]\n",
            "213 [D loss: 1.000026] [G loss: 1.000224]\n",
            "214 [D loss: 0.999942] [G loss: 1.000325]\n",
            "215 [D loss: 1.000055] [G loss: 1.000179]\n",
            "216 [D loss: 0.999992] [G loss: 1.000246]\n",
            "217 [D loss: 1.000059] [G loss: 1.000245]\n",
            "218 [D loss: 1.000135] [G loss: 1.000161]\n",
            "219 [D loss: 1.000120] [G loss: 1.000275]\n",
            "220 [D loss: 0.999982] [G loss: 1.000457]\n",
            "221 [D loss: 1.000006] [G loss: 1.000308]\n",
            "222 [D loss: 1.000057] [G loss: 1.000351]\n",
            "223 [D loss: 0.999941] [G loss: 1.000430]\n",
            "224 [D loss: 0.999922] [G loss: 1.000354]\n",
            "225 [D loss: 0.999984] [G loss: 1.000305]\n",
            "226 [D loss: 1.000009] [G loss: 1.000261]\n",
            "227 [D loss: 1.000071] [G loss: 1.000230]\n",
            "228 [D loss: 0.999958] [G loss: 1.000340]\n",
            "229 [D loss: 1.000082] [G loss: 1.000214]\n",
            "230 [D loss: 0.999988] [G loss: 1.000301]\n",
            "231 [D loss: 0.999965] [G loss: 1.000327]\n",
            "232 [D loss: 0.999958] [G loss: 1.000262]\n",
            "233 [D loss: 0.999987] [G loss: 1.000239]\n",
            "234 [D loss: 1.000021] [G loss: 1.000210]\n",
            "235 [D loss: 0.999937] [G loss: 1.000284]\n",
            "236 [D loss: 0.999936] [G loss: 1.000275]\n",
            "237 [D loss: 0.999992] [G loss: 1.000217]\n",
            "238 [D loss: 0.999994] [G loss: 1.000219]\n",
            "239 [D loss: 0.999982] [G loss: 1.000233]\n",
            "240 [D loss: 0.999957] [G loss: 1.000243]\n",
            "241 [D loss: 0.999981] [G loss: 1.000192]\n",
            "242 [D loss: 0.999949] [G loss: 1.000199]\n",
            "243 [D loss: 0.999971] [G loss: 1.000203]\n",
            "244 [D loss: 1.000002] [G loss: 1.000175]\n",
            "245 [D loss: 1.000028] [G loss: 1.000141]\n",
            "246 [D loss: 0.999976] [G loss: 1.000182]\n",
            "247 [D loss: 0.999980] [G loss: 1.000193]\n",
            "248 [D loss: 0.999941] [G loss: 1.000184]\n",
            "249 [D loss: 0.999955] [G loss: 1.000151]\n",
            "250 [D loss: 0.999992] [G loss: 1.000181]\n",
            "251 [D loss: 1.000015] [G loss: 1.000107]\n",
            "252 [D loss: 0.999971] [G loss: 1.000149]\n",
            "253 [D loss: 1.000022] [G loss: 1.000110]\n",
            "254 [D loss: 1.000033] [G loss: 1.000111]\n",
            "255 [D loss: 0.999991] [G loss: 1.000127]\n",
            "256 [D loss: 1.000009] [G loss: 1.000134]\n",
            "257 [D loss: 1.000012] [G loss: 1.000104]\n",
            "258 [D loss: 0.999968] [G loss: 1.000152]\n",
            "259 [D loss: 0.999966] [G loss: 1.000210]\n",
            "260 [D loss: 0.999981] [G loss: 1.000184]\n",
            "261 [D loss: 0.999983] [G loss: 1.000132]\n",
            "262 [D loss: 0.999924] [G loss: 1.000145]\n",
            "263 [D loss: 0.999948] [G loss: 1.000139]\n",
            "264 [D loss: 0.999998] [G loss: 1.000143]\n",
            "265 [D loss: 0.999958] [G loss: 1.000128]\n",
            "266 [D loss: 0.999962] [G loss: 1.000117]\n",
            "267 [D loss: 1.000013] [G loss: 1.000085]\n",
            "268 [D loss: 0.999970] [G loss: 1.000142]\n",
            "269 [D loss: 1.000011] [G loss: 1.000155]\n",
            "270 [D loss: 0.999985] [G loss: 1.000153]\n",
            "271 [D loss: 0.999992] [G loss: 1.000186]\n",
            "272 [D loss: 1.000019] [G loss: 1.000122]\n",
            "273 [D loss: 0.999990] [G loss: 1.000149]\n",
            "274 [D loss: 0.999999] [G loss: 1.000151]\n",
            "275 [D loss: 0.999970] [G loss: 1.000138]\n",
            "276 [D loss: 0.999992] [G loss: 1.000122]\n",
            "277 [D loss: 0.999981] [G loss: 1.000151]\n",
            "278 [D loss: 0.999953] [G loss: 1.000151]\n",
            "279 [D loss: 0.999985] [G loss: 1.000148]\n",
            "280 [D loss: 0.999956] [G loss: 1.000177]\n",
            "281 [D loss: 0.999970] [G loss: 1.000167]\n",
            "282 [D loss: 0.999968] [G loss: 1.000146]\n",
            "283 [D loss: 0.999964] [G loss: 1.000180]\n",
            "284 [D loss: 0.999956] [G loss: 1.000152]\n",
            "285 [D loss: 0.999970] [G loss: 1.000146]\n",
            "286 [D loss: 0.999975] [G loss: 1.000123]\n",
            "287 [D loss: 0.999978] [G loss: 1.000121]\n",
            "288 [D loss: 0.999982] [G loss: 1.000111]\n",
            "289 [D loss: 0.999973] [G loss: 1.000125]\n",
            "290 [D loss: 0.999963] [G loss: 1.000141]\n",
            "291 [D loss: 0.999977] [G loss: 1.000125]\n",
            "292 [D loss: 0.999956] [G loss: 1.000105]\n",
            "293 [D loss: 0.999977] [G loss: 1.000121]\n",
            "294 [D loss: 0.999952] [G loss: 1.000129]\n",
            "295 [D loss: 0.999976] [G loss: 1.000106]\n",
            "296 [D loss: 0.999980] [G loss: 1.000113]\n",
            "297 [D loss: 0.999957] [G loss: 1.000115]\n",
            "298 [D loss: 0.999994] [G loss: 1.000086]\n",
            "299 [D loss: 0.999972] [G loss: 1.000093]\n",
            "300 [D loss: 0.999971] [G loss: 1.000085]\n",
            "301 [D loss: 0.999964] [G loss: 1.000114]\n",
            "302 [D loss: 0.999976] [G loss: 1.000107]\n",
            "303 [D loss: 0.999974] [G loss: 1.000114]\n",
            "304 [D loss: 0.999970] [G loss: 1.000128]\n",
            "305 [D loss: 0.999953] [G loss: 1.000126]\n",
            "306 [D loss: 0.999963] [G loss: 1.000117]\n",
            "307 [D loss: 0.999959] [G loss: 1.000110]\n",
            "308 [D loss: 0.999969] [G loss: 1.000104]\n",
            "309 [D loss: 0.999973] [G loss: 1.000103]\n",
            "310 [D loss: 0.999977] [G loss: 1.000091]\n",
            "311 [D loss: 0.999966] [G loss: 1.000095]\n",
            "312 [D loss: 0.999973] [G loss: 1.000091]\n",
            "313 [D loss: 0.999977] [G loss: 1.000103]\n",
            "314 [D loss: 0.999979] [G loss: 1.000069]\n",
            "315 [D loss: 0.999965] [G loss: 1.000086]\n",
            "316 [D loss: 0.999971] [G loss: 1.000096]\n",
            "317 [D loss: 0.999968] [G loss: 1.000115]\n",
            "318 [D loss: 0.999963] [G loss: 1.000118]\n",
            "319 [D loss: 0.999976] [G loss: 1.000100]\n",
            "320 [D loss: 0.999968] [G loss: 1.000085]\n",
            "321 [D loss: 0.999967] [G loss: 1.000100]\n",
            "322 [D loss: 0.999970] [G loss: 1.000082]\n",
            "323 [D loss: 0.999971] [G loss: 1.000106]\n",
            "324 [D loss: 0.999976] [G loss: 1.000096]\n",
            "325 [D loss: 0.999979] [G loss: 1.000093]\n",
            "326 [D loss: 0.999972] [G loss: 1.000090]\n",
            "327 [D loss: 0.999965] [G loss: 1.000088]\n",
            "328 [D loss: 0.999967] [G loss: 1.000092]\n",
            "329 [D loss: 0.999975] [G loss: 1.000089]\n",
            "330 [D loss: 0.999973] [G loss: 1.000087]\n",
            "331 [D loss: 0.999970] [G loss: 1.000099]\n",
            "332 [D loss: 0.999972] [G loss: 1.000074]\n",
            "333 [D loss: 0.999975] [G loss: 1.000092]\n",
            "334 [D loss: 1.000002] [G loss: 1.000087]\n",
            "335 [D loss: 0.999975] [G loss: 1.000102]\n",
            "336 [D loss: 0.999980] [G loss: 1.000075]\n",
            "337 [D loss: 0.999965] [G loss: 1.000093]\n",
            "338 [D loss: 0.999977] [G loss: 1.000090]\n",
            "339 [D loss: 0.999970] [G loss: 1.000090]\n",
            "340 [D loss: 0.999974] [G loss: 1.000094]\n",
            "341 [D loss: 0.999974] [G loss: 1.000083]\n",
            "342 [D loss: 0.999988] [G loss: 1.000088]\n",
            "343 [D loss: 0.999990] [G loss: 1.000092]\n",
            "344 [D loss: 0.999968] [G loss: 1.000093]\n",
            "345 [D loss: 0.999979] [G loss: 1.000088]\n",
            "346 [D loss: 0.999967] [G loss: 1.000123]\n",
            "347 [D loss: 0.999958] [G loss: 1.000124]\n",
            "348 [D loss: 0.999973] [G loss: 1.000092]\n",
            "349 [D loss: 0.999981] [G loss: 1.000100]\n",
            "350 [D loss: 0.999964] [G loss: 1.000101]\n",
            "351 [D loss: 0.999980] [G loss: 1.000102]\n",
            "352 [D loss: 0.999981] [G loss: 1.000099]\n",
            "353 [D loss: 0.999974] [G loss: 1.000086]\n",
            "354 [D loss: 0.999983] [G loss: 1.000085]\n",
            "355 [D loss: 0.999970] [G loss: 1.000097]\n",
            "356 [D loss: 0.999972] [G loss: 1.000104]\n",
            "357 [D loss: 0.999981] [G loss: 1.000090]\n",
            "358 [D loss: 0.999982] [G loss: 1.000097]\n",
            "359 [D loss: 0.999966] [G loss: 1.000107]\n",
            "360 [D loss: 0.999970] [G loss: 1.000090]\n",
            "361 [D loss: 0.999973] [G loss: 1.000085]\n",
            "362 [D loss: 0.999969] [G loss: 1.000109]\n",
            "363 [D loss: 0.999972] [G loss: 1.000113]\n",
            "364 [D loss: 0.999975] [G loss: 1.000090]\n",
            "365 [D loss: 0.999972] [G loss: 1.000082]\n",
            "366 [D loss: 0.999978] [G loss: 1.000069]\n",
            "367 [D loss: 0.999971] [G loss: 1.000091]\n",
            "368 [D loss: 0.999976] [G loss: 1.000102]\n",
            "369 [D loss: 0.999973] [G loss: 1.000096]\n",
            "370 [D loss: 0.999973] [G loss: 1.000110]\n",
            "371 [D loss: 0.999975] [G loss: 1.000122]\n",
            "372 [D loss: 0.999988] [G loss: 1.000086]\n",
            "373 [D loss: 0.999977] [G loss: 1.000091]\n",
            "374 [D loss: 0.999988] [G loss: 1.000092]\n",
            "375 [D loss: 0.999968] [G loss: 1.000104]\n",
            "376 [D loss: 0.999975] [G loss: 1.000108]\n",
            "377 [D loss: 0.999956] [G loss: 1.000098]\n",
            "378 [D loss: 0.999981] [G loss: 1.000086]\n",
            "379 [D loss: 0.999968] [G loss: 1.000090]\n",
            "380 [D loss: 0.999971] [G loss: 1.000080]\n",
            "381 [D loss: 0.999979] [G loss: 1.000093]\n",
            "382 [D loss: 0.999976] [G loss: 1.000083]\n",
            "383 [D loss: 0.999974] [G loss: 1.000088]\n",
            "384 [D loss: 0.999985] [G loss: 1.000069]\n",
            "385 [D loss: 0.999975] [G loss: 1.000093]\n",
            "386 [D loss: 0.999973] [G loss: 1.000085]\n",
            "387 [D loss: 0.999959] [G loss: 1.000094]\n",
            "388 [D loss: 0.999973] [G loss: 1.000089]\n",
            "389 [D loss: 0.999981] [G loss: 1.000081]\n",
            "390 [D loss: 0.999977] [G loss: 1.000093]\n",
            "391 [D loss: 0.999992] [G loss: 1.000071]\n",
            "392 [D loss: 0.999960] [G loss: 1.000094]\n",
            "393 [D loss: 0.999964] [G loss: 1.000093]\n",
            "394 [D loss: 0.999986] [G loss: 1.000084]\n",
            "395 [D loss: 0.999990] [G loss: 1.000065]\n",
            "396 [D loss: 0.999985] [G loss: 1.000074]\n",
            "397 [D loss: 0.999980] [G loss: 1.000075]\n",
            "398 [D loss: 0.999972] [G loss: 1.000063]\n",
            "399 [D loss: 0.999969] [G loss: 1.000082]\n",
            "400 [D loss: 0.999979] [G loss: 1.000062]\n",
            "401 [D loss: 0.999963] [G loss: 1.000079]\n",
            "402 [D loss: 0.999979] [G loss: 1.000070]\n",
            "403 [D loss: 0.999986] [G loss: 1.000067]\n",
            "404 [D loss: 0.999974] [G loss: 1.000077]\n",
            "405 [D loss: 0.999978] [G loss: 1.000061]\n",
            "406 [D loss: 0.999957] [G loss: 1.000074]\n",
            "407 [D loss: 0.999984] [G loss: 1.000065]\n",
            "408 [D loss: 0.999978] [G loss: 1.000092]\n",
            "409 [D loss: 0.999963] [G loss: 1.000076]\n",
            "410 [D loss: 0.999987] [G loss: 1.000076]\n",
            "411 [D loss: 0.999983] [G loss: 1.000098]\n",
            "412 [D loss: 0.999966] [G loss: 1.000096]\n",
            "413 [D loss: 0.999963] [G loss: 1.000077]\n",
            "414 [D loss: 0.999976] [G loss: 1.000075]\n",
            "415 [D loss: 0.999959] [G loss: 1.000088]\n",
            "416 [D loss: 0.999974] [G loss: 1.000082]\n",
            "417 [D loss: 0.999965] [G loss: 1.000078]\n",
            "418 [D loss: 0.999962] [G loss: 1.000081]\n",
            "419 [D loss: 0.999959] [G loss: 1.000090]\n",
            "420 [D loss: 0.999959] [G loss: 1.000099]\n",
            "421 [D loss: 0.999973] [G loss: 1.000076]\n",
            "422 [D loss: 0.999964] [G loss: 1.000067]\n",
            "423 [D loss: 0.999966] [G loss: 1.000063]\n",
            "424 [D loss: 0.999980] [G loss: 1.000075]\n",
            "425 [D loss: 0.999971] [G loss: 1.000092]\n",
            "426 [D loss: 0.999959] [G loss: 1.000080]\n",
            "427 [D loss: 0.999981] [G loss: 1.000064]\n",
            "428 [D loss: 0.999972] [G loss: 1.000067]\n",
            "429 [D loss: 0.999972] [G loss: 1.000079]\n",
            "430 [D loss: 0.999970] [G loss: 1.000072]\n",
            "431 [D loss: 0.999964] [G loss: 1.000097]\n",
            "432 [D loss: 0.999958] [G loss: 1.000081]\n",
            "433 [D loss: 0.999978] [G loss: 1.000076]\n",
            "434 [D loss: 0.999969] [G loss: 1.000084]\n",
            "435 [D loss: 0.999977] [G loss: 1.000075]\n",
            "436 [D loss: 0.999984] [G loss: 1.000067]\n",
            "437 [D loss: 0.999973] [G loss: 1.000074]\n",
            "438 [D loss: 0.999974] [G loss: 1.000077]\n",
            "439 [D loss: 0.999962] [G loss: 1.000065]\n",
            "440 [D loss: 0.999986] [G loss: 1.000068]\n",
            "441 [D loss: 0.999969] [G loss: 1.000074]\n",
            "442 [D loss: 0.999970] [G loss: 1.000070]\n",
            "443 [D loss: 0.999972] [G loss: 1.000073]\n",
            "444 [D loss: 0.999981] [G loss: 1.000098]\n",
            "445 [D loss: 0.999977] [G loss: 1.000062]\n",
            "446 [D loss: 0.999968] [G loss: 1.000079]\n",
            "447 [D loss: 0.999981] [G loss: 1.000069]\n",
            "448 [D loss: 0.999972] [G loss: 1.000081]\n",
            "449 [D loss: 0.999986] [G loss: 1.000092]\n",
            "450 [D loss: 0.999965] [G loss: 1.000095]\n",
            "451 [D loss: 0.999962] [G loss: 1.000091]\n",
            "452 [D loss: 0.999971] [G loss: 1.000097]\n",
            "453 [D loss: 0.999971] [G loss: 1.000084]\n",
            "454 [D loss: 0.999978] [G loss: 1.000078]\n",
            "455 [D loss: 0.999960] [G loss: 1.000069]\n",
            "456 [D loss: 0.999961] [G loss: 1.000085]\n",
            "457 [D loss: 0.999975] [G loss: 1.000078]\n",
            "458 [D loss: 0.999972] [G loss: 1.000093]\n",
            "459 [D loss: 0.999972] [G loss: 1.000096]\n",
            "460 [D loss: 0.999973] [G loss: 1.000078]\n",
            "461 [D loss: 0.999971] [G loss: 1.000091]\n",
            "462 [D loss: 0.999977] [G loss: 1.000066]\n",
            "463 [D loss: 0.999987] [G loss: 1.000069]\n",
            "464 [D loss: 0.999987] [G loss: 1.000076]\n",
            "465 [D loss: 0.999974] [G loss: 1.000089]\n",
            "466 [D loss: 0.999956] [G loss: 1.000079]\n",
            "467 [D loss: 0.999959] [G loss: 1.000094]\n",
            "468 [D loss: 0.999956] [G loss: 1.000062]\n",
            "469 [D loss: 0.999967] [G loss: 1.000072]\n",
            "470 [D loss: 0.999980] [G loss: 1.000061]\n",
            "471 [D loss: 0.999970] [G loss: 1.000068]\n",
            "472 [D loss: 0.999973] [G loss: 1.000080]\n",
            "473 [D loss: 0.999962] [G loss: 1.000082]\n",
            "474 [D loss: 0.999973] [G loss: 1.000069]\n",
            "475 [D loss: 0.999964] [G loss: 1.000058]\n",
            "476 [D loss: 0.999972] [G loss: 1.000079]\n",
            "477 [D loss: 0.999977] [G loss: 1.000079]\n",
            "478 [D loss: 0.999963] [G loss: 1.000087]\n",
            "479 [D loss: 0.999955] [G loss: 1.000071]\n",
            "480 [D loss: 0.999977] [G loss: 1.000096]\n",
            "481 [D loss: 0.999962] [G loss: 1.000091]\n",
            "482 [D loss: 0.999966] [G loss: 1.000095]\n",
            "483 [D loss: 0.999953] [G loss: 1.000105]\n",
            "484 [D loss: 0.999972] [G loss: 1.000095]\n",
            "485 [D loss: 0.999969] [G loss: 1.000073]\n",
            "486 [D loss: 0.999978] [G loss: 1.000091]\n",
            "487 [D loss: 0.999978] [G loss: 1.000075]\n",
            "488 [D loss: 0.999969] [G loss: 1.000089]\n",
            "489 [D loss: 0.999982] [G loss: 1.000080]\n",
            "490 [D loss: 0.999986] [G loss: 1.000071]\n",
            "491 [D loss: 0.999957] [G loss: 1.000071]\n",
            "492 [D loss: 0.999967] [G loss: 1.000074]\n",
            "493 [D loss: 0.999967] [G loss: 1.000079]\n",
            "494 [D loss: 0.999983] [G loss: 1.000079]\n",
            "495 [D loss: 0.999968] [G loss: 1.000089]\n",
            "496 [D loss: 0.999973] [G loss: 1.000085]\n",
            "497 [D loss: 0.999981] [G loss: 1.000066]\n",
            "498 [D loss: 0.999984] [G loss: 1.000065]\n",
            "499 [D loss: 0.999978] [G loss: 1.000078]\n",
            "500 [D loss: 0.999980] [G loss: 1.000056]\n",
            "501 [D loss: 0.999965] [G loss: 1.000067]\n",
            "502 [D loss: 0.999981] [G loss: 1.000077]\n",
            "503 [D loss: 0.999977] [G loss: 1.000069]\n",
            "504 [D loss: 0.999964] [G loss: 1.000086]\n",
            "505 [D loss: 0.999973] [G loss: 1.000079]\n",
            "506 [D loss: 0.999967] [G loss: 1.000080]\n",
            "507 [D loss: 0.999975] [G loss: 1.000075]\n",
            "508 [D loss: 0.999967] [G loss: 1.000056]\n",
            "509 [D loss: 0.999970] [G loss: 1.000063]\n",
            "510 [D loss: 0.999987] [G loss: 1.000069]\n",
            "511 [D loss: 0.999962] [G loss: 1.000053]\n",
            "512 [D loss: 0.999977] [G loss: 1.000086]\n",
            "513 [D loss: 0.999974] [G loss: 1.000082]\n",
            "514 [D loss: 0.999973] [G loss: 1.000093]\n",
            "515 [D loss: 0.999972] [G loss: 1.000059]\n",
            "516 [D loss: 0.999987] [G loss: 1.000088]\n",
            "517 [D loss: 0.999963] [G loss: 1.000071]\n",
            "518 [D loss: 0.999988] [G loss: 1.000067]\n",
            "519 [D loss: 0.999979] [G loss: 1.000056]\n",
            "520 [D loss: 0.999984] [G loss: 1.000075]\n",
            "521 [D loss: 0.999958] [G loss: 1.000063]\n",
            "522 [D loss: 0.999987] [G loss: 1.000062]\n",
            "523 [D loss: 0.999977] [G loss: 1.000065]\n",
            "524 [D loss: 0.999967] [G loss: 1.000084]\n",
            "525 [D loss: 0.999973] [G loss: 1.000063]\n",
            "526 [D loss: 0.999977] [G loss: 1.000060]\n",
            "527 [D loss: 0.999996] [G loss: 1.000069]\n",
            "528 [D loss: 0.999993] [G loss: 1.000082]\n",
            "529 [D loss: 0.999983] [G loss: 1.000059]\n",
            "530 [D loss: 1.000015] [G loss: 1.000057]\n",
            "531 [D loss: 1.000035] [G loss: 1.000030]\n",
            "532 [D loss: 1.000036] [G loss: 1.000044]\n",
            "533 [D loss: 1.000036] [G loss: 1.000061]\n",
            "534 [D loss: 1.000074] [G loss: 1.000037]\n",
            "535 [D loss: 1.000112] [G loss: 1.000058]\n",
            "536 [D loss: 1.000155] [G loss: 1.000222]\n",
            "537 [D loss: 1.000190] [G loss: 1.000377]\n",
            "538 [D loss: 1.000233] [G loss: 1.000435]\n",
            "539 [D loss: 1.000318] [G loss: 1.000577]\n",
            "540 [D loss: 1.000297] [G loss: 1.000565]\n",
            "541 [D loss: 1.000410] [G loss: 1.000799]\n",
            "542 [D loss: 1.000495] [G loss: 1.000817]\n",
            "543 [D loss: 1.000591] [G loss: 1.000796]\n",
            "544 [D loss: 1.000678] [G loss: 1.000844]\n",
            "545 [D loss: 1.000683] [G loss: 1.000950]\n",
            "546 [D loss: 1.000821] [G loss: 1.000877]\n",
            "547 [D loss: 1.000878] [G loss: 1.000941]\n",
            "548 [D loss: 1.000839] [G loss: 1.000677]\n",
            "549 [D loss: 1.001083] [G loss: 1.000627]\n",
            "550 [D loss: 1.000754] [G loss: 1.000503]\n",
            "551 [D loss: 1.000693] [G loss: 1.000540]\n",
            "552 [D loss: 1.001129] [G loss: 1.000536]\n",
            "553 [D loss: 1.001119] [G loss: 1.000420]\n",
            "554 [D loss: 1.001185] [G loss: 1.000340]\n",
            "555 [D loss: 1.000971] [G loss: 1.000415]\n",
            "556 [D loss: 1.001208] [G loss: 1.000194]\n",
            "557 [D loss: 1.001235] [G loss: 1.000268]\n",
            "558 [D loss: 1.001235] [G loss: 1.000253]\n",
            "559 [D loss: 1.001233] [G loss: 1.000204]\n",
            "560 [D loss: 1.001311] [G loss: 1.000048]\n",
            "561 [D loss: 1.001666] [G loss: 1.000009]\n",
            "562 [D loss: 1.001411] [G loss: 0.999981]\n",
            "563 [D loss: 1.001846] [G loss: 0.999962]\n",
            "564 [D loss: 1.001159] [G loss: 0.999834]\n",
            "565 [D loss: 1.001761] [G loss: 0.999874]\n",
            "566 [D loss: 1.001496] [G loss: 0.999724]\n",
            "567 [D loss: 1.001485] [G loss: 0.999760]\n",
            "568 [D loss: 1.001160] [G loss: 0.999678]\n",
            "569 [D loss: 1.001154] [G loss: 0.999807]\n",
            "570 [D loss: 1.001591] [G loss: 0.999842]\n",
            "571 [D loss: 1.001256] [G loss: 0.999744]\n",
            "572 [D loss: 1.001313] [G loss: 0.999850]\n",
            "573 [D loss: 1.001291] [G loss: 0.999815]\n",
            "574 [D loss: 1.001465] [G loss: 0.999659]\n",
            "575 [D loss: 1.001966] [G loss: 0.999365]\n",
            "576 [D loss: 1.001698] [G loss: 0.999220]\n",
            "577 [D loss: 1.002068] [G loss: 0.999383]\n",
            "578 [D loss: 1.001904] [G loss: 0.999140]\n",
            "579 [D loss: 1.002307] [G loss: 0.999158]\n",
            "580 [D loss: 1.001926] [G loss: 0.999146]\n",
            "581 [D loss: 1.001449] [G loss: 0.999007]\n",
            "582 [D loss: 1.001892] [G loss: 0.999126]\n",
            "583 [D loss: 1.001987] [G loss: 0.998979]\n",
            "584 [D loss: 1.002370] [G loss: 0.998843]\n",
            "585 [D loss: 1.002297] [G loss: 0.998546]\n",
            "586 [D loss: 1.002399] [G loss: 0.998392]\n",
            "587 [D loss: 1.002311] [G loss: 0.998240]\n",
            "588 [D loss: 1.002267] [G loss: 0.998169]\n",
            "589 [D loss: 1.002412] [G loss: 0.998007]\n",
            "590 [D loss: 1.002782] [G loss: 0.997833]\n",
            "591 [D loss: 1.003067] [G loss: 0.997820]\n",
            "592 [D loss: 1.002363] [G loss: 0.997849]\n",
            "593 [D loss: 1.001778] [G loss: 0.997972]\n",
            "594 [D loss: 1.001445] [G loss: 0.998157]\n",
            "595 [D loss: 1.001239] [G loss: 0.998727]\n",
            "596 [D loss: 1.001334] [G loss: 0.998916]\n",
            "597 [D loss: 1.000978] [G loss: 0.999021]\n",
            "598 [D loss: 1.001449] [G loss: 0.999163]\n",
            "599 [D loss: 1.001181] [G loss: 0.999157]\n",
            "600 [D loss: 1.001447] [G loss: 0.999161]\n",
            "601 [D loss: 1.001001] [G loss: 0.999571]\n",
            "602 [D loss: 1.001426] [G loss: 0.999501]\n",
            "603 [D loss: 1.001549] [G loss: 0.999767]\n",
            "604 [D loss: 1.001001] [G loss: 1.000180]\n",
            "605 [D loss: 1.001218] [G loss: 1.000251]\n",
            "606 [D loss: 1.000965] [G loss: 1.000428]\n",
            "607 [D loss: 1.000726] [G loss: 1.000667]\n",
            "608 [D loss: 1.000956] [G loss: 1.000697]\n",
            "609 [D loss: 1.000954] [G loss: 1.000858]\n",
            "610 [D loss: 1.000425] [G loss: 1.000907]\n",
            "611 [D loss: 1.000869] [G loss: 1.000925]\n",
            "612 [D loss: 1.000864] [G loss: 1.001119]\n",
            "613 [D loss: 1.000802] [G loss: 1.001170]\n",
            "614 [D loss: 1.000962] [G loss: 1.000922]\n",
            "615 [D loss: 1.000749] [G loss: 1.001204]\n",
            "616 [D loss: 1.000897] [G loss: 1.001023]\n",
            "617 [D loss: 1.001075] [G loss: 1.001107]\n",
            "618 [D loss: 1.001112] [G loss: 1.000985]\n",
            "619 [D loss: 1.001368] [G loss: 1.001089]\n",
            "620 [D loss: 1.001521] [G loss: 1.001144]\n",
            "621 [D loss: 1.001408] [G loss: 1.001060]\n",
            "622 [D loss: 1.001290] [G loss: 1.001237]\n",
            "623 [D loss: 1.001515] [G loss: 1.001087]\n",
            "624 [D loss: 1.001604] [G loss: 1.001237]\n",
            "625 [D loss: 1.001488] [G loss: 1.001247]\n",
            "626 [D loss: 1.001478] [G loss: 1.001128]\n",
            "627 [D loss: 1.001666] [G loss: 1.001203]\n",
            "628 [D loss: 1.001606] [G loss: 1.001369]\n",
            "629 [D loss: 1.001619] [G loss: 1.001265]\n",
            "630 [D loss: 1.001562] [G loss: 1.001004]\n",
            "631 [D loss: 1.001739] [G loss: 1.001149]\n",
            "632 [D loss: 1.001943] [G loss: 1.001267]\n",
            "633 [D loss: 1.001894] [G loss: 1.001105]\n",
            "634 [D loss: 1.001721] [G loss: 1.001081]\n",
            "635 [D loss: 1.001768] [G loss: 1.000832]\n",
            "636 [D loss: 1.001891] [G loss: 1.000689]\n",
            "637 [D loss: 1.002288] [G loss: 1.000524]\n",
            "638 [D loss: 1.002497] [G loss: 1.000105]\n",
            "639 [D loss: 1.002768] [G loss: 0.999978]\n",
            "640 [D loss: 1.003119] [G loss: 0.999675]\n",
            "641 [D loss: 1.002985] [G loss: 0.999450]\n",
            "642 [D loss: 1.003191] [G loss: 0.999287]\n",
            "643 [D loss: 1.003234] [G loss: 0.999271]\n",
            "644 [D loss: 1.002909] [G loss: 0.999868]\n",
            "645 [D loss: 1.003302] [G loss: 0.999733]\n",
            "646 [D loss: 1.002670] [G loss: 1.000447]\n",
            "647 [D loss: 1.002890] [G loss: 1.000772]\n",
            "648 [D loss: 1.002724] [G loss: 1.000265]\n",
            "649 [D loss: 1.003066] [G loss: 1.000396]\n",
            "650 [D loss: 1.003002] [G loss: 1.000161]\n",
            "651 [D loss: 1.002995] [G loss: 0.999940]\n",
            "652 [D loss: 1.002754] [G loss: 0.999440]\n",
            "653 [D loss: 1.003235] [G loss: 0.999076]\n",
            "654 [D loss: 1.003033] [G loss: 0.999360]\n",
            "655 [D loss: 1.003171] [G loss: 0.998995]\n",
            "656 [D loss: 1.003361] [G loss: 0.998920]\n",
            "657 [D loss: 1.003522] [G loss: 0.998575]\n",
            "658 [D loss: 1.003392] [G loss: 0.998899]\n",
            "659 [D loss: 1.003381] [G loss: 0.998957]\n",
            "660 [D loss: 1.003551] [G loss: 0.999658]\n",
            "661 [D loss: 1.002878] [G loss: 0.999965]\n",
            "662 [D loss: 1.002286] [G loss: 1.000886]\n",
            "663 [D loss: 1.002173] [G loss: 1.001722]\n",
            "664 [D loss: 1.001879] [G loss: 1.002457]\n",
            "665 [D loss: 1.001944] [G loss: 1.002986]\n",
            "666 [D loss: 1.001823] [G loss: 1.002983]\n",
            "667 [D loss: 1.001661] [G loss: 1.002979]\n",
            "668 [D loss: 1.001239] [G loss: 1.003225]\n",
            "669 [D loss: 1.001002] [G loss: 1.004396]\n",
            "670 [D loss: 1.000662] [G loss: 1.005780]\n",
            "671 [D loss: 0.999622] [G loss: 1.006952]\n",
            "672 [D loss: 0.999850] [G loss: 1.007518]\n",
            "673 [D loss: 0.999551] [G loss: 1.007458]\n",
            "674 [D loss: 0.999265] [G loss: 1.007222]\n",
            "675 [D loss: 0.999333] [G loss: 1.006930]\n",
            "676 [D loss: 0.999506] [G loss: 1.006587]\n",
            "677 [D loss: 0.999475] [G loss: 1.006221]\n",
            "678 [D loss: 0.999749] [G loss: 1.006110]\n",
            "679 [D loss: 0.999745] [G loss: 1.005769]\n",
            "680 [D loss: 0.999734] [G loss: 1.005833]\n",
            "681 [D loss: 0.999986] [G loss: 1.005560]\n",
            "682 [D loss: 1.000075] [G loss: 1.005284]\n",
            "683 [D loss: 0.999927] [G loss: 1.005223]\n",
            "684 [D loss: 0.999991] [G loss: 1.004911]\n",
            "685 [D loss: 1.000083] [G loss: 1.004723]\n",
            "686 [D loss: 1.000165] [G loss: 1.004691]\n",
            "687 [D loss: 1.000080] [G loss: 1.004775]\n",
            "688 [D loss: 1.000372] [G loss: 1.004745]\n",
            "689 [D loss: 1.000173] [G loss: 1.004602]\n",
            "690 [D loss: 1.000282] [G loss: 1.004555]\n",
            "691 [D loss: 1.000167] [G loss: 1.004671]\n",
            "692 [D loss: 1.000221] [G loss: 1.004519]\n",
            "693 [D loss: 1.000285] [G loss: 1.004427]\n",
            "694 [D loss: 1.000331] [G loss: 1.004595]\n",
            "695 [D loss: 1.000351] [G loss: 1.004295]\n",
            "696 [D loss: 1.000449] [G loss: 1.004321]\n",
            "697 [D loss: 1.000380] [G loss: 1.004309]\n",
            "698 [D loss: 1.000355] [G loss: 1.003932]\n",
            "699 [D loss: 1.000529] [G loss: 1.003979]\n",
            "700 [D loss: 1.000510] [G loss: 1.004032]\n",
            "701 [D loss: 1.000601] [G loss: 1.003932]\n",
            "702 [D loss: 1.000685] [G loss: 1.003740]\n",
            "703 [D loss: 1.000806] [G loss: 1.003918]\n",
            "704 [D loss: 1.000717] [G loss: 1.003605]\n",
            "705 [D loss: 1.000937] [G loss: 1.003722]\n",
            "706 [D loss: 1.000646] [G loss: 1.003859]\n",
            "707 [D loss: 1.000469] [G loss: 1.003791]\n",
            "708 [D loss: 1.000541] [G loss: 1.004004]\n",
            "709 [D loss: 1.000251] [G loss: 1.004433]\n",
            "710 [D loss: 1.000268] [G loss: 1.004676]\n",
            "711 [D loss: 1.000093] [G loss: 1.004831]\n",
            "712 [D loss: 0.999950] [G loss: 1.005013]\n",
            "713 [D loss: 1.000092] [G loss: 1.005156]\n",
            "714 [D loss: 0.999992] [G loss: 1.005064]\n",
            "715 [D loss: 0.999891] [G loss: 1.005166]\n",
            "716 [D loss: 0.999998] [G loss: 1.005094]\n",
            "717 [D loss: 1.000008] [G loss: 1.005034]\n",
            "718 [D loss: 1.000029] [G loss: 1.004822]\n",
            "719 [D loss: 1.000046] [G loss: 1.004748]\n",
            "720 [D loss: 1.000319] [G loss: 1.004964]\n",
            "721 [D loss: 1.000162] [G loss: 1.004919]\n",
            "722 [D loss: 1.000194] [G loss: 1.004717]\n",
            "723 [D loss: 1.000438] [G loss: 1.004382]\n",
            "724 [D loss: 1.000447] [G loss: 1.004455]\n",
            "725 [D loss: 1.000473] [G loss: 1.004487]\n",
            "726 [D loss: 1.000510] [G loss: 1.004536]\n",
            "727 [D loss: 1.000547] [G loss: 1.004215]\n",
            "728 [D loss: 1.000914] [G loss: 1.004360]\n",
            "729 [D loss: 1.000705] [G loss: 1.004245]\n",
            "730 [D loss: 1.000808] [G loss: 1.003971]\n",
            "731 [D loss: 1.000856] [G loss: 1.004019]\n",
            "732 [D loss: 1.000838] [G loss: 1.003724]\n",
            "733 [D loss: 1.001359] [G loss: 1.003859]\n",
            "734 [D loss: 1.000934] [G loss: 1.003619]\n",
            "735 [D loss: 1.001343] [G loss: 1.003907]\n",
            "736 [D loss: 1.001537] [G loss: 1.003491]\n",
            "737 [D loss: 1.001473] [G loss: 1.003874]\n",
            "738 [D loss: 1.001067] [G loss: 1.004394]\n",
            "739 [D loss: 1.000625] [G loss: 1.005041]\n",
            "740 [D loss: 1.000736] [G loss: 1.005343]\n",
            "741 [D loss: 1.000377] [G loss: 1.005850]\n",
            "742 [D loss: 1.000117] [G loss: 1.006196]\n",
            "743 [D loss: 0.999550] [G loss: 1.006903]\n",
            "744 [D loss: 0.999656] [G loss: 1.006598]\n",
            "745 [D loss: 0.999608] [G loss: 1.006731]\n",
            "746 [D loss: 0.999780] [G loss: 1.006689]\n",
            "747 [D loss: 0.999402] [G loss: 1.006522]\n",
            "748 [D loss: 0.999537] [G loss: 1.006354]\n",
            "749 [D loss: 0.999706] [G loss: 1.006240]\n",
            "750 [D loss: 0.999553] [G loss: 1.005982]\n",
            "751 [D loss: 0.999795] [G loss: 1.005693]\n",
            "752 [D loss: 0.999715] [G loss: 1.005725]\n",
            "753 [D loss: 0.999803] [G loss: 1.005352]\n",
            "754 [D loss: 0.999733] [G loss: 1.005354]\n",
            "755 [D loss: 0.999838] [G loss: 1.005093]\n",
            "756 [D loss: 0.999854] [G loss: 1.005140]\n",
            "757 [D loss: 0.999786] [G loss: 1.004921]\n",
            "758 [D loss: 0.999729] [G loss: 1.004866]\n",
            "759 [D loss: 0.999901] [G loss: 1.004773]\n",
            "760 [D loss: 0.999889] [G loss: 1.004555]\n",
            "761 [D loss: 0.999968] [G loss: 1.004506]\n",
            "762 [D loss: 1.000004] [G loss: 1.004219]\n",
            "763 [D loss: 1.000114] [G loss: 1.004025]\n",
            "764 [D loss: 1.000213] [G loss: 1.003926]\n",
            "765 [D loss: 1.000130] [G loss: 1.003837]\n",
            "766 [D loss: 1.000287] [G loss: 1.003880]\n",
            "767 [D loss: 1.000208] [G loss: 1.003880]\n",
            "768 [D loss: 1.000139] [G loss: 1.003786]\n",
            "769 [D loss: 1.000090] [G loss: 1.003814]\n",
            "770 [D loss: 1.000035] [G loss: 1.003880]\n",
            "771 [D loss: 0.999875] [G loss: 1.004123]\n",
            "772 [D loss: 0.999782] [G loss: 1.004213]\n",
            "773 [D loss: 0.999817] [G loss: 1.004153]\n",
            "774 [D loss: 0.999913] [G loss: 1.004221]\n",
            "775 [D loss: 0.999674] [G loss: 1.004188]\n",
            "776 [D loss: 0.999944] [G loss: 1.004117]\n",
            "777 [D loss: 0.999715] [G loss: 1.004196]\n",
            "778 [D loss: 1.000028] [G loss: 1.003742]\n",
            "779 [D loss: 0.999935] [G loss: 1.003647]\n",
            "780 [D loss: 1.000060] [G loss: 1.003542]\n",
            "781 [D loss: 1.000087] [G loss: 1.003519]\n",
            "782 [D loss: 1.000224] [G loss: 1.003503]\n",
            "783 [D loss: 1.000141] [G loss: 1.003532]\n",
            "784 [D loss: 1.000284] [G loss: 1.003292]\n",
            "785 [D loss: 1.000163] [G loss: 1.003376]\n",
            "786 [D loss: 1.000209] [G loss: 1.003590]\n",
            "787 [D loss: 1.000210] [G loss: 1.003689]\n",
            "788 [D loss: 1.000144] [G loss: 1.003680]\n",
            "789 [D loss: 1.000191] [G loss: 1.003556]\n",
            "790 [D loss: 1.000204] [G loss: 1.003794]\n",
            "791 [D loss: 0.999932] [G loss: 1.003741]\n",
            "792 [D loss: 0.999751] [G loss: 1.003917]\n",
            "793 [D loss: 1.000095] [G loss: 1.003667]\n",
            "794 [D loss: 0.999750] [G loss: 1.003871]\n",
            "795 [D loss: 0.999770] [G loss: 1.003928]\n",
            "796 [D loss: 0.999730] [G loss: 1.003815]\n",
            "797 [D loss: 0.999734] [G loss: 1.003652]\n",
            "798 [D loss: 0.999897] [G loss: 1.003531]\n",
            "799 [D loss: 0.999783] [G loss: 1.003487]\n",
            "800 [D loss: 0.999820] [G loss: 1.003419]\n",
            "801 [D loss: 0.999793] [G loss: 1.003304]\n",
            "802 [D loss: 0.999970] [G loss: 1.003055]\n",
            "803 [D loss: 0.999875] [G loss: 1.003219]\n",
            "804 [D loss: 0.999888] [G loss: 1.003098]\n",
            "805 [D loss: 0.999985] [G loss: 1.002807]\n",
            "806 [D loss: 0.999910] [G loss: 1.002947]\n",
            "807 [D loss: 0.999936] [G loss: 1.002933]\n",
            "808 [D loss: 0.999835] [G loss: 1.002792]\n",
            "809 [D loss: 0.999892] [G loss: 1.002759]\n",
            "810 [D loss: 0.999819] [G loss: 1.002795]\n",
            "811 [D loss: 0.999915] [G loss: 1.002699]\n",
            "812 [D loss: 1.000017] [G loss: 1.002602]\n",
            "813 [D loss: 0.999933] [G loss: 1.002504]\n",
            "814 [D loss: 0.999956] [G loss: 1.002516]\n",
            "815 [D loss: 0.999980] [G loss: 1.002416]\n",
            "816 [D loss: 0.999990] [G loss: 1.002269]\n",
            "817 [D loss: 1.000069] [G loss: 1.002327]\n",
            "818 [D loss: 1.000136] [G loss: 1.002142]\n",
            "819 [D loss: 1.000000] [G loss: 1.002266]\n",
            "820 [D loss: 0.999964] [G loss: 1.002112]\n",
            "821 [D loss: 1.000055] [G loss: 1.002097]\n",
            "822 [D loss: 0.999898] [G loss: 1.002460]\n",
            "823 [D loss: 0.999980] [G loss: 1.002415]\n",
            "824 [D loss: 0.999899] [G loss: 1.002423]\n",
            "825 [D loss: 0.999835] [G loss: 1.002584]\n",
            "826 [D loss: 0.999810] [G loss: 1.002587]\n",
            "827 [D loss: 0.999820] [G loss: 1.002549]\n",
            "828 [D loss: 0.999812] [G loss: 1.002458]\n",
            "829 [D loss: 0.999902] [G loss: 1.002446]\n",
            "830 [D loss: 0.999813] [G loss: 1.002393]\n",
            "831 [D loss: 0.999875] [G loss: 1.002335]\n",
            "832 [D loss: 0.999890] [G loss: 1.002316]\n",
            "833 [D loss: 0.999899] [G loss: 1.002329]\n",
            "834 [D loss: 0.999933] [G loss: 1.002183]\n",
            "835 [D loss: 0.999896] [G loss: 1.002379]\n",
            "836 [D loss: 0.999905] [G loss: 1.002270]\n",
            "837 [D loss: 0.999932] [G loss: 1.002278]\n",
            "838 [D loss: 1.000028] [G loss: 1.002316]\n",
            "839 [D loss: 0.999961] [G loss: 1.002272]\n",
            "840 [D loss: 0.999876] [G loss: 1.002295]\n",
            "841 [D loss: 0.999973] [G loss: 1.002292]\n",
            "842 [D loss: 0.999832] [G loss: 1.002266]\n",
            "843 [D loss: 0.999991] [G loss: 1.002246]\n",
            "844 [D loss: 0.999868] [G loss: 1.002277]\n",
            "845 [D loss: 0.999948] [G loss: 1.002270]\n",
            "846 [D loss: 0.999925] [G loss: 1.002133]\n",
            "847 [D loss: 0.999941] [G loss: 1.002155]\n",
            "848 [D loss: 1.000005] [G loss: 1.002175]\n",
            "849 [D loss: 0.999914] [G loss: 1.002043]\n",
            "850 [D loss: 0.999865] [G loss: 1.001999]\n",
            "851 [D loss: 1.000009] [G loss: 1.002006]\n",
            "852 [D loss: 0.999976] [G loss: 1.001954]\n",
            "853 [D loss: 0.999882] [G loss: 1.001964]\n",
            "854 [D loss: 0.999934] [G loss: 1.001886]\n",
            "855 [D loss: 0.999869] [G loss: 1.001947]\n",
            "856 [D loss: 0.999824] [G loss: 1.001896]\n",
            "857 [D loss: 0.999887] [G loss: 1.001810]\n",
            "858 [D loss: 0.999901] [G loss: 1.001958]\n",
            "859 [D loss: 0.999890] [G loss: 1.001864]\n",
            "860 [D loss: 0.999858] [G loss: 1.001886]\n",
            "861 [D loss: 0.999887] [G loss: 1.001854]\n",
            "862 [D loss: 0.999871] [G loss: 1.001717]\n",
            "863 [D loss: 0.999858] [G loss: 1.001783]\n",
            "864 [D loss: 0.999911] [G loss: 1.001727]\n",
            "865 [D loss: 0.999896] [G loss: 1.001647]\n",
            "866 [D loss: 0.999853] [G loss: 1.001567]\n",
            "867 [D loss: 0.999896] [G loss: 1.001548]\n",
            "868 [D loss: 0.999928] [G loss: 1.001518]\n",
            "869 [D loss: 0.999946] [G loss: 1.001492]\n",
            "870 [D loss: 0.999977] [G loss: 1.001396]\n",
            "871 [D loss: 0.999982] [G loss: 1.001413]\n",
            "872 [D loss: 1.000000] [G loss: 1.001460]\n",
            "873 [D loss: 0.999942] [G loss: 1.001482]\n",
            "874 [D loss: 1.000016] [G loss: 1.001595]\n",
            "875 [D loss: 0.999997] [G loss: 1.001579]\n",
            "876 [D loss: 0.999925] [G loss: 1.001678]\n",
            "877 [D loss: 0.999962] [G loss: 1.001665]\n",
            "878 [D loss: 0.999935] [G loss: 1.001743]\n",
            "879 [D loss: 0.999862] [G loss: 1.001660]\n",
            "880 [D loss: 0.999897] [G loss: 1.001593]\n",
            "881 [D loss: 0.999918] [G loss: 1.001594]\n",
            "882 [D loss: 0.999899] [G loss: 1.001519]\n",
            "883 [D loss: 0.999913] [G loss: 1.001485]\n",
            "884 [D loss: 0.999939] [G loss: 1.001407]\n",
            "885 [D loss: 0.999909] [G loss: 1.001318]\n",
            "886 [D loss: 0.999934] [G loss: 1.001308]\n",
            "887 [D loss: 0.999917] [G loss: 1.001252]\n",
            "888 [D loss: 0.999915] [G loss: 1.001217]\n",
            "889 [D loss: 0.999925] [G loss: 1.001226]\n",
            "890 [D loss: 0.999935] [G loss: 1.001189]\n",
            "891 [D loss: 0.999937] [G loss: 1.001182]\n",
            "892 [D loss: 0.999933] [G loss: 1.001181]\n",
            "893 [D loss: 0.999962] [G loss: 1.001128]\n",
            "894 [D loss: 0.999926] [G loss: 1.001078]\n",
            "895 [D loss: 0.999941] [G loss: 1.001088]\n",
            "896 [D loss: 0.999930] [G loss: 1.001053]\n",
            "897 [D loss: 0.999946] [G loss: 1.001042]\n",
            "898 [D loss: 0.999965] [G loss: 1.000999]\n",
            "899 [D loss: 0.999960] [G loss: 1.001017]\n",
            "900 [D loss: 0.999978] [G loss: 1.000928]\n",
            "901 [D loss: 0.999950] [G loss: 1.000963]\n",
            "902 [D loss: 0.999922] [G loss: 1.001000]\n",
            "903 [D loss: 0.999973] [G loss: 1.000957]\n",
            "904 [D loss: 0.999936] [G loss: 1.000948]\n",
            "905 [D loss: 0.999964] [G loss: 1.000931]\n",
            "906 [D loss: 0.999963] [G loss: 1.000934]\n",
            "907 [D loss: 0.999944] [G loss: 1.000889]\n",
            "908 [D loss: 0.999977] [G loss: 1.000912]\n",
            "909 [D loss: 1.000008] [G loss: 1.000841]\n",
            "910 [D loss: 0.999978] [G loss: 1.000892]\n",
            "911 [D loss: 0.999996] [G loss: 1.000897]\n",
            "912 [D loss: 0.999989] [G loss: 1.000865]\n",
            "913 [D loss: 0.999981] [G loss: 1.000913]\n",
            "914 [D loss: 0.999955] [G loss: 1.000894]\n",
            "915 [D loss: 0.999947] [G loss: 1.000879]\n",
            "916 [D loss: 0.999911] [G loss: 1.000906]\n",
            "917 [D loss: 0.999933] [G loss: 1.000897]\n",
            "918 [D loss: 0.999963] [G loss: 1.000898]\n",
            "919 [D loss: 0.999908] [G loss: 1.000906]\n",
            "920 [D loss: 0.999928] [G loss: 1.000861]\n",
            "921 [D loss: 0.999917] [G loss: 1.000855]\n",
            "922 [D loss: 0.999932] [G loss: 1.000856]\n",
            "923 [D loss: 0.999962] [G loss: 1.000820]\n",
            "924 [D loss: 0.999925] [G loss: 1.000803]\n",
            "925 [D loss: 0.999933] [G loss: 1.000792]\n",
            "926 [D loss: 0.999937] [G loss: 1.000762]\n",
            "927 [D loss: 0.999932] [G loss: 1.000734]\n",
            "928 [D loss: 0.999934] [G loss: 1.000749]\n",
            "929 [D loss: 0.999939] [G loss: 1.000698]\n",
            "930 [D loss: 0.999979] [G loss: 1.000719]\n",
            "931 [D loss: 0.999955] [G loss: 1.000711]\n",
            "932 [D loss: 1.000003] [G loss: 1.000686]\n",
            "933 [D loss: 1.000012] [G loss: 1.000714]\n",
            "934 [D loss: 1.000036] [G loss: 1.000705]\n",
            "935 [D loss: 1.000010] [G loss: 1.000689]\n",
            "936 [D loss: 1.000003] [G loss: 1.000742]\n",
            "937 [D loss: 1.000007] [G loss: 1.000728]\n",
            "938 [D loss: 0.999998] [G loss: 1.000810]\n",
            "939 [D loss: 1.000007] [G loss: 1.000796]\n",
            "940 [D loss: 1.000030] [G loss: 1.000766]\n",
            "941 [D loss: 1.000001] [G loss: 1.000790]\n",
            "942 [D loss: 0.999966] [G loss: 1.000782]\n",
            "943 [D loss: 1.000006] [G loss: 1.000774]\n",
            "944 [D loss: 0.999940] [G loss: 1.000818]\n",
            "945 [D loss: 0.999998] [G loss: 1.000865]\n",
            "946 [D loss: 0.999947] [G loss: 1.000840]\n",
            "947 [D loss: 0.999933] [G loss: 1.000787]\n",
            "948 [D loss: 0.999942] [G loss: 1.000818]\n",
            "949 [D loss: 0.999961] [G loss: 1.000775]\n",
            "950 [D loss: 0.999883] [G loss: 1.000790]\n",
            "951 [D loss: 0.999928] [G loss: 1.000781]\n",
            "952 [D loss: 0.999938] [G loss: 1.000773]\n",
            "953 [D loss: 0.999926] [G loss: 1.000781]\n",
            "954 [D loss: 0.999947] [G loss: 1.000726]\n",
            "955 [D loss: 0.999957] [G loss: 1.000721]\n",
            "956 [D loss: 0.999922] [G loss: 1.000691]\n",
            "957 [D loss: 0.999925] [G loss: 1.000662]\n",
            "958 [D loss: 0.999972] [G loss: 1.000642]\n",
            "959 [D loss: 0.999968] [G loss: 1.000622]\n",
            "960 [D loss: 0.999971] [G loss: 1.000618]\n",
            "961 [D loss: 0.999977] [G loss: 1.000608]\n",
            "962 [D loss: 0.999946] [G loss: 1.000634]\n",
            "963 [D loss: 0.999964] [G loss: 1.000583]\n",
            "964 [D loss: 0.999985] [G loss: 1.000574]\n",
            "965 [D loss: 0.999979] [G loss: 1.000559]\n",
            "966 [D loss: 0.999979] [G loss: 1.000572]\n",
            "967 [D loss: 0.999949] [G loss: 1.000556]\n",
            "968 [D loss: 0.999965] [G loss: 1.000573]\n",
            "969 [D loss: 0.999969] [G loss: 1.000574]\n",
            "970 [D loss: 0.999985] [G loss: 1.000582]\n",
            "971 [D loss: 0.999984] [G loss: 1.000569]\n",
            "972 [D loss: 0.999972] [G loss: 1.000616]\n",
            "973 [D loss: 0.999973] [G loss: 1.000611]\n",
            "974 [D loss: 1.000004] [G loss: 1.000619]\n",
            "975 [D loss: 0.999962] [G loss: 1.000612]\n",
            "976 [D loss: 1.000007] [G loss: 1.000625]\n",
            "977 [D loss: 0.999995] [G loss: 1.000597]\n",
            "978 [D loss: 0.999976] [G loss: 1.000624]\n",
            "979 [D loss: 0.999973] [G loss: 1.000612]\n",
            "980 [D loss: 0.999956] [G loss: 1.000604]\n",
            "981 [D loss: 0.999954] [G loss: 1.000592]\n",
            "982 [D loss: 0.999979] [G loss: 1.000574]\n",
            "983 [D loss: 0.999976] [G loss: 1.000626]\n",
            "984 [D loss: 0.999986] [G loss: 1.000596]\n",
            "985 [D loss: 1.000031] [G loss: 1.000534]\n",
            "986 [D loss: 0.999982] [G loss: 1.000592]\n",
            "987 [D loss: 0.999994] [G loss: 1.000563]\n",
            "988 [D loss: 0.999972] [G loss: 1.000519]\n",
            "989 [D loss: 0.999996] [G loss: 1.000543]\n",
            "990 [D loss: 0.999948] [G loss: 1.000557]\n",
            "991 [D loss: 0.999944] [G loss: 1.000518]\n",
            "992 [D loss: 1.000017] [G loss: 1.000488]\n",
            "993 [D loss: 0.999950] [G loss: 1.000502]\n",
            "994 [D loss: 0.999986] [G loss: 1.000510]\n",
            "995 [D loss: 0.999944] [G loss: 1.000488]\n",
            "996 [D loss: 0.999958] [G loss: 1.000477]\n",
            "997 [D loss: 0.999903] [G loss: 1.000480]\n",
            "998 [D loss: 0.999938] [G loss: 1.000448]\n",
            "999 [D loss: 0.999958] [G loss: 1.000463]\n",
            "1000 [D loss: 0.999935] [G loss: 1.000429]\n",
            "1001 [D loss: 0.999949] [G loss: 1.000391]\n",
            "1002 [D loss: 0.999962] [G loss: 1.000398]\n",
            "1003 [D loss: 0.999951] [G loss: 1.000389]\n",
            "1004 [D loss: 0.999962] [G loss: 1.000391]\n",
            "1005 [D loss: 0.999967] [G loss: 1.000350]\n",
            "1006 [D loss: 1.000006] [G loss: 1.000392]\n",
            "1007 [D loss: 0.999978] [G loss: 1.000376]\n",
            "1008 [D loss: 0.999981] [G loss: 1.000353]\n",
            "1009 [D loss: 0.999984] [G loss: 1.000355]\n",
            "1010 [D loss: 0.999979] [G loss: 1.000355]\n",
            "1011 [D loss: 1.000024] [G loss: 1.000354]\n",
            "1012 [D loss: 1.000014] [G loss: 1.000336]\n",
            "1013 [D loss: 1.000022] [G loss: 1.000325]\n",
            "1014 [D loss: 0.999990] [G loss: 1.000327]\n",
            "1015 [D loss: 1.000017] [G loss: 1.000311]\n",
            "1016 [D loss: 0.999987] [G loss: 1.000374]\n",
            "1017 [D loss: 0.999996] [G loss: 1.000374]\n",
            "1018 [D loss: 0.999995] [G loss: 1.000373]\n",
            "1019 [D loss: 1.000017] [G loss: 1.000346]\n",
            "1020 [D loss: 1.000019] [G loss: 1.000305]\n",
            "1021 [D loss: 0.999943] [G loss: 1.000418]\n",
            "1022 [D loss: 0.999971] [G loss: 1.000434]\n",
            "1023 [D loss: 1.000004] [G loss: 1.000403]\n",
            "1024 [D loss: 0.999991] [G loss: 1.000381]\n",
            "1025 [D loss: 0.999987] [G loss: 1.000407]\n",
            "1026 [D loss: 1.000018] [G loss: 1.000345]\n",
            "1027 [D loss: 0.999979] [G loss: 1.000289]\n",
            "1028 [D loss: 0.999994] [G loss: 1.000279]\n",
            "1029 [D loss: 1.000001] [G loss: 1.000267]\n",
            "1030 [D loss: 1.000047] [G loss: 1.000255]\n",
            "1031 [D loss: 0.999997] [G loss: 1.000261]\n",
            "1032 [D loss: 1.000035] [G loss: 1.000226]\n",
            "1033 [D loss: 0.999991] [G loss: 1.000274]\n",
            "1034 [D loss: 1.000065] [G loss: 1.000301]\n",
            "1035 [D loss: 1.000030] [G loss: 1.000268]\n",
            "1036 [D loss: 1.000003] [G loss: 1.000291]\n",
            "1037 [D loss: 0.999972] [G loss: 1.000272]\n",
            "1038 [D loss: 0.999988] [G loss: 1.000195]\n",
            "1039 [D loss: 0.999996] [G loss: 1.000196]\n",
            "1040 [D loss: 0.999962] [G loss: 1.000171]\n",
            "1041 [D loss: 1.000062] [G loss: 1.000150]\n",
            "1042 [D loss: 1.000037] [G loss: 1.000096]\n",
            "1043 [D loss: 0.999992] [G loss: 1.000116]\n",
            "1044 [D loss: 1.000058] [G loss: 1.000100]\n",
            "1045 [D loss: 1.000010] [G loss: 1.000147]\n",
            "1046 [D loss: 0.999922] [G loss: 1.000174]\n",
            "1047 [D loss: 0.999914] [G loss: 1.000248]\n",
            "1048 [D loss: 0.999973] [G loss: 1.000231]\n",
            "1049 [D loss: 0.999969] [G loss: 1.000172]\n",
            "1050 [D loss: 1.000011] [G loss: 1.000219]\n",
            "1051 [D loss: 1.000003] [G loss: 1.000140]\n",
            "1052 [D loss: 1.000019] [G loss: 1.000097]\n",
            "1053 [D loss: 1.000001] [G loss: 1.000056]\n",
            "1054 [D loss: 1.000021] [G loss: 1.000006]\n",
            "1055 [D loss: 1.000001] [G loss: 1.000069]\n",
            "1056 [D loss: 1.000046] [G loss: 0.999971]\n",
            "1057 [D loss: 1.000080] [G loss: 0.999967]\n",
            "1058 [D loss: 0.999973] [G loss: 1.000048]\n",
            "1059 [D loss: 0.999949] [G loss: 1.000154]\n",
            "1060 [D loss: 1.000016] [G loss: 1.000168]\n",
            "1061 [D loss: 0.999927] [G loss: 1.000197]\n",
            "1062 [D loss: 0.999930] [G loss: 1.000208]\n",
            "1063 [D loss: 0.999931] [G loss: 1.000202]\n",
            "1064 [D loss: 0.999937] [G loss: 1.000185]\n",
            "1065 [D loss: 0.999947] [G loss: 1.000176]\n",
            "1066 [D loss: 0.999947] [G loss: 1.000153]\n",
            "1067 [D loss: 0.999958] [G loss: 1.000129]\n",
            "1068 [D loss: 0.999966] [G loss: 1.000110]\n",
            "1069 [D loss: 0.999962] [G loss: 1.000101]\n",
            "1070 [D loss: 0.999979] [G loss: 1.000062]\n",
            "1071 [D loss: 1.000021] [G loss: 1.000038]\n",
            "1072 [D loss: 1.000018] [G loss: 0.999982]\n",
            "1073 [D loss: 1.000052] [G loss: 0.999974]\n",
            "1074 [D loss: 1.000021] [G loss: 0.999991]\n",
            "1075 [D loss: 1.000023] [G loss: 1.000094]\n",
            "1076 [D loss: 1.000003] [G loss: 1.000095]\n",
            "1077 [D loss: 0.999991] [G loss: 1.000105]\n",
            "1078 [D loss: 1.000019] [G loss: 1.000114]\n",
            "1079 [D loss: 1.000001] [G loss: 1.000108]\n",
            "1080 [D loss: 0.999986] [G loss: 1.000132]\n",
            "1081 [D loss: 1.000001] [G loss: 1.000127]\n",
            "1082 [D loss: 1.000010] [G loss: 1.000117]\n",
            "1083 [D loss: 1.000005] [G loss: 1.000124]\n",
            "1084 [D loss: 1.000001] [G loss: 1.000108]\n",
            "1085 [D loss: 0.999987] [G loss: 1.000125]\n",
            "1086 [D loss: 1.000027] [G loss: 1.000102]\n",
            "1087 [D loss: 0.999991] [G loss: 1.000156]\n",
            "1088 [D loss: 0.999997] [G loss: 1.000162]\n",
            "1089 [D loss: 1.000034] [G loss: 1.000125]\n",
            "1090 [D loss: 0.999992] [G loss: 1.000160]\n",
            "1091 [D loss: 1.000002] [G loss: 1.000155]\n",
            "1092 [D loss: 0.999985] [G loss: 1.000151]\n",
            "1093 [D loss: 1.000021] [G loss: 1.000174]\n",
            "1094 [D loss: 0.999986] [G loss: 1.000157]\n",
            "1095 [D loss: 0.999992] [G loss: 1.000163]\n",
            "1096 [D loss: 1.000009] [G loss: 1.000138]\n",
            "1097 [D loss: 1.000002] [G loss: 1.000195]\n",
            "1098 [D loss: 0.999984] [G loss: 1.000203]\n",
            "1099 [D loss: 0.999982] [G loss: 1.000218]\n",
            "1100 [D loss: 1.000023] [G loss: 1.000157]\n",
            "1101 [D loss: 0.999989] [G loss: 1.000223]\n",
            "1102 [D loss: 1.000023] [G loss: 1.000151]\n",
            "1103 [D loss: 0.999994] [G loss: 1.000169]\n",
            "1104 [D loss: 1.000017] [G loss: 1.000145]\n",
            "1105 [D loss: 1.000027] [G loss: 1.000133]\n",
            "1106 [D loss: 1.000008] [G loss: 1.000168]\n",
            "1107 [D loss: 1.000008] [G loss: 1.000113]\n",
            "1108 [D loss: 0.999987] [G loss: 1.000150]\n",
            "1109 [D loss: 1.000023] [G loss: 1.000129]\n",
            "1110 [D loss: 1.000007] [G loss: 1.000236]\n",
            "1111 [D loss: 0.999990] [G loss: 1.000202]\n",
            "1112 [D loss: 1.000007] [G loss: 1.000165]\n",
            "1113 [D loss: 1.000018] [G loss: 1.000149]\n",
            "1114 [D loss: 1.000018] [G loss: 1.000189]\n",
            "1115 [D loss: 1.000030] [G loss: 1.000166]\n",
            "1116 [D loss: 0.999983] [G loss: 1.000248]\n",
            "1117 [D loss: 1.000017] [G loss: 1.000174]\n",
            "1118 [D loss: 0.999986] [G loss: 1.000151]\n",
            "1119 [D loss: 0.999995] [G loss: 1.000207]\n",
            "1120 [D loss: 1.000075] [G loss: 1.000239]\n",
            "1121 [D loss: 1.000035] [G loss: 1.000296]\n",
            "1122 [D loss: 1.000037] [G loss: 1.000191]\n",
            "1123 [D loss: 1.000076] [G loss: 1.000271]\n",
            "1124 [D loss: 1.000054] [G loss: 1.000264]\n",
            "1125 [D loss: 1.000031] [G loss: 1.000243]\n",
            "1126 [D loss: 1.000059] [G loss: 1.000179]\n",
            "1127 [D loss: 1.000052] [G loss: 1.000201]\n",
            "1128 [D loss: 1.000104] [G loss: 1.000131]\n",
            "1129 [D loss: 1.000243] [G loss: 1.000106]\n",
            "1130 [D loss: 1.000123] [G loss: 1.000057]\n",
            "1131 [D loss: 1.000169] [G loss: 1.000011]\n",
            "1132 [D loss: 1.000150] [G loss: 1.000046]\n",
            "1133 [D loss: 1.000087] [G loss: 0.999924]\n",
            "1134 [D loss: 1.000181] [G loss: 0.999959]\n",
            "1135 [D loss: 1.000103] [G loss: 0.999964]\n",
            "1136 [D loss: 1.000148] [G loss: 1.000034]\n",
            "1137 [D loss: 1.000092] [G loss: 0.999930]\n",
            "1138 [D loss: 1.000149] [G loss: 0.999849]\n",
            "1139 [D loss: 1.000213] [G loss: 0.999818]\n",
            "1140 [D loss: 1.000123] [G loss: 0.999804]\n",
            "1141 [D loss: 1.000233] [G loss: 0.999741]\n",
            "1142 [D loss: 1.000163] [G loss: 0.999740]\n",
            "1143 [D loss: 1.000202] [G loss: 0.999651]\n",
            "1144 [D loss: 1.000129] [G loss: 0.999760]\n",
            "1145 [D loss: 1.000190] [G loss: 0.999831]\n",
            "1146 [D loss: 1.000105] [G loss: 0.999865]\n",
            "1147 [D loss: 1.000089] [G loss: 0.999973]\n",
            "1148 [D loss: 1.000131] [G loss: 1.000032]\n",
            "1149 [D loss: 1.000091] [G loss: 1.000089]\n",
            "1150 [D loss: 1.000133] [G loss: 0.999982]\n",
            "1151 [D loss: 1.000116] [G loss: 1.000041]\n",
            "1152 [D loss: 1.000116] [G loss: 1.000007]\n",
            "1153 [D loss: 1.000109] [G loss: 1.000019]\n",
            "1154 [D loss: 1.000156] [G loss: 1.000001]\n",
            "1155 [D loss: 1.000027] [G loss: 1.000092]\n",
            "1156 [D loss: 1.000017] [G loss: 1.000062]\n",
            "1157 [D loss: 1.000087] [G loss: 1.000032]\n",
            "1158 [D loss: 1.000089] [G loss: 1.000062]\n",
            "1159 [D loss: 1.000034] [G loss: 1.000050]\n",
            "1160 [D loss: 1.000011] [G loss: 1.000119]\n",
            "1161 [D loss: 1.000022] [G loss: 1.000090]\n",
            "1162 [D loss: 1.000045] [G loss: 0.999999]\n",
            "1163 [D loss: 1.000012] [G loss: 0.999990]\n",
            "1164 [D loss: 1.000016] [G loss: 0.999940]\n",
            "1165 [D loss: 1.000085] [G loss: 0.999979]\n",
            "1166 [D loss: 1.000038] [G loss: 0.999929]\n",
            "1167 [D loss: 1.000147] [G loss: 0.999910]\n",
            "1168 [D loss: 1.000146] [G loss: 0.999872]\n",
            "1169 [D loss: 1.000083] [G loss: 0.999877]\n",
            "1170 [D loss: 1.000119] [G loss: 0.999936]\n",
            "1171 [D loss: 1.000038] [G loss: 0.999917]\n",
            "1172 [D loss: 1.000100] [G loss: 1.000009]\n",
            "1173 [D loss: 1.000107] [G loss: 0.999996]\n",
            "1174 [D loss: 1.000067] [G loss: 1.000042]\n",
            "1175 [D loss: 1.000156] [G loss: 1.000016]\n",
            "1176 [D loss: 1.000125] [G loss: 1.000007]\n",
            "1177 [D loss: 1.000103] [G loss: 0.999977]\n",
            "1178 [D loss: 1.000167] [G loss: 0.999970]\n",
            "1179 [D loss: 1.000163] [G loss: 0.999997]\n",
            "1180 [D loss: 1.000144] [G loss: 0.999988]\n",
            "1181 [D loss: 1.000311] [G loss: 1.000060]\n",
            "1182 [D loss: 1.000005] [G loss: 1.000073]\n",
            "1183 [D loss: 1.000156] [G loss: 1.000073]\n",
            "1184 [D loss: 1.000181] [G loss: 1.000141]\n",
            "1185 [D loss: 1.000120] [G loss: 1.000232]\n",
            "1186 [D loss: 1.000142] [G loss: 1.000087]\n",
            "1187 [D loss: 1.000075] [G loss: 1.000212]\n",
            "1188 [D loss: 1.000077] [G loss: 1.000241]\n",
            "1189 [D loss: 1.000012] [G loss: 1.000317]\n",
            "1190 [D loss: 1.000214] [G loss: 1.000231]\n",
            "1191 [D loss: 1.000093] [G loss: 1.000289]\n",
            "1192 [D loss: 1.000001] [G loss: 1.000302]\n",
            "1193 [D loss: 1.000008] [G loss: 1.000324]\n",
            "1194 [D loss: 0.999870] [G loss: 1.000236]\n",
            "1195 [D loss: 1.000052] [G loss: 1.000219]\n",
            "1196 [D loss: 0.999985] [G loss: 1.000291]\n",
            "1197 [D loss: 1.000026] [G loss: 1.000254]\n",
            "1198 [D loss: 0.999956] [G loss: 1.000426]\n",
            "1199 [D loss: 0.999958] [G loss: 1.000339]\n",
            "1200 [D loss: 1.000052] [G loss: 1.000319]\n",
            "1201 [D loss: 0.999894] [G loss: 1.000286]\n",
            "1202 [D loss: 0.999938] [G loss: 1.000224]\n",
            "1203 [D loss: 0.999894] [G loss: 1.000260]\n",
            "1204 [D loss: 1.000017] [G loss: 1.000119]\n",
            "1205 [D loss: 0.999990] [G loss: 1.000179]\n",
            "1206 [D loss: 1.000013] [G loss: 1.000169]\n",
            "1207 [D loss: 0.999982] [G loss: 1.000137]\n",
            "1208 [D loss: 1.000033] [G loss: 1.000054]\n",
            "1209 [D loss: 0.999954] [G loss: 1.000121]\n",
            "1210 [D loss: 1.000098] [G loss: 1.000060]\n",
            "1211 [D loss: 1.000095] [G loss: 0.999997]\n",
            "1212 [D loss: 1.000062] [G loss: 1.000028]\n",
            "1213 [D loss: 1.000000] [G loss: 1.000173]\n",
            "1214 [D loss: 0.999975] [G loss: 1.000139]\n",
            "1215 [D loss: 1.000098] [G loss: 1.000038]\n",
            "1216 [D loss: 1.000025] [G loss: 1.000062]\n",
            "1217 [D loss: 0.999984] [G loss: 1.000132]\n",
            "1218 [D loss: 0.999987] [G loss: 1.000185]\n",
            "1219 [D loss: 0.999992] [G loss: 1.000134]\n",
            "1220 [D loss: 0.999982] [G loss: 1.000104]\n",
            "1221 [D loss: 0.999988] [G loss: 1.000166]\n",
            "1222 [D loss: 0.999983] [G loss: 1.000154]\n",
            "1223 [D loss: 0.999938] [G loss: 1.000114]\n",
            "1224 [D loss: 0.999964] [G loss: 1.000159]\n",
            "1225 [D loss: 0.999974] [G loss: 1.000132]\n",
            "1226 [D loss: 0.999949] [G loss: 1.000077]\n",
            "1227 [D loss: 0.999948] [G loss: 1.000076]\n",
            "1228 [D loss: 0.999939] [G loss: 1.000082]\n",
            "1229 [D loss: 1.000006] [G loss: 1.000017]\n",
            "1230 [D loss: 0.999927] [G loss: 1.000080]\n",
            "1231 [D loss: 0.999994] [G loss: 1.000037]\n",
            "1232 [D loss: 0.999968] [G loss: 1.000053]\n",
            "1233 [D loss: 0.999951] [G loss: 1.000084]\n",
            "1234 [D loss: 0.999974] [G loss: 1.000037]\n",
            "1235 [D loss: 0.999981] [G loss: 1.000036]\n",
            "1236 [D loss: 1.000014] [G loss: 1.000040]\n",
            "1237 [D loss: 1.000002] [G loss: 1.000033]\n",
            "1238 [D loss: 1.000017] [G loss: 1.000022]\n",
            "1239 [D loss: 1.000003] [G loss: 1.000046]\n",
            "1240 [D loss: 1.000005] [G loss: 1.000058]\n",
            "1241 [D loss: 0.999995] [G loss: 1.000063]\n",
            "1242 [D loss: 0.999978] [G loss: 1.000113]\n",
            "1243 [D loss: 0.999966] [G loss: 1.000086]\n",
            "1244 [D loss: 0.999980] [G loss: 1.000076]\n",
            "1245 [D loss: 0.999986] [G loss: 1.000104]\n",
            "1246 [D loss: 0.999997] [G loss: 1.000099]\n",
            "1247 [D loss: 1.000016] [G loss: 1.000109]\n",
            "1248 [D loss: 1.000056] [G loss: 1.000087]\n",
            "1249 [D loss: 0.999975] [G loss: 1.000117]\n",
            "1250 [D loss: 0.999995] [G loss: 1.000137]\n",
            "1251 [D loss: 0.999999] [G loss: 1.000097]\n",
            "1252 [D loss: 1.000023] [G loss: 1.000024]\n",
            "1253 [D loss: 1.000051] [G loss: 1.000057]\n",
            "1254 [D loss: 0.999984] [G loss: 1.000136]\n",
            "1255 [D loss: 1.000070] [G loss: 1.000002]\n",
            "1256 [D loss: 1.000047] [G loss: 1.000107]\n",
            "1257 [D loss: 0.999994] [G loss: 1.000062]\n",
            "1258 [D loss: 1.000038] [G loss: 1.000071]\n",
            "1259 [D loss: 1.000073] [G loss: 1.000075]\n",
            "1260 [D loss: 0.999992] [G loss: 1.000087]\n",
            "1261 [D loss: 0.999990] [G loss: 1.000108]\n",
            "1262 [D loss: 1.000060] [G loss: 1.000183]\n",
            "1263 [D loss: 1.000000] [G loss: 1.000149]\n",
            "1264 [D loss: 0.999986] [G loss: 1.000135]\n",
            "1265 [D loss: 0.999993] [G loss: 1.000115]\n",
            "1266 [D loss: 1.000062] [G loss: 1.000065]\n",
            "1267 [D loss: 0.999970] [G loss: 1.000107]\n",
            "1268 [D loss: 1.000016] [G loss: 1.000145]\n",
            "1269 [D loss: 1.000012] [G loss: 1.000123]\n",
            "1270 [D loss: 1.000064] [G loss: 1.000063]\n",
            "1271 [D loss: 1.000041] [G loss: 1.000122]\n",
            "1272 [D loss: 1.000016] [G loss: 1.000075]\n",
            "1273 [D loss: 1.000066] [G loss: 1.000125]\n",
            "1274 [D loss: 1.000046] [G loss: 1.000137]\n",
            "1275 [D loss: 1.000072] [G loss: 1.000109]\n",
            "1276 [D loss: 1.000064] [G loss: 1.000158]\n",
            "1277 [D loss: 1.000021] [G loss: 1.000122]\n",
            "1278 [D loss: 1.000019] [G loss: 1.000082]\n",
            "1279 [D loss: 1.000082] [G loss: 1.000136]\n",
            "1280 [D loss: 1.000031] [G loss: 1.000078]\n",
            "1281 [D loss: 1.000055] [G loss: 1.000180]\n",
            "1282 [D loss: 1.000062] [G loss: 1.000137]\n",
            "1283 [D loss: 1.000045] [G loss: 1.000127]\n",
            "1284 [D loss: 1.000037] [G loss: 1.000158]\n",
            "1285 [D loss: 1.000051] [G loss: 1.000177]\n",
            "1286 [D loss: 1.000014] [G loss: 1.000157]\n",
            "1287 [D loss: 1.000044] [G loss: 1.000152]\n",
            "1288 [D loss: 1.000007] [G loss: 1.000148]\n",
            "1289 [D loss: 0.999964] [G loss: 1.000221]\n",
            "1290 [D loss: 1.000043] [G loss: 1.000159]\n",
            "1291 [D loss: 1.000048] [G loss: 1.000180]\n",
            "1292 [D loss: 1.000034] [G loss: 1.000162]\n",
            "1293 [D loss: 1.000042] [G loss: 1.000159]\n",
            "1294 [D loss: 1.000034] [G loss: 1.000086]\n",
            "1295 [D loss: 1.000058] [G loss: 1.000107]\n",
            "1296 [D loss: 1.000035] [G loss: 1.000164]\n",
            "1297 [D loss: 1.000024] [G loss: 1.000148]\n",
            "1298 [D loss: 1.000067] [G loss: 1.000148]\n",
            "1299 [D loss: 1.000004] [G loss: 1.000194]\n",
            "1300 [D loss: 1.000078] [G loss: 1.000141]\n",
            "1301 [D loss: 1.000027] [G loss: 1.000146]\n",
            "1302 [D loss: 0.999996] [G loss: 1.000152]\n",
            "1303 [D loss: 1.000051] [G loss: 1.000193]\n",
            "1304 [D loss: 1.000091] [G loss: 1.000089]\n",
            "1305 [D loss: 1.000095] [G loss: 1.000054]\n",
            "1306 [D loss: 1.000107] [G loss: 1.000156]\n",
            "1307 [D loss: 1.000084] [G loss: 1.000166]\n",
            "1308 [D loss: 0.999996] [G loss: 1.000141]\n",
            "1309 [D loss: 1.000040] [G loss: 1.000127]\n",
            "1310 [D loss: 1.000074] [G loss: 1.000040]\n",
            "1311 [D loss: 1.000092] [G loss: 1.000031]\n",
            "1312 [D loss: 1.000051] [G loss: 1.000087]\n",
            "1313 [D loss: 1.000010] [G loss: 1.000083]\n",
            "1314 [D loss: 0.999972] [G loss: 1.000131]\n",
            "1315 [D loss: 0.999982] [G loss: 1.000115]\n",
            "1316 [D loss: 1.000032] [G loss: 1.000116]\n",
            "1317 [D loss: 1.000020] [G loss: 1.000066]\n",
            "1318 [D loss: 0.999983] [G loss: 1.000078]\n",
            "1319 [D loss: 1.000053] [G loss: 1.000098]\n",
            "1320 [D loss: 0.999999] [G loss: 1.000104]\n",
            "1321 [D loss: 1.000060] [G loss: 1.000027]\n",
            "1322 [D loss: 1.000025] [G loss: 1.000139]\n",
            "1323 [D loss: 1.000091] [G loss: 1.000087]\n",
            "1324 [D loss: 1.000091] [G loss: 1.000098]\n",
            "1325 [D loss: 1.000038] [G loss: 1.000115]\n",
            "1326 [D loss: 1.000101] [G loss: 1.000100]\n",
            "1327 [D loss: 1.000096] [G loss: 1.000067]\n",
            "1328 [D loss: 1.000090] [G loss: 1.000121]\n",
            "1329 [D loss: 1.000114] [G loss: 1.000130]\n",
            "1330 [D loss: 1.000027] [G loss: 1.000180]\n",
            "1331 [D loss: 1.000062] [G loss: 1.000223]\n",
            "1332 [D loss: 1.000108] [G loss: 1.000198]\n",
            "1333 [D loss: 1.000111] [G loss: 1.000222]\n",
            "1334 [D loss: 1.000100] [G loss: 1.000072]\n",
            "1335 [D loss: 0.999931] [G loss: 1.000211]\n",
            "1336 [D loss: 1.000109] [G loss: 1.000138]\n",
            "1337 [D loss: 1.000056] [G loss: 1.000187]\n",
            "1338 [D loss: 1.000038] [G loss: 1.000179]\n",
            "1339 [D loss: 1.000083] [G loss: 1.000125]\n",
            "1340 [D loss: 0.999959] [G loss: 1.000110]\n",
            "1341 [D loss: 1.000049] [G loss: 1.000029]\n",
            "1342 [D loss: 1.000064] [G loss: 1.000148]\n",
            "1343 [D loss: 1.000065] [G loss: 1.000123]\n",
            "1344 [D loss: 1.000016] [G loss: 0.999998]\n",
            "1345 [D loss: 0.999937] [G loss: 1.000015]\n",
            "1346 [D loss: 1.000112] [G loss: 0.999988]\n",
            "1347 [D loss: 1.000129] [G loss: 0.999864]\n",
            "1348 [D loss: 0.999984] [G loss: 1.000131]\n",
            "1349 [D loss: 1.000059] [G loss: 0.999979]\n",
            "1350 [D loss: 1.000023] [G loss: 1.000026]\n",
            "1351 [D loss: 1.000076] [G loss: 1.000089]\n",
            "1352 [D loss: 1.000062] [G loss: 1.000064]\n",
            "1353 [D loss: 1.000136] [G loss: 0.999930]\n",
            "1354 [D loss: 1.000036] [G loss: 0.999961]\n",
            "1355 [D loss: 1.000064] [G loss: 1.000011]\n",
            "1356 [D loss: 1.000063] [G loss: 1.000091]\n",
            "1357 [D loss: 1.000020] [G loss: 1.000051]\n",
            "1358 [D loss: 1.000155] [G loss: 0.999936]\n",
            "1359 [D loss: 1.000024] [G loss: 1.000027]\n",
            "1360 [D loss: 1.000089] [G loss: 1.000090]\n",
            "1361 [D loss: 1.000054] [G loss: 1.000012]\n",
            "1362 [D loss: 0.999966] [G loss: 1.000038]\n",
            "1363 [D loss: 1.000011] [G loss: 1.000034]\n",
            "1364 [D loss: 1.000031] [G loss: 1.000089]\n",
            "1365 [D loss: 1.000062] [G loss: 1.000073]\n",
            "1366 [D loss: 1.000066] [G loss: 1.000104]\n",
            "1367 [D loss: 0.999963] [G loss: 1.000043]\n",
            "1368 [D loss: 1.000011] [G loss: 1.000120]\n",
            "1369 [D loss: 1.000001] [G loss: 1.000088]\n",
            "1370 [D loss: 1.000082] [G loss: 1.000091]\n",
            "1371 [D loss: 0.999987] [G loss: 1.000077]\n",
            "1372 [D loss: 1.000014] [G loss: 1.000065]\n",
            "1373 [D loss: 1.000048] [G loss: 0.999946]\n",
            "1374 [D loss: 0.999981] [G loss: 1.000118]\n",
            "1375 [D loss: 1.000018] [G loss: 1.000117]\n",
            "1376 [D loss: 0.999978] [G loss: 1.000078]\n",
            "1377 [D loss: 0.999991] [G loss: 1.000065]\n",
            "1378 [D loss: 0.999984] [G loss: 1.000092]\n",
            "1379 [D loss: 1.000078] [G loss: 1.000079]\n",
            "1380 [D loss: 1.000084] [G loss: 1.000028]\n",
            "1381 [D loss: 0.999998] [G loss: 1.000028]\n",
            "1382 [D loss: 1.000074] [G loss: 0.999975]\n",
            "1383 [D loss: 1.000022] [G loss: 1.000038]\n",
            "1384 [D loss: 0.999966] [G loss: 1.000013]\n",
            "1385 [D loss: 1.000007] [G loss: 1.000015]\n",
            "1386 [D loss: 0.999995] [G loss: 1.000024]\n",
            "1387 [D loss: 1.000036] [G loss: 1.000057]\n",
            "1388 [D loss: 1.000032] [G loss: 0.999997]\n",
            "1389 [D loss: 1.000015] [G loss: 1.000064]\n",
            "1390 [D loss: 1.000074] [G loss: 0.999969]\n",
            "1391 [D loss: 0.999956] [G loss: 1.000065]\n",
            "1392 [D loss: 1.000025] [G loss: 1.000048]\n",
            "1393 [D loss: 1.000058] [G loss: 0.999990]\n",
            "1394 [D loss: 0.999951] [G loss: 1.000061]\n",
            "1395 [D loss: 1.000053] [G loss: 1.000047]\n",
            "1396 [D loss: 1.000130] [G loss: 0.999950]\n",
            "1397 [D loss: 1.000039] [G loss: 1.000003]\n",
            "1398 [D loss: 0.999998] [G loss: 1.000003]\n",
            "1399 [D loss: 1.000046] [G loss: 0.999986]\n",
            "1400 [D loss: 1.000103] [G loss: 1.000020]\n",
            "1401 [D loss: 1.000093] [G loss: 1.000010]\n",
            "1402 [D loss: 1.000071] [G loss: 0.999954]\n",
            "1403 [D loss: 1.000028] [G loss: 0.999989]\n",
            "1404 [D loss: 1.000054] [G loss: 0.999957]\n",
            "1405 [D loss: 1.000051] [G loss: 1.000024]\n",
            "1406 [D loss: 1.000088] [G loss: 0.999925]\n",
            "1407 [D loss: 1.000023] [G loss: 0.999953]\n",
            "1408 [D loss: 0.999984] [G loss: 0.999973]\n",
            "1409 [D loss: 1.000042] [G loss: 0.999993]\n",
            "1410 [D loss: 1.000064] [G loss: 0.999888]\n",
            "1411 [D loss: 1.000031] [G loss: 0.999940]\n",
            "1412 [D loss: 1.000053] [G loss: 0.999940]\n",
            "1413 [D loss: 1.000098] [G loss: 0.999975]\n",
            "1414 [D loss: 0.999971] [G loss: 0.999934]\n",
            "1415 [D loss: 1.000202] [G loss: 0.999896]\n",
            "1416 [D loss: 1.000064] [G loss: 0.999915]\n",
            "1417 [D loss: 1.000113] [G loss: 0.999985]\n",
            "1418 [D loss: 1.000074] [G loss: 0.999952]\n",
            "1419 [D loss: 1.000079] [G loss: 0.999947]\n",
            "1420 [D loss: 1.000047] [G loss: 0.999948]\n",
            "1421 [D loss: 1.000123] [G loss: 0.999943]\n",
            "1422 [D loss: 1.000125] [G loss: 1.000020]\n",
            "1423 [D loss: 1.000078] [G loss: 0.999912]\n",
            "1424 [D loss: 1.000093] [G loss: 0.999943]\n",
            "1425 [D loss: 1.000040] [G loss: 0.999980]\n",
            "1426 [D loss: 1.000069] [G loss: 0.999975]\n",
            "1427 [D loss: 1.000137] [G loss: 0.999939]\n",
            "1428 [D loss: 1.000100] [G loss: 0.999898]\n",
            "1429 [D loss: 1.000092] [G loss: 0.999955]\n",
            "1430 [D loss: 1.000067] [G loss: 0.999965]\n",
            "1431 [D loss: 1.000002] [G loss: 0.999965]\n",
            "1432 [D loss: 1.000101] [G loss: 0.999957]\n",
            "1433 [D loss: 1.000052] [G loss: 0.999969]\n",
            "1434 [D loss: 1.000066] [G loss: 0.999946]\n",
            "1435 [D loss: 1.000022] [G loss: 0.999911]\n",
            "1436 [D loss: 1.000093] [G loss: 0.999981]\n",
            "1437 [D loss: 1.000082] [G loss: 1.000004]\n",
            "1438 [D loss: 1.000119] [G loss: 0.999942]\n",
            "1439 [D loss: 1.000076] [G loss: 1.000001]\n",
            "1440 [D loss: 1.000097] [G loss: 0.999946]\n",
            "1441 [D loss: 0.999967] [G loss: 0.999976]\n",
            "1442 [D loss: 1.000025] [G loss: 0.999962]\n",
            "1443 [D loss: 1.000025] [G loss: 0.999940]\n",
            "1444 [D loss: 1.000042] [G loss: 0.999980]\n",
            "1445 [D loss: 1.000128] [G loss: 0.999951]\n",
            "1446 [D loss: 1.000064] [G loss: 1.000042]\n",
            "1447 [D loss: 1.000087] [G loss: 1.000021]\n",
            "1448 [D loss: 1.000113] [G loss: 0.999959]\n",
            "1449 [D loss: 1.000011] [G loss: 1.000016]\n",
            "1450 [D loss: 1.000067] [G loss: 0.999946]\n",
            "1451 [D loss: 0.999971] [G loss: 1.000022]\n",
            "1452 [D loss: 1.000025] [G loss: 1.000030]\n",
            "1453 [D loss: 1.000019] [G loss: 1.000050]\n",
            "1454 [D loss: 1.000031] [G loss: 1.000033]\n",
            "1455 [D loss: 1.000015] [G loss: 1.000021]\n",
            "1456 [D loss: 1.000072] [G loss: 1.000072]\n",
            "1457 [D loss: 0.999990] [G loss: 1.000067]\n",
            "1458 [D loss: 1.000099] [G loss: 1.000004]\n",
            "1459 [D loss: 1.000024] [G loss: 0.999986]\n",
            "1460 [D loss: 0.999955] [G loss: 1.000049]\n",
            "1461 [D loss: 1.000013] [G loss: 1.000080]\n",
            "1462 [D loss: 1.000060] [G loss: 1.000061]\n",
            "1463 [D loss: 1.000050] [G loss: 1.000049]\n",
            "1464 [D loss: 1.000035] [G loss: 1.000063]\n",
            "1465 [D loss: 1.000008] [G loss: 1.000053]\n",
            "1466 [D loss: 1.000032] [G loss: 1.000049]\n",
            "1467 [D loss: 1.000080] [G loss: 1.000044]\n",
            "1468 [D loss: 1.000045] [G loss: 1.000023]\n",
            "1469 [D loss: 1.000114] [G loss: 0.999982]\n",
            "1470 [D loss: 1.000075] [G loss: 1.000094]\n",
            "1471 [D loss: 1.000071] [G loss: 1.000064]\n",
            "1472 [D loss: 1.000024] [G loss: 1.000035]\n",
            "1473 [D loss: 1.000036] [G loss: 1.000076]\n",
            "1474 [D loss: 1.000022] [G loss: 1.000053]\n",
            "1475 [D loss: 1.000008] [G loss: 1.000036]\n",
            "1476 [D loss: 1.000083] [G loss: 1.000047]\n",
            "1477 [D loss: 1.000095] [G loss: 0.999932]\n",
            "1478 [D loss: 1.000034] [G loss: 1.000032]\n",
            "1479 [D loss: 1.000121] [G loss: 1.000016]\n",
            "1480 [D loss: 0.999942] [G loss: 1.000027]\n",
            "1481 [D loss: 1.000012] [G loss: 1.000051]\n",
            "1482 [D loss: 1.000005] [G loss: 0.999986]\n",
            "1483 [D loss: 1.000010] [G loss: 1.000070]\n",
            "1484 [D loss: 1.000075] [G loss: 1.000024]\n",
            "1485 [D loss: 1.000028] [G loss: 1.000042]\n",
            "1486 [D loss: 1.000071] [G loss: 1.000027]\n",
            "1487 [D loss: 1.000127] [G loss: 0.999998]\n",
            "1488 [D loss: 1.000051] [G loss: 1.000002]\n",
            "1489 [D loss: 1.000057] [G loss: 1.000060]\n",
            "1490 [D loss: 1.000039] [G loss: 1.000057]\n",
            "1491 [D loss: 1.000020] [G loss: 1.000027]\n",
            "1492 [D loss: 1.000025] [G loss: 0.999986]\n",
            "1493 [D loss: 1.000036] [G loss: 1.000087]\n",
            "1494 [D loss: 0.999992] [G loss: 1.000073]\n",
            "1495 [D loss: 1.000026] [G loss: 1.000018]\n",
            "1496 [D loss: 1.000028] [G loss: 1.000006]\n",
            "1497 [D loss: 1.000039] [G loss: 1.000043]\n",
            "1498 [D loss: 1.000029] [G loss: 1.000052]\n",
            "1499 [D loss: 1.000024] [G loss: 1.000027]\n",
            "1500 [D loss: 1.000045] [G loss: 1.000036]\n",
            "1501 [D loss: 1.000080] [G loss: 1.000031]\n",
            "1502 [D loss: 1.000143] [G loss: 1.000012]\n",
            "1503 [D loss: 1.000031] [G loss: 0.999931]\n",
            "1504 [D loss: 0.999997] [G loss: 1.000044]\n",
            "1505 [D loss: 1.000108] [G loss: 1.000062]\n",
            "1506 [D loss: 0.999968] [G loss: 1.000011]\n",
            "1507 [D loss: 1.000006] [G loss: 1.000088]\n",
            "1508 [D loss: 1.000057] [G loss: 1.000041]\n",
            "1509 [D loss: 1.000005] [G loss: 1.000031]\n",
            "1510 [D loss: 1.000109] [G loss: 1.000042]\n",
            "1511 [D loss: 1.000031] [G loss: 1.000084]\n",
            "1512 [D loss: 1.000086] [G loss: 1.000047]\n",
            "1513 [D loss: 1.000003] [G loss: 1.000079]\n",
            "1514 [D loss: 1.000073] [G loss: 1.000059]\n",
            "1515 [D loss: 1.000011] [G loss: 1.000079]\n",
            "1516 [D loss: 0.999995] [G loss: 1.000119]\n",
            "1517 [D loss: 1.000042] [G loss: 1.000131]\n",
            "1518 [D loss: 1.000039] [G loss: 1.000098]\n",
            "1519 [D loss: 1.000070] [G loss: 1.000073]\n",
            "1520 [D loss: 1.000018] [G loss: 1.000048]\n",
            "1521 [D loss: 1.000050] [G loss: 1.000077]\n",
            "1522 [D loss: 1.000012] [G loss: 1.000105]\n",
            "1523 [D loss: 1.000060] [G loss: 1.000042]\n",
            "1524 [D loss: 1.000056] [G loss: 1.000039]\n",
            "1525 [D loss: 1.000038] [G loss: 1.000087]\n",
            "1526 [D loss: 1.000132] [G loss: 1.000005]\n",
            "1527 [D loss: 1.000037] [G loss: 1.000045]\n",
            "1528 [D loss: 1.000063] [G loss: 1.000037]\n",
            "1529 [D loss: 0.999997] [G loss: 1.000057]\n",
            "1530 [D loss: 1.000095] [G loss: 1.000083]\n",
            "1531 [D loss: 1.000156] [G loss: 1.000003]\n",
            "1532 [D loss: 1.000033] [G loss: 1.000055]\n",
            "1533 [D loss: 0.999911] [G loss: 1.000089]\n",
            "1534 [D loss: 1.000055] [G loss: 1.000131]\n",
            "1535 [D loss: 0.999992] [G loss: 1.000124]\n",
            "1536 [D loss: 0.999966] [G loss: 1.000086]\n",
            "1537 [D loss: 1.000043] [G loss: 1.000090]\n",
            "1538 [D loss: 1.000009] [G loss: 1.000051]\n",
            "1539 [D loss: 1.000006] [G loss: 1.000027]\n",
            "1540 [D loss: 1.000062] [G loss: 1.000042]\n",
            "1541 [D loss: 0.999998] [G loss: 1.000040]\n",
            "1542 [D loss: 1.000076] [G loss: 1.000027]\n",
            "1543 [D loss: 1.000091] [G loss: 1.000089]\n",
            "1544 [D loss: 1.000017] [G loss: 1.000051]\n",
            "1545 [D loss: 1.000088] [G loss: 1.000057]\n",
            "1546 [D loss: 1.000093] [G loss: 1.000071]\n",
            "1547 [D loss: 1.000040] [G loss: 1.000056]\n",
            "1548 [D loss: 1.000089] [G loss: 1.000046]\n",
            "1549 [D loss: 1.000108] [G loss: 1.000035]\n",
            "1550 [D loss: 1.000026] [G loss: 1.000057]\n",
            "1551 [D loss: 1.000005] [G loss: 1.000056]\n",
            "1552 [D loss: 0.999953] [G loss: 1.000115]\n",
            "1553 [D loss: 1.000027] [G loss: 1.000055]\n",
            "1554 [D loss: 1.000074] [G loss: 1.000031]\n",
            "1555 [D loss: 1.000064] [G loss: 1.000002]\n",
            "1556 [D loss: 1.000127] [G loss: 1.000057]\n",
            "1557 [D loss: 0.999957] [G loss: 0.999979]\n",
            "1558 [D loss: 1.000061] [G loss: 1.000057]\n",
            "1559 [D loss: 1.000012] [G loss: 0.999984]\n",
            "1560 [D loss: 1.000069] [G loss: 1.000081]\n",
            "1561 [D loss: 1.000142] [G loss: 1.000045]\n",
            "1562 [D loss: 1.000104] [G loss: 1.000042]\n",
            "1563 [D loss: 1.000056] [G loss: 1.000010]\n",
            "1564 [D loss: 1.000025] [G loss: 1.000019]\n",
            "1565 [D loss: 1.000013] [G loss: 1.000059]\n",
            "1566 [D loss: 1.000066] [G loss: 1.000035]\n",
            "1567 [D loss: 1.000034] [G loss: 1.000011]\n",
            "1568 [D loss: 1.000137] [G loss: 0.999993]\n",
            "1569 [D loss: 1.000080] [G loss: 1.000011]\n",
            "1570 [D loss: 0.999998] [G loss: 1.000014]\n",
            "1571 [D loss: 1.000030] [G loss: 1.000042]\n",
            "1572 [D loss: 1.000126] [G loss: 1.000025]\n",
            "1573 [D loss: 1.000029] [G loss: 1.000016]\n",
            "1574 [D loss: 0.999947] [G loss: 1.000024]\n",
            "1575 [D loss: 1.000088] [G loss: 1.000071]\n",
            "1576 [D loss: 1.000022] [G loss: 1.000020]\n",
            "1577 [D loss: 1.000087] [G loss: 0.999937]\n",
            "1578 [D loss: 1.000081] [G loss: 1.000003]\n",
            "1579 [D loss: 1.000131] [G loss: 0.999953]\n",
            "1580 [D loss: 1.000056] [G loss: 0.999973]\n",
            "1581 [D loss: 1.000081] [G loss: 1.000042]\n",
            "1582 [D loss: 1.000053] [G loss: 0.999985]\n",
            "1583 [D loss: 1.000077] [G loss: 0.999963]\n",
            "1584 [D loss: 0.999992] [G loss: 1.000016]\n",
            "1585 [D loss: 0.999974] [G loss: 1.000102]\n",
            "1586 [D loss: 0.999983] [G loss: 1.000011]\n",
            "1587 [D loss: 0.999986] [G loss: 1.000010]\n",
            "1588 [D loss: 0.999997] [G loss: 1.000088]\n",
            "1589 [D loss: 0.999961] [G loss: 1.000074]\n",
            "1590 [D loss: 0.999996] [G loss: 1.000051]\n",
            "1591 [D loss: 0.999877] [G loss: 1.000085]\n",
            "1592 [D loss: 1.000071] [G loss: 0.999973]\n",
            "1593 [D loss: 0.999990] [G loss: 0.999959]\n",
            "1594 [D loss: 1.000170] [G loss: 1.000022]\n",
            "1595 [D loss: 0.999877] [G loss: 1.000032]\n",
            "1596 [D loss: 0.999990] [G loss: 1.000017]\n",
            "1597 [D loss: 1.000062] [G loss: 0.999983]\n",
            "1598 [D loss: 1.000014] [G loss: 0.999944]\n",
            "1599 [D loss: 1.000050] [G loss: 0.999945]\n",
            "1600 [D loss: 1.000143] [G loss: 0.999915]\n",
            "1601 [D loss: 1.000099] [G loss: 0.999911]\n",
            "1602 [D loss: 1.000007] [G loss: 0.999951]\n",
            "1603 [D loss: 1.000026] [G loss: 1.000023]\n",
            "1604 [D loss: 1.000057] [G loss: 0.999932]\n",
            "1605 [D loss: 1.000054] [G loss: 0.999889]\n",
            "1606 [D loss: 1.000028] [G loss: 0.999994]\n",
            "1607 [D loss: 1.000062] [G loss: 0.999890]\n",
            "1608 [D loss: 1.000096] [G loss: 0.999966]\n",
            "1609 [D loss: 1.000052] [G loss: 0.999911]\n",
            "1610 [D loss: 0.999981] [G loss: 0.999915]\n",
            "1611 [D loss: 1.000048] [G loss: 0.999949]\n",
            "1612 [D loss: 1.000025] [G loss: 0.999994]\n",
            "1613 [D loss: 1.000031] [G loss: 0.999896]\n",
            "1614 [D loss: 0.999968] [G loss: 0.999989]\n",
            "1615 [D loss: 1.000113] [G loss: 1.000009]\n",
            "1616 [D loss: 1.000036] [G loss: 0.999965]\n",
            "1617 [D loss: 1.000052] [G loss: 0.999978]\n",
            "1618 [D loss: 1.000011] [G loss: 0.999993]\n",
            "1619 [D loss: 1.000067] [G loss: 0.999971]\n",
            "1620 [D loss: 1.000077] [G loss: 0.999927]\n",
            "1621 [D loss: 1.000047] [G loss: 0.999969]\n",
            "1622 [D loss: 1.000061] [G loss: 0.999917]\n",
            "1623 [D loss: 1.000064] [G loss: 0.999977]\n",
            "1624 [D loss: 1.000098] [G loss: 0.999869]\n",
            "1625 [D loss: 1.000021] [G loss: 0.999952]\n",
            "1626 [D loss: 0.999974] [G loss: 0.999981]\n",
            "1627 [D loss: 1.000009] [G loss: 0.999953]\n",
            "1628 [D loss: 0.999986] [G loss: 1.000006]\n",
            "1629 [D loss: 1.000056] [G loss: 0.999940]\n",
            "1630 [D loss: 0.999966] [G loss: 0.999979]\n",
            "1631 [D loss: 1.000023] [G loss: 0.999988]\n",
            "1632 [D loss: 0.999948] [G loss: 0.999975]\n",
            "1633 [D loss: 1.000039] [G loss: 0.999995]\n",
            "1634 [D loss: 1.000103] [G loss: 0.999980]\n",
            "1635 [D loss: 1.000116] [G loss: 0.999966]\n",
            "1636 [D loss: 1.000023] [G loss: 1.000017]\n",
            "1637 [D loss: 1.000077] [G loss: 0.999985]\n",
            "1638 [D loss: 1.000013] [G loss: 0.999995]\n",
            "1639 [D loss: 1.000041] [G loss: 0.999983]\n",
            "1640 [D loss: 1.000025] [G loss: 1.000044]\n",
            "1641 [D loss: 1.000018] [G loss: 1.000025]\n",
            "1642 [D loss: 1.000021] [G loss: 1.000010]\n",
            "1643 [D loss: 1.000005] [G loss: 1.000055]\n",
            "1644 [D loss: 1.000007] [G loss: 0.999999]\n",
            "1645 [D loss: 1.000021] [G loss: 0.999963]\n",
            "1646 [D loss: 1.000047] [G loss: 0.999996]\n",
            "1647 [D loss: 1.000046] [G loss: 1.000006]\n",
            "1648 [D loss: 1.000066] [G loss: 0.999957]\n",
            "1649 [D loss: 1.000059] [G loss: 1.000003]\n",
            "1650 [D loss: 0.999909] [G loss: 1.000032]\n",
            "1651 [D loss: 0.999975] [G loss: 0.999943]\n",
            "1652 [D loss: 0.999996] [G loss: 0.999984]\n",
            "1653 [D loss: 1.000038] [G loss: 0.999980]\n",
            "1654 [D loss: 1.000016] [G loss: 1.000035]\n",
            "1655 [D loss: 0.999978] [G loss: 1.000018]\n",
            "1656 [D loss: 1.000086] [G loss: 0.999962]\n",
            "1657 [D loss: 0.999990] [G loss: 1.000001]\n",
            "1658 [D loss: 0.999977] [G loss: 1.000008]\n",
            "1659 [D loss: 1.000035] [G loss: 1.000001]\n",
            "1660 [D loss: 1.000040] [G loss: 1.000030]\n",
            "1661 [D loss: 1.000005] [G loss: 0.999994]\n",
            "1662 [D loss: 1.000007] [G loss: 0.999985]\n",
            "1663 [D loss: 1.000044] [G loss: 0.999969]\n",
            "1664 [D loss: 0.999932] [G loss: 1.000012]\n",
            "1665 [D loss: 1.000060] [G loss: 1.000025]\n",
            "1666 [D loss: 1.000053] [G loss: 0.999991]\n",
            "1667 [D loss: 0.999976] [G loss: 1.000030]\n",
            "1668 [D loss: 1.000054] [G loss: 0.999974]\n",
            "1669 [D loss: 1.000014] [G loss: 0.999999]\n",
            "1670 [D loss: 0.999973] [G loss: 0.999998]\n",
            "1671 [D loss: 1.000055] [G loss: 1.000022]\n",
            "1672 [D loss: 1.000016] [G loss: 0.999988]\n",
            "1673 [D loss: 1.000025] [G loss: 0.999940]\n",
            "1674 [D loss: 1.000006] [G loss: 0.999983]\n",
            "1675 [D loss: 1.000027] [G loss: 0.999965]\n",
            "1676 [D loss: 1.000019] [G loss: 0.999975]\n",
            "1677 [D loss: 1.000024] [G loss: 1.000053]\n",
            "1678 [D loss: 1.000058] [G loss: 1.000037]\n",
            "1679 [D loss: 1.000008] [G loss: 0.999987]\n",
            "1680 [D loss: 0.999990] [G loss: 1.000038]\n",
            "1681 [D loss: 0.999981] [G loss: 1.000017]\n",
            "1682 [D loss: 1.000037] [G loss: 0.999984]\n",
            "1683 [D loss: 1.000026] [G loss: 0.999935]\n",
            "1684 [D loss: 1.000065] [G loss: 0.999978]\n",
            "1685 [D loss: 1.000030] [G loss: 0.999948]\n",
            "1686 [D loss: 0.999986] [G loss: 1.000014]\n",
            "1687 [D loss: 0.999943] [G loss: 1.000021]\n",
            "1688 [D loss: 1.000022] [G loss: 1.000019]\n",
            "1689 [D loss: 0.999979] [G loss: 1.000029]\n",
            "1690 [D loss: 1.000077] [G loss: 0.999976]\n",
            "1691 [D loss: 1.000030] [G loss: 1.000041]\n",
            "1692 [D loss: 0.999953] [G loss: 0.999990]\n",
            "1693 [D loss: 0.999953] [G loss: 1.000004]\n",
            "1694 [D loss: 1.000048] [G loss: 1.000007]\n",
            "1695 [D loss: 1.000023] [G loss: 1.000014]\n",
            "1696 [D loss: 1.000004] [G loss: 1.000057]\n",
            "1697 [D loss: 0.999934] [G loss: 1.000008]\n",
            "1698 [D loss: 1.000102] [G loss: 1.000004]\n",
            "1699 [D loss: 0.999999] [G loss: 0.999938]\n",
            "1700 [D loss: 0.999986] [G loss: 0.999957]\n",
            "1701 [D loss: 0.999974] [G loss: 1.000022]\n",
            "1702 [D loss: 1.000049] [G loss: 1.000029]\n",
            "1703 [D loss: 0.999963] [G loss: 1.000018]\n",
            "1704 [D loss: 1.000018] [G loss: 1.000045]\n",
            "1705 [D loss: 1.000058] [G loss: 1.000029]\n",
            "1706 [D loss: 1.000008] [G loss: 1.000009]\n",
            "1707 [D loss: 1.000063] [G loss: 1.000007]\n",
            "1708 [D loss: 1.000010] [G loss: 1.000005]\n",
            "1709 [D loss: 1.000055] [G loss: 0.999999]\n",
            "1710 [D loss: 1.000077] [G loss: 1.000048]\n",
            "1711 [D loss: 1.000078] [G loss: 0.999985]\n",
            "1712 [D loss: 1.000060] [G loss: 0.999997]\n",
            "1713 [D loss: 0.999984] [G loss: 1.000053]\n",
            "1714 [D loss: 1.000030] [G loss: 0.999971]\n",
            "1715 [D loss: 1.000021] [G loss: 0.999996]\n",
            "1716 [D loss: 0.999942] [G loss: 1.000028]\n",
            "1717 [D loss: 1.000034] [G loss: 0.999979]\n",
            "1718 [D loss: 1.000010] [G loss: 1.000003]\n",
            "1719 [D loss: 1.000045] [G loss: 0.999920]\n",
            "1720 [D loss: 1.000001] [G loss: 1.000049]\n",
            "1721 [D loss: 1.000025] [G loss: 1.000012]\n",
            "1722 [D loss: 1.000047] [G loss: 0.999956]\n",
            "1723 [D loss: 1.000148] [G loss: 0.999981]\n",
            "1724 [D loss: 1.000072] [G loss: 1.000002]\n",
            "1725 [D loss: 1.000030] [G loss: 0.999940]\n",
            "1726 [D loss: 1.000037] [G loss: 0.999999]\n",
            "1727 [D loss: 1.000121] [G loss: 0.999961]\n",
            "1728 [D loss: 0.999997] [G loss: 0.999926]\n",
            "1729 [D loss: 1.000003] [G loss: 0.999951]\n",
            "1730 [D loss: 1.000050] [G loss: 0.999934]\n",
            "1731 [D loss: 1.000099] [G loss: 0.999928]\n",
            "1732 [D loss: 1.000100] [G loss: 1.000040]\n",
            "1733 [D loss: 1.000045] [G loss: 0.999918]\n",
            "1734 [D loss: 1.000042] [G loss: 0.999964]\n",
            "1735 [D loss: 1.000034] [G loss: 0.999960]\n",
            "1736 [D loss: 1.000008] [G loss: 0.999957]\n",
            "1737 [D loss: 0.999998] [G loss: 0.999949]\n",
            "1738 [D loss: 1.000126] [G loss: 1.000005]\n",
            "1739 [D loss: 0.999972] [G loss: 0.999874]\n",
            "1740 [D loss: 1.000126] [G loss: 0.999967]\n",
            "1741 [D loss: 1.000015] [G loss: 0.999971]\n",
            "1742 [D loss: 1.000108] [G loss: 0.999925]\n",
            "1743 [D loss: 1.000172] [G loss: 0.999899]\n",
            "1744 [D loss: 1.000058] [G loss: 1.000005]\n",
            "1745 [D loss: 1.000107] [G loss: 0.999978]\n",
            "1746 [D loss: 1.000113] [G loss: 0.999990]\n",
            "1747 [D loss: 0.999974] [G loss: 0.999929]\n",
            "1748 [D loss: 1.000088] [G loss: 0.999989]\n",
            "1749 [D loss: 1.000158] [G loss: 0.999938]\n",
            "1750 [D loss: 1.000010] [G loss: 0.999968]\n",
            "1751 [D loss: 0.999940] [G loss: 1.000007]\n",
            "1752 [D loss: 1.000064] [G loss: 0.999960]\n",
            "1753 [D loss: 1.000021] [G loss: 1.000002]\n",
            "1754 [D loss: 0.999976] [G loss: 1.000035]\n",
            "1755 [D loss: 1.000022] [G loss: 0.999916]\n",
            "1756 [D loss: 1.000066] [G loss: 0.999952]\n",
            "1757 [D loss: 1.000021] [G loss: 0.999958]\n",
            "1758 [D loss: 1.000100] [G loss: 0.999952]\n",
            "1759 [D loss: 0.999944] [G loss: 0.999975]\n",
            "1760 [D loss: 0.999941] [G loss: 1.000017]\n",
            "1761 [D loss: 1.000078] [G loss: 0.999878]\n",
            "1762 [D loss: 1.000042] [G loss: 0.999990]\n",
            "1763 [D loss: 1.000027] [G loss: 0.999852]\n",
            "1764 [D loss: 0.999958] [G loss: 0.999901]\n",
            "1765 [D loss: 0.999982] [G loss: 0.999973]\n",
            "1766 [D loss: 0.999961] [G loss: 0.999998]\n",
            "1767 [D loss: 1.000059] [G loss: 0.999978]\n",
            "1768 [D loss: 1.000081] [G loss: 0.999979]\n",
            "1769 [D loss: 1.000028] [G loss: 0.999970]\n",
            "1770 [D loss: 0.999933] [G loss: 0.999988]\n",
            "1771 [D loss: 1.000004] [G loss: 0.999905]\n",
            "1772 [D loss: 1.000028] [G loss: 0.999951]\n",
            "1773 [D loss: 1.000030] [G loss: 0.999974]\n",
            "1774 [D loss: 0.999918] [G loss: 1.000002]\n",
            "1775 [D loss: 0.999944] [G loss: 0.999990]\n",
            "1776 [D loss: 1.000022] [G loss: 0.999854]\n",
            "1777 [D loss: 0.999969] [G loss: 0.999943]\n",
            "1778 [D loss: 1.000091] [G loss: 0.999854]\n",
            "1779 [D loss: 1.000018] [G loss: 0.999907]\n",
            "1780 [D loss: 1.000044] [G loss: 0.999827]\n",
            "1781 [D loss: 0.999860] [G loss: 0.999936]\n",
            "1782 [D loss: 1.000035] [G loss: 0.999892]\n",
            "1783 [D loss: 1.000015] [G loss: 0.999855]\n",
            "1784 [D loss: 1.000075] [G loss: 0.999911]\n",
            "1785 [D loss: 1.000075] [G loss: 0.999921]\n",
            "1786 [D loss: 0.999964] [G loss: 0.999915]\n",
            "1787 [D loss: 0.999964] [G loss: 0.999911]\n",
            "1788 [D loss: 0.999981] [G loss: 0.999936]\n",
            "1789 [D loss: 1.000056] [G loss: 0.999945]\n",
            "1790 [D loss: 1.000069] [G loss: 0.999891]\n",
            "1791 [D loss: 1.000006] [G loss: 0.999902]\n",
            "1792 [D loss: 1.000042] [G loss: 0.999927]\n",
            "1793 [D loss: 0.999965] [G loss: 0.999914]\n",
            "1794 [D loss: 1.000001] [G loss: 0.999940]\n",
            "1795 [D loss: 1.000055] [G loss: 0.999922]\n",
            "1796 [D loss: 1.000005] [G loss: 0.999928]\n",
            "1797 [D loss: 1.000019] [G loss: 0.999910]\n",
            "1798 [D loss: 1.000023] [G loss: 0.999924]\n",
            "1799 [D loss: 1.000016] [G loss: 0.999894]\n",
            "1800 [D loss: 0.999992] [G loss: 0.999884]\n",
            "1801 [D loss: 1.000033] [G loss: 0.999846]\n",
            "1802 [D loss: 1.000020] [G loss: 0.999874]\n",
            "1803 [D loss: 1.000013] [G loss: 0.999892]\n",
            "1804 [D loss: 1.000026] [G loss: 0.999910]\n",
            "1805 [D loss: 0.999966] [G loss: 0.999881]\n",
            "1806 [D loss: 1.000017] [G loss: 0.999903]\n",
            "1807 [D loss: 1.000009] [G loss: 0.999948]\n",
            "1808 [D loss: 0.999976] [G loss: 0.999911]\n",
            "1809 [D loss: 0.999963] [G loss: 0.999970]\n",
            "1810 [D loss: 1.000162] [G loss: 0.999816]\n",
            "1811 [D loss: 1.000059] [G loss: 0.999874]\n",
            "1812 [D loss: 1.000105] [G loss: 0.999888]\n",
            "1813 [D loss: 0.999949] [G loss: 0.999949]\n",
            "1814 [D loss: 0.999963] [G loss: 0.999933]\n",
            "1815 [D loss: 1.000066] [G loss: 0.999881]\n",
            "1816 [D loss: 1.000000] [G loss: 0.999915]\n",
            "1817 [D loss: 0.999994] [G loss: 0.999932]\n",
            "1818 [D loss: 1.000032] [G loss: 0.999832]\n",
            "1819 [D loss: 1.000074] [G loss: 0.999901]\n",
            "1820 [D loss: 0.999993] [G loss: 0.999934]\n",
            "1821 [D loss: 1.000040] [G loss: 0.999850]\n",
            "1822 [D loss: 1.000006] [G loss: 0.999921]\n",
            "1823 [D loss: 0.999994] [G loss: 0.999903]\n",
            "1824 [D loss: 0.999994] [G loss: 0.999996]\n",
            "1825 [D loss: 1.000065] [G loss: 0.999899]\n",
            "1826 [D loss: 0.999989] [G loss: 0.999983]\n",
            "1827 [D loss: 1.000007] [G loss: 0.999961]\n",
            "1828 [D loss: 0.999971] [G loss: 0.999916]\n",
            "1829 [D loss: 1.000022] [G loss: 0.999917]\n",
            "1830 [D loss: 0.999974] [G loss: 0.999935]\n",
            "1831 [D loss: 1.000001] [G loss: 0.999924]\n",
            "1832 [D loss: 1.000071] [G loss: 0.999853]\n",
            "1833 [D loss: 1.000002] [G loss: 0.999949]\n",
            "1834 [D loss: 1.000029] [G loss: 0.999995]\n",
            "1835 [D loss: 0.999929] [G loss: 0.999892]\n",
            "1836 [D loss: 0.999974] [G loss: 0.999993]\n",
            "1837 [D loss: 0.999996] [G loss: 0.999957]\n",
            "1838 [D loss: 1.000046] [G loss: 0.999903]\n",
            "1839 [D loss: 0.999961] [G loss: 0.999941]\n",
            "1840 [D loss: 0.999983] [G loss: 0.999908]\n",
            "1841 [D loss: 1.000049] [G loss: 0.999885]\n",
            "1842 [D loss: 1.000069] [G loss: 1.000009]\n",
            "1843 [D loss: 0.999986] [G loss: 0.999937]\n",
            "1844 [D loss: 0.999961] [G loss: 0.999882]\n",
            "1845 [D loss: 0.999991] [G loss: 0.999890]\n",
            "1846 [D loss: 0.999952] [G loss: 0.999987]\n",
            "1847 [D loss: 1.000033] [G loss: 0.999924]\n",
            "1848 [D loss: 1.000023] [G loss: 0.999910]\n",
            "1849 [D loss: 1.000085] [G loss: 0.999888]\n",
            "1850 [D loss: 1.000034] [G loss: 0.999934]\n",
            "1851 [D loss: 0.999915] [G loss: 1.000012]\n",
            "1852 [D loss: 0.999951] [G loss: 0.999935]\n",
            "1853 [D loss: 1.000091] [G loss: 0.999868]\n",
            "1854 [D loss: 1.000073] [G loss: 0.999987]\n",
            "1855 [D loss: 0.999925] [G loss: 0.999929]\n",
            "1856 [D loss: 1.000025] [G loss: 0.999949]\n",
            "1857 [D loss: 1.000030] [G loss: 0.999921]\n",
            "1858 [D loss: 1.000018] [G loss: 0.999905]\n",
            "1859 [D loss: 0.999975] [G loss: 0.999916]\n",
            "1860 [D loss: 1.000063] [G loss: 0.999960]\n",
            "1861 [D loss: 1.000064] [G loss: 0.999980]\n",
            "1862 [D loss: 1.000024] [G loss: 0.999976]\n",
            "1863 [D loss: 1.000029] [G loss: 0.999950]\n",
            "1864 [D loss: 1.000038] [G loss: 0.999936]\n",
            "1865 [D loss: 0.999927] [G loss: 0.999947]\n",
            "1866 [D loss: 0.999953] [G loss: 0.999957]\n",
            "1867 [D loss: 1.000053] [G loss: 0.999959]\n",
            "1868 [D loss: 1.000010] [G loss: 0.999942]\n",
            "1869 [D loss: 0.999965] [G loss: 1.000018]\n",
            "1870 [D loss: 0.999980] [G loss: 0.999881]\n",
            "1871 [D loss: 1.000013] [G loss: 0.999913]\n",
            "1872 [D loss: 0.999985] [G loss: 0.999993]\n",
            "1873 [D loss: 1.000035] [G loss: 0.999932]\n",
            "1874 [D loss: 1.000038] [G loss: 0.999915]\n",
            "1875 [D loss: 0.999954] [G loss: 0.999965]\n",
            "1876 [D loss: 1.000012] [G loss: 0.999929]\n",
            "1877 [D loss: 1.000079] [G loss: 0.999970]\n",
            "1878 [D loss: 0.999962] [G loss: 0.999919]\n",
            "1879 [D loss: 1.000036] [G loss: 0.999885]\n",
            "1880 [D loss: 0.999933] [G loss: 0.999937]\n",
            "1881 [D loss: 1.000028] [G loss: 0.999924]\n",
            "1882 [D loss: 0.999909] [G loss: 0.999945]\n",
            "1883 [D loss: 0.999950] [G loss: 0.999992]\n",
            "1884 [D loss: 1.000011] [G loss: 0.999968]\n",
            "1885 [D loss: 0.999982] [G loss: 0.999964]\n",
            "1886 [D loss: 0.999955] [G loss: 0.999990]\n",
            "1887 [D loss: 0.999959] [G loss: 0.999921]\n",
            "1888 [D loss: 0.999979] [G loss: 0.999955]\n",
            "1889 [D loss: 1.000050] [G loss: 0.999917]\n",
            "1890 [D loss: 1.000041] [G loss: 0.999934]\n",
            "1891 [D loss: 1.000045] [G loss: 0.999969]\n",
            "1892 [D loss: 1.000010] [G loss: 0.999915]\n",
            "1893 [D loss: 1.000006] [G loss: 0.999992]\n",
            "1894 [D loss: 1.000013] [G loss: 0.999998]\n",
            "1895 [D loss: 0.999954] [G loss: 1.000023]\n",
            "1896 [D loss: 0.999940] [G loss: 0.999977]\n",
            "1897 [D loss: 0.999966] [G loss: 0.999985]\n",
            "1898 [D loss: 1.000024] [G loss: 0.999948]\n",
            "1899 [D loss: 1.000011] [G loss: 0.999979]\n",
            "1900 [D loss: 1.000019] [G loss: 1.000021]\n",
            "1901 [D loss: 0.999972] [G loss: 1.000100]\n",
            "1902 [D loss: 1.000045] [G loss: 0.999969]\n",
            "1903 [D loss: 1.000029] [G loss: 0.999991]\n",
            "1904 [D loss: 0.999926] [G loss: 1.000025]\n",
            "1905 [D loss: 0.999992] [G loss: 0.999995]\n",
            "1906 [D loss: 0.999903] [G loss: 1.000053]\n",
            "1907 [D loss: 0.999932] [G loss: 0.999985]\n",
            "1908 [D loss: 0.999844] [G loss: 1.000057]\n",
            "1909 [D loss: 0.999989] [G loss: 0.999945]\n",
            "1910 [D loss: 0.999963] [G loss: 1.000039]\n",
            "1911 [D loss: 0.999998] [G loss: 0.999966]\n",
            "1912 [D loss: 1.000060] [G loss: 1.000018]\n",
            "1913 [D loss: 0.999973] [G loss: 1.000014]\n",
            "1914 [D loss: 0.999908] [G loss: 1.000006]\n",
            "1915 [D loss: 0.999997] [G loss: 0.999985]\n",
            "1916 [D loss: 1.000098] [G loss: 0.999955]\n",
            "1917 [D loss: 0.999962] [G loss: 0.999962]\n",
            "1918 [D loss: 0.999965] [G loss: 0.999988]\n",
            "1919 [D loss: 0.999977] [G loss: 1.000022]\n",
            "1920 [D loss: 0.999976] [G loss: 0.999973]\n",
            "1921 [D loss: 0.999956] [G loss: 0.999966]\n",
            "1922 [D loss: 1.000091] [G loss: 0.999903]\n",
            "1923 [D loss: 1.000021] [G loss: 0.999920]\n",
            "1924 [D loss: 0.999984] [G loss: 0.999966]\n",
            "1925 [D loss: 1.000042] [G loss: 0.999970]\n",
            "1926 [D loss: 1.000022] [G loss: 0.999993]\n",
            "1927 [D loss: 1.000026] [G loss: 0.999981]\n",
            "1928 [D loss: 1.000083] [G loss: 0.999973]\n",
            "1929 [D loss: 0.999993] [G loss: 0.999939]\n",
            "1930 [D loss: 0.999958] [G loss: 0.999990]\n",
            "1931 [D loss: 1.000064] [G loss: 0.999993]\n",
            "1932 [D loss: 0.999936] [G loss: 1.000003]\n",
            "1933 [D loss: 0.999991] [G loss: 0.999984]\n",
            "1934 [D loss: 1.000093] [G loss: 1.000004]\n",
            "1935 [D loss: 0.999982] [G loss: 1.000069]\n",
            "1936 [D loss: 0.999960] [G loss: 1.000001]\n",
            "1937 [D loss: 0.999923] [G loss: 1.000027]\n",
            "1938 [D loss: 1.000041] [G loss: 1.000030]\n",
            "1939 [D loss: 0.999959] [G loss: 0.999931]\n",
            "1940 [D loss: 0.999905] [G loss: 1.000107]\n",
            "1941 [D loss: 1.000017] [G loss: 1.000029]\n",
            "1942 [D loss: 0.999981] [G loss: 0.999992]\n",
            "1943 [D loss: 0.999945] [G loss: 0.999977]\n",
            "1944 [D loss: 1.000010] [G loss: 1.000036]\n",
            "1945 [D loss: 0.999909] [G loss: 1.000070]\n",
            "1946 [D loss: 0.999943] [G loss: 1.000012]\n",
            "1947 [D loss: 0.999990] [G loss: 1.000021]\n",
            "1948 [D loss: 1.000073] [G loss: 0.999996]\n",
            "1949 [D loss: 0.999978] [G loss: 1.000032]\n",
            "1950 [D loss: 0.999961] [G loss: 1.000015]\n",
            "1951 [D loss: 0.999998] [G loss: 1.000013]\n",
            "1952 [D loss: 0.999927] [G loss: 1.000005]\n",
            "1953 [D loss: 1.000032] [G loss: 0.999993]\n",
            "1954 [D loss: 0.999998] [G loss: 0.999956]\n",
            "1955 [D loss: 1.000039] [G loss: 1.000020]\n",
            "1956 [D loss: 0.999936] [G loss: 0.999968]\n",
            "1957 [D loss: 1.000042] [G loss: 0.999971]\n",
            "1958 [D loss: 0.999890] [G loss: 1.000026]\n",
            "1959 [D loss: 1.000073] [G loss: 0.999921]\n",
            "1960 [D loss: 1.000023] [G loss: 1.000024]\n",
            "1961 [D loss: 0.999987] [G loss: 0.999954]\n",
            "1962 [D loss: 0.999961] [G loss: 0.999948]\n",
            "1963 [D loss: 1.000033] [G loss: 0.999958]\n",
            "1964 [D loss: 1.000073] [G loss: 0.999959]\n",
            "1965 [D loss: 0.999927] [G loss: 0.999996]\n",
            "1966 [D loss: 0.999989] [G loss: 0.999954]\n",
            "1967 [D loss: 0.999957] [G loss: 0.999983]\n",
            "1968 [D loss: 1.000048] [G loss: 1.000027]\n",
            "1969 [D loss: 0.999962] [G loss: 0.999999]\n",
            "1970 [D loss: 1.000006] [G loss: 0.999928]\n",
            "1971 [D loss: 0.999999] [G loss: 1.000011]\n",
            "1972 [D loss: 1.000006] [G loss: 0.999988]\n",
            "1973 [D loss: 1.000007] [G loss: 1.000024]\n",
            "1974 [D loss: 1.000028] [G loss: 0.999971]\n",
            "1975 [D loss: 1.000049] [G loss: 0.999983]\n",
            "1976 [D loss: 0.999986] [G loss: 0.999970]\n",
            "1977 [D loss: 1.000062] [G loss: 1.000061]\n",
            "1978 [D loss: 1.000029] [G loss: 1.000066]\n",
            "1979 [D loss: 1.000010] [G loss: 0.999942]\n",
            "1980 [D loss: 1.000031] [G loss: 0.999999]\n",
            "1981 [D loss: 0.999962] [G loss: 1.000049]\n",
            "1982 [D loss: 1.000120] [G loss: 0.999942]\n",
            "1983 [D loss: 0.999964] [G loss: 1.000058]\n",
            "1984 [D loss: 1.000003] [G loss: 1.000060]\n",
            "1985 [D loss: 1.000033] [G loss: 1.000052]\n",
            "1986 [D loss: 1.000020] [G loss: 1.000013]\n",
            "1987 [D loss: 0.999935] [G loss: 1.000010]\n",
            "1988 [D loss: 0.999944] [G loss: 1.000039]\n",
            "1989 [D loss: 0.999971] [G loss: 1.000038]\n",
            "1990 [D loss: 0.999993] [G loss: 1.000044]\n",
            "1991 [D loss: 0.999995] [G loss: 1.000084]\n",
            "1992 [D loss: 0.999996] [G loss: 0.999931]\n",
            "1993 [D loss: 0.999986] [G loss: 1.000035]\n",
            "1994 [D loss: 1.000059] [G loss: 0.999989]\n",
            "1995 [D loss: 1.000052] [G loss: 1.000061]\n",
            "1996 [D loss: 1.000004] [G loss: 1.000029]\n",
            "1997 [D loss: 0.999992] [G loss: 0.999986]\n",
            "1998 [D loss: 0.999988] [G loss: 1.000011]\n",
            "1999 [D loss: 1.000038] [G loss: 1.000022]\n",
            "2000 [D loss: 0.999938] [G loss: 1.000079]\n",
            "2001 [D loss: 1.000043] [G loss: 1.000005]\n",
            "2002 [D loss: 1.000020] [G loss: 0.999927]\n",
            "2003 [D loss: 0.999927] [G loss: 0.999994]\n",
            "2004 [D loss: 1.000023] [G loss: 1.000044]\n",
            "2005 [D loss: 1.000000] [G loss: 0.999939]\n",
            "2006 [D loss: 0.999924] [G loss: 1.000008]\n",
            "2007 [D loss: 1.000038] [G loss: 0.999988]\n",
            "2008 [D loss: 0.999866] [G loss: 0.999944]\n",
            "2009 [D loss: 1.000008] [G loss: 0.999980]\n",
            "2010 [D loss: 1.000004] [G loss: 1.000030]\n",
            "2011 [D loss: 0.999963] [G loss: 1.000047]\n",
            "2012 [D loss: 0.999998] [G loss: 1.000006]\n",
            "2013 [D loss: 0.999964] [G loss: 0.999986]\n",
            "2014 [D loss: 0.999994] [G loss: 1.000023]\n",
            "2015 [D loss: 1.000045] [G loss: 0.999971]\n",
            "2016 [D loss: 1.000016] [G loss: 1.000008]\n",
            "2017 [D loss: 0.999974] [G loss: 0.999973]\n",
            "2018 [D loss: 0.999982] [G loss: 0.999929]\n",
            "2019 [D loss: 0.999955] [G loss: 1.000008]\n",
            "2020 [D loss: 1.000033] [G loss: 0.999954]\n",
            "2021 [D loss: 0.999968] [G loss: 0.999990]\n",
            "2022 [D loss: 1.000033] [G loss: 0.999916]\n",
            "2023 [D loss: 1.000003] [G loss: 1.000005]\n",
            "2024 [D loss: 0.999983] [G loss: 0.999986]\n",
            "2025 [D loss: 1.000014] [G loss: 1.000011]\n",
            "2026 [D loss: 0.999984] [G loss: 0.999941]\n",
            "2027 [D loss: 0.999989] [G loss: 0.999913]\n",
            "2028 [D loss: 0.999993] [G loss: 0.999901]\n",
            "2029 [D loss: 1.000004] [G loss: 0.999975]\n",
            "2030 [D loss: 0.999989] [G loss: 0.999977]\n",
            "2031 [D loss: 0.999988] [G loss: 0.999943]\n",
            "2032 [D loss: 1.000100] [G loss: 0.999919]\n",
            "2033 [D loss: 0.999925] [G loss: 0.999994]\n",
            "2034 [D loss: 1.000051] [G loss: 0.999920]\n",
            "2035 [D loss: 0.999990] [G loss: 0.999960]\n",
            "2036 [D loss: 1.000025] [G loss: 0.999937]\n",
            "2037 [D loss: 0.999965] [G loss: 1.000036]\n",
            "2038 [D loss: 1.000027] [G loss: 0.999944]\n",
            "2039 [D loss: 0.999937] [G loss: 0.999999]\n",
            "2040 [D loss: 0.999973] [G loss: 1.000035]\n",
            "2041 [D loss: 0.999979] [G loss: 0.999961]\n",
            "2042 [D loss: 0.999999] [G loss: 1.000001]\n",
            "2043 [D loss: 1.000016] [G loss: 1.000037]\n",
            "2044 [D loss: 1.000050] [G loss: 0.999999]\n",
            "2045 [D loss: 1.000017] [G loss: 0.999930]\n",
            "2046 [D loss: 0.999925] [G loss: 1.000054]\n",
            "2047 [D loss: 0.999999] [G loss: 1.000015]\n",
            "2048 [D loss: 0.999920] [G loss: 0.999973]\n",
            "2049 [D loss: 0.999969] [G loss: 0.999944]\n",
            "2050 [D loss: 0.999981] [G loss: 1.000002]\n",
            "2051 [D loss: 0.999993] [G loss: 1.000019]\n",
            "2052 [D loss: 0.999983] [G loss: 0.999997]\n",
            "2053 [D loss: 0.999999] [G loss: 0.999987]\n",
            "2054 [D loss: 1.000043] [G loss: 0.999975]\n",
            "2055 [D loss: 1.000021] [G loss: 1.000011]\n",
            "2056 [D loss: 1.000023] [G loss: 0.999952]\n",
            "2057 [D loss: 1.000005] [G loss: 1.000017]\n",
            "2058 [D loss: 0.999973] [G loss: 1.000019]\n",
            "2059 [D loss: 1.000074] [G loss: 0.999994]\n",
            "2060 [D loss: 0.999987] [G loss: 0.999988]\n",
            "2061 [D loss: 0.999968] [G loss: 1.000001]\n",
            "2062 [D loss: 0.999998] [G loss: 0.999996]\n",
            "2063 [D loss: 0.999944] [G loss: 0.999993]\n",
            "2064 [D loss: 1.000052] [G loss: 0.999978]\n",
            "2065 [D loss: 0.999981] [G loss: 1.000016]\n",
            "2066 [D loss: 0.999957] [G loss: 0.999992]\n",
            "2067 [D loss: 1.000043] [G loss: 1.000002]\n",
            "2068 [D loss: 0.999982] [G loss: 0.999996]\n",
            "2069 [D loss: 0.999994] [G loss: 1.000007]\n",
            "2070 [D loss: 1.000004] [G loss: 0.999979]\n",
            "2071 [D loss: 0.999986] [G loss: 1.000019]\n",
            "2072 [D loss: 0.999999] [G loss: 1.000000]\n",
            "2073 [D loss: 0.999990] [G loss: 0.999951]\n",
            "2074 [D loss: 1.000037] [G loss: 1.000003]\n",
            "2075 [D loss: 0.999983] [G loss: 1.000012]\n",
            "2076 [D loss: 0.999972] [G loss: 1.000045]\n",
            "2077 [D loss: 0.999987] [G loss: 1.000063]\n",
            "2078 [D loss: 0.999964] [G loss: 1.000022]\n",
            "2079 [D loss: 0.999954] [G loss: 0.999996]\n",
            "2080 [D loss: 1.000087] [G loss: 1.000022]\n",
            "2081 [D loss: 0.999991] [G loss: 1.000021]\n",
            "2082 [D loss: 1.000066] [G loss: 1.000038]\n",
            "2083 [D loss: 0.999984] [G loss: 0.999988]\n",
            "2084 [D loss: 0.999986] [G loss: 0.999981]\n",
            "2085 [D loss: 0.999955] [G loss: 1.000034]\n",
            "2086 [D loss: 1.000014] [G loss: 1.000004]\n",
            "2087 [D loss: 0.999961] [G loss: 1.000009]\n",
            "2088 [D loss: 1.000037] [G loss: 1.000011]\n",
            "2089 [D loss: 0.999989] [G loss: 0.999995]\n",
            "2090 [D loss: 1.000022] [G loss: 0.999974]\n",
            "2091 [D loss: 0.999960] [G loss: 1.000051]\n",
            "2092 [D loss: 1.000042] [G loss: 0.999931]\n",
            "2093 [D loss: 0.999983] [G loss: 0.999984]\n",
            "2094 [D loss: 0.999995] [G loss: 1.000045]\n",
            "2095 [D loss: 0.999997] [G loss: 1.000044]\n",
            "2096 [D loss: 0.999918] [G loss: 1.000063]\n",
            "2097 [D loss: 1.000033] [G loss: 1.000031]\n",
            "2098 [D loss: 1.000010] [G loss: 0.999995]\n",
            "2099 [D loss: 1.000004] [G loss: 1.000047]\n",
            "2100 [D loss: 1.000048] [G loss: 0.999962]\n",
            "2101 [D loss: 1.000002] [G loss: 1.000075]\n",
            "2102 [D loss: 0.999960] [G loss: 1.000056]\n",
            "2103 [D loss: 0.999950] [G loss: 1.000003]\n",
            "2104 [D loss: 1.000015] [G loss: 1.000070]\n",
            "2105 [D loss: 0.999972] [G loss: 1.000051]\n",
            "2106 [D loss: 0.999997] [G loss: 1.000034]\n",
            "2107 [D loss: 1.000054] [G loss: 0.999981]\n",
            "2108 [D loss: 0.999996] [G loss: 0.999981]\n",
            "2109 [D loss: 1.000014] [G loss: 1.000018]\n",
            "2110 [D loss: 1.000015] [G loss: 1.000044]\n",
            "2111 [D loss: 0.999974] [G loss: 1.000009]\n",
            "2112 [D loss: 0.999921] [G loss: 1.000031]\n",
            "2113 [D loss: 0.999977] [G loss: 1.000047]\n",
            "2114 [D loss: 0.999996] [G loss: 1.000011]\n",
            "2115 [D loss: 1.000001] [G loss: 0.999992]\n",
            "2116 [D loss: 0.999984] [G loss: 1.000062]\n",
            "2117 [D loss: 0.999987] [G loss: 1.000036]\n",
            "2118 [D loss: 0.999920] [G loss: 1.000105]\n",
            "2119 [D loss: 0.999982] [G loss: 1.000035]\n",
            "2120 [D loss: 1.000029] [G loss: 1.000045]\n",
            "2121 [D loss: 0.999940] [G loss: 1.000072]\n",
            "2122 [D loss: 0.999991] [G loss: 1.000077]\n",
            "2123 [D loss: 0.999955] [G loss: 1.000093]\n",
            "2124 [D loss: 0.999914] [G loss: 1.000090]\n",
            "2125 [D loss: 0.999967] [G loss: 1.000109]\n",
            "2126 [D loss: 0.999941] [G loss: 1.000085]\n",
            "2127 [D loss: 1.000046] [G loss: 1.000119]\n",
            "2128 [D loss: 1.000018] [G loss: 1.000072]\n",
            "2129 [D loss: 0.999918] [G loss: 1.000055]\n",
            "2130 [D loss: 0.999970] [G loss: 1.000006]\n",
            "2131 [D loss: 1.000021] [G loss: 1.000117]\n",
            "2132 [D loss: 0.999915] [G loss: 1.000091]\n",
            "2133 [D loss: 0.999950] [G loss: 1.000068]\n",
            "2134 [D loss: 1.000016] [G loss: 1.000094]\n",
            "2135 [D loss: 0.999901] [G loss: 1.000064]\n",
            "2136 [D loss: 1.000013] [G loss: 1.000021]\n",
            "2137 [D loss: 0.999954] [G loss: 1.000082]\n",
            "2138 [D loss: 1.000006] [G loss: 1.000055]\n",
            "2139 [D loss: 0.999995] [G loss: 1.000080]\n",
            "2140 [D loss: 0.999955] [G loss: 1.000110]\n",
            "2141 [D loss: 1.000037] [G loss: 1.000087]\n",
            "2142 [D loss: 1.000027] [G loss: 1.000088]\n",
            "2143 [D loss: 1.000003] [G loss: 1.000102]\n",
            "2144 [D loss: 1.000038] [G loss: 1.000086]\n",
            "2145 [D loss: 0.999970] [G loss: 1.000078]\n",
            "2146 [D loss: 0.999974] [G loss: 1.000087]\n",
            "2147 [D loss: 1.000006] [G loss: 1.000056]\n",
            "2148 [D loss: 0.999950] [G loss: 1.000107]\n",
            "2149 [D loss: 1.000023] [G loss: 1.000033]\n",
            "2150 [D loss: 1.000009] [G loss: 1.000064]\n",
            "2151 [D loss: 0.999929] [G loss: 1.000087]\n",
            "2152 [D loss: 0.999949] [G loss: 1.000070]\n",
            "2153 [D loss: 0.999988] [G loss: 0.999997]\n",
            "2154 [D loss: 0.999967] [G loss: 1.000057]\n",
            "2155 [D loss: 0.999951] [G loss: 1.000041]\n",
            "2156 [D loss: 0.999892] [G loss: 1.000047]\n",
            "2157 [D loss: 1.000014] [G loss: 1.000029]\n",
            "2158 [D loss: 1.000018] [G loss: 1.000026]\n",
            "2159 [D loss: 0.999862] [G loss: 1.000088]\n",
            "2160 [D loss: 1.000026] [G loss: 1.000020]\n",
            "2161 [D loss: 0.999963] [G loss: 1.000062]\n",
            "2162 [D loss: 0.999993] [G loss: 1.000065]\n",
            "2163 [D loss: 1.000003] [G loss: 0.999980]\n",
            "2164 [D loss: 1.000015] [G loss: 1.000047]\n",
            "2165 [D loss: 0.999983] [G loss: 1.000050]\n",
            "2166 [D loss: 0.999967] [G loss: 1.000141]\n",
            "2167 [D loss: 0.999981] [G loss: 1.000079]\n",
            "2168 [D loss: 0.999932] [G loss: 1.000058]\n",
            "2169 [D loss: 0.999988] [G loss: 1.000100]\n",
            "2170 [D loss: 0.999970] [G loss: 1.000157]\n",
            "2171 [D loss: 1.000016] [G loss: 1.000104]\n",
            "2172 [D loss: 0.999972] [G loss: 1.000085]\n",
            "2173 [D loss: 1.000016] [G loss: 1.000093]\n",
            "2174 [D loss: 0.999982] [G loss: 1.000093]\n",
            "2175 [D loss: 0.999982] [G loss: 1.000035]\n",
            "2176 [D loss: 1.000030] [G loss: 1.000059]\n",
            "2177 [D loss: 1.000017] [G loss: 1.000145]\n",
            "2178 [D loss: 0.999934] [G loss: 1.000134]\n",
            "2179 [D loss: 0.999983] [G loss: 1.000060]\n",
            "2180 [D loss: 0.999969] [G loss: 1.000065]\n",
            "2181 [D loss: 0.999975] [G loss: 1.000064]\n",
            "2182 [D loss: 0.999980] [G loss: 1.000053]\n",
            "2183 [D loss: 0.999963] [G loss: 1.000024]\n",
            "2184 [D loss: 0.999953] [G loss: 1.000070]\n",
            "2185 [D loss: 0.999932] [G loss: 1.000082]\n",
            "2186 [D loss: 0.999990] [G loss: 1.000039]\n",
            "2187 [D loss: 0.999932] [G loss: 1.000010]\n",
            "2188 [D loss: 1.000008] [G loss: 1.000004]\n",
            "2189 [D loss: 0.999916] [G loss: 1.000088]\n",
            "2190 [D loss: 1.000012] [G loss: 1.000027]\n",
            "2191 [D loss: 1.000014] [G loss: 1.000068]\n",
            "2192 [D loss: 0.999949] [G loss: 1.000049]\n",
            "2193 [D loss: 1.000032] [G loss: 1.000161]\n",
            "2194 [D loss: 0.999977] [G loss: 1.000034]\n",
            "2195 [D loss: 0.999992] [G loss: 1.000082]\n",
            "2196 [D loss: 1.000001] [G loss: 1.000081]\n",
            "2197 [D loss: 0.999990] [G loss: 1.000039]\n",
            "2198 [D loss: 0.999971] [G loss: 1.000070]\n",
            "2199 [D loss: 1.000006] [G loss: 1.000029]\n",
            "2200 [D loss: 0.999985] [G loss: 1.000034]\n",
            "2201 [D loss: 1.000005] [G loss: 1.000045]\n",
            "2202 [D loss: 0.999972] [G loss: 1.000061]\n",
            "2203 [D loss: 1.000011] [G loss: 1.000034]\n",
            "2204 [D loss: 0.999954] [G loss: 1.000080]\n",
            "2205 [D loss: 0.999957] [G loss: 1.000034]\n",
            "2206 [D loss: 1.000066] [G loss: 0.999988]\n",
            "2207 [D loss: 0.999918] [G loss: 1.000140]\n",
            "2208 [D loss: 1.000020] [G loss: 1.000055]\n",
            "2209 [D loss: 0.999998] [G loss: 1.000096]\n",
            "2210 [D loss: 0.999990] [G loss: 1.000060]\n",
            "2211 [D loss: 0.999962] [G loss: 1.000118]\n",
            "2212 [D loss: 1.000069] [G loss: 1.000027]\n",
            "2213 [D loss: 0.999998] [G loss: 1.000021]\n",
            "2214 [D loss: 1.000026] [G loss: 1.000038]\n",
            "2215 [D loss: 1.000005] [G loss: 1.000074]\n",
            "2216 [D loss: 0.999989] [G loss: 1.000073]\n",
            "2217 [D loss: 0.999957] [G loss: 1.000074]\n",
            "2218 [D loss: 0.999968] [G loss: 1.000011]\n",
            "2219 [D loss: 1.000010] [G loss: 1.000023]\n",
            "2220 [D loss: 0.999972] [G loss: 1.000053]\n",
            "2221 [D loss: 1.000028] [G loss: 1.000032]\n",
            "2222 [D loss: 0.999922] [G loss: 1.000062]\n",
            "2223 [D loss: 1.000015] [G loss: 1.000068]\n",
            "2224 [D loss: 1.000015] [G loss: 0.999965]\n",
            "2225 [D loss: 0.999955] [G loss: 1.000014]\n",
            "2226 [D loss: 1.000020] [G loss: 0.999968]\n",
            "2227 [D loss: 0.999974] [G loss: 1.000025]\n",
            "2228 [D loss: 0.999893] [G loss: 1.000028]\n",
            "2229 [D loss: 0.999996] [G loss: 1.000001]\n",
            "2230 [D loss: 0.999947] [G loss: 1.000013]\n",
            "2231 [D loss: 0.999984] [G loss: 1.000011]\n",
            "2232 [D loss: 0.999985] [G loss: 1.000043]\n",
            "2233 [D loss: 0.999972] [G loss: 1.000015]\n",
            "2234 [D loss: 0.999940] [G loss: 1.000048]\n",
            "2235 [D loss: 0.999917] [G loss: 1.000060]\n",
            "2236 [D loss: 0.999996] [G loss: 1.000028]\n",
            "2237 [D loss: 0.999960] [G loss: 1.000064]\n",
            "2238 [D loss: 0.999977] [G loss: 1.000002]\n",
            "2239 [D loss: 0.999937] [G loss: 1.000016]\n",
            "2240 [D loss: 1.000044] [G loss: 0.999983]\n",
            "2241 [D loss: 1.000053] [G loss: 0.999990]\n",
            "2242 [D loss: 0.999923] [G loss: 1.000027]\n",
            "2243 [D loss: 1.000002] [G loss: 1.000021]\n",
            "2244 [D loss: 0.999916] [G loss: 1.000032]\n",
            "2245 [D loss: 1.000020] [G loss: 1.000058]\n",
            "2246 [D loss: 0.999981] [G loss: 1.000012]\n",
            "2247 [D loss: 1.000017] [G loss: 1.000042]\n",
            "2248 [D loss: 1.000022] [G loss: 1.000029]\n",
            "2249 [D loss: 1.000015] [G loss: 1.000031]\n",
            "2250 [D loss: 0.999989] [G loss: 1.000049]\n",
            "2251 [D loss: 0.999963] [G loss: 1.000063]\n",
            "2252 [D loss: 1.000039] [G loss: 0.999993]\n",
            "2253 [D loss: 0.999967] [G loss: 1.000015]\n",
            "2254 [D loss: 1.000045] [G loss: 1.000091]\n",
            "2255 [D loss: 0.999963] [G loss: 1.000047]\n",
            "2256 [D loss: 0.999986] [G loss: 1.000002]\n",
            "2257 [D loss: 0.999992] [G loss: 1.000042]\n",
            "2258 [D loss: 1.000010] [G loss: 1.000030]\n",
            "2259 [D loss: 1.000000] [G loss: 1.000060]\n",
            "2260 [D loss: 0.999980] [G loss: 1.000035]\n",
            "2261 [D loss: 1.000024] [G loss: 0.999989]\n",
            "2262 [D loss: 1.000013] [G loss: 1.000040]\n",
            "2263 [D loss: 0.999934] [G loss: 0.999978]\n",
            "2264 [D loss: 0.999950] [G loss: 1.000007]\n",
            "2265 [D loss: 0.999953] [G loss: 1.000041]\n",
            "2266 [D loss: 1.000015] [G loss: 0.999943]\n",
            "2267 [D loss: 0.999955] [G loss: 1.000018]\n",
            "2268 [D loss: 0.999996] [G loss: 1.000007]\n",
            "2269 [D loss: 1.000031] [G loss: 0.999975]\n",
            "2270 [D loss: 1.000000] [G loss: 0.999951]\n",
            "2271 [D loss: 1.000026] [G loss: 0.999987]\n",
            "2272 [D loss: 1.000041] [G loss: 0.999956]\n",
            "2273 [D loss: 0.999913] [G loss: 0.999960]\n",
            "2274 [D loss: 0.999981] [G loss: 0.999991]\n",
            "2275 [D loss: 0.999992] [G loss: 1.000005]\n",
            "2276 [D loss: 0.999963] [G loss: 1.000004]\n",
            "2277 [D loss: 0.999954] [G loss: 0.999976]\n",
            "2278 [D loss: 0.999986] [G loss: 0.999994]\n",
            "2279 [D loss: 0.999994] [G loss: 0.999981]\n",
            "2280 [D loss: 0.999984] [G loss: 1.000004]\n",
            "2281 [D loss: 0.999950] [G loss: 0.999972]\n",
            "2282 [D loss: 0.999965] [G loss: 0.999961]\n",
            "2283 [D loss: 0.999934] [G loss: 0.999985]\n",
            "2284 [D loss: 0.999998] [G loss: 0.999959]\n",
            "2285 [D loss: 0.999973] [G loss: 0.999978]\n",
            "2286 [D loss: 0.999957] [G loss: 0.999972]\n",
            "2287 [D loss: 1.000008] [G loss: 0.999989]\n",
            "2288 [D loss: 0.999972] [G loss: 0.999971]\n",
            "2289 [D loss: 0.999950] [G loss: 0.999985]\n",
            "2290 [D loss: 0.999988] [G loss: 1.000000]\n",
            "2291 [D loss: 0.999967] [G loss: 0.999956]\n",
            "2292 [D loss: 1.000027] [G loss: 0.999946]\n",
            "2293 [D loss: 0.999959] [G loss: 1.000045]\n",
            "2294 [D loss: 0.999987] [G loss: 0.999936]\n",
            "2295 [D loss: 0.999960] [G loss: 0.999992]\n",
            "2296 [D loss: 1.000014] [G loss: 0.999959]\n",
            "2297 [D loss: 0.999985] [G loss: 0.999972]\n",
            "2298 [D loss: 1.000013] [G loss: 1.000022]\n",
            "2299 [D loss: 0.999964] [G loss: 1.000011]\n",
            "2300 [D loss: 0.999955] [G loss: 0.999993]\n",
            "2301 [D loss: 1.000024] [G loss: 0.999978]\n",
            "2302 [D loss: 0.999997] [G loss: 1.000063]\n",
            "2303 [D loss: 0.999996] [G loss: 0.999962]\n",
            "2304 [D loss: 0.999973] [G loss: 0.999968]\n",
            "2305 [D loss: 0.999984] [G loss: 1.000045]\n",
            "2306 [D loss: 1.000039] [G loss: 0.999956]\n",
            "2307 [D loss: 0.999938] [G loss: 1.000030]\n",
            "2308 [D loss: 1.000000] [G loss: 1.000044]\n",
            "2309 [D loss: 0.999981] [G loss: 0.999990]\n",
            "2310 [D loss: 0.999974] [G loss: 1.000054]\n",
            "2311 [D loss: 0.999953] [G loss: 1.000001]\n",
            "2312 [D loss: 1.000027] [G loss: 1.000025]\n",
            "2313 [D loss: 1.000017] [G loss: 1.000019]\n",
            "2314 [D loss: 1.000010] [G loss: 1.000016]\n",
            "2315 [D loss: 1.000003] [G loss: 1.000001]\n",
            "2316 [D loss: 0.999980] [G loss: 1.000034]\n",
            "2317 [D loss: 0.999998] [G loss: 1.000033]\n",
            "2318 [D loss: 0.999986] [G loss: 0.999985]\n",
            "2319 [D loss: 0.999984] [G loss: 1.000013]\n",
            "2320 [D loss: 1.000020] [G loss: 0.999979]\n",
            "2321 [D loss: 0.999960] [G loss: 1.000064]\n",
            "2322 [D loss: 1.000007] [G loss: 1.000025]\n",
            "2323 [D loss: 0.999985] [G loss: 1.000028]\n",
            "2324 [D loss: 0.999903] [G loss: 1.000095]\n",
            "2325 [D loss: 0.999992] [G loss: 1.000045]\n",
            "2326 [D loss: 0.999954] [G loss: 0.999998]\n",
            "2327 [D loss: 0.999925] [G loss: 1.000040]\n",
            "2328 [D loss: 0.999968] [G loss: 1.000038]\n",
            "2329 [D loss: 0.999997] [G loss: 1.000052]\n",
            "2330 [D loss: 0.999985] [G loss: 1.000019]\n",
            "2331 [D loss: 0.999961] [G loss: 1.000000]\n",
            "2332 [D loss: 1.000003] [G loss: 1.000022]\n",
            "2333 [D loss: 0.999979] [G loss: 1.000043]\n",
            "2334 [D loss: 1.000003] [G loss: 1.000021]\n",
            "2335 [D loss: 0.999921] [G loss: 1.000038]\n",
            "2336 [D loss: 0.999969] [G loss: 1.000040]\n",
            "2337 [D loss: 0.999964] [G loss: 1.000043]\n",
            "2338 [D loss: 0.999994] [G loss: 1.000005]\n",
            "2339 [D loss: 0.999925] [G loss: 1.000033]\n",
            "2340 [D loss: 0.999956] [G loss: 1.000003]\n",
            "2341 [D loss: 0.999940] [G loss: 1.000034]\n",
            "2342 [D loss: 0.999965] [G loss: 1.000013]\n",
            "2343 [D loss: 0.999985] [G loss: 1.000021]\n",
            "2344 [D loss: 0.999966] [G loss: 1.000033]\n",
            "2345 [D loss: 0.999893] [G loss: 1.000075]\n",
            "2346 [D loss: 0.999911] [G loss: 1.000063]\n",
            "2347 [D loss: 0.999990] [G loss: 0.999995]\n",
            "2348 [D loss: 0.999994] [G loss: 0.999918]\n",
            "2349 [D loss: 0.999952] [G loss: 1.000000]\n",
            "2350 [D loss: 1.000053] [G loss: 0.999968]\n",
            "2351 [D loss: 0.999948] [G loss: 1.000030]\n",
            "2352 [D loss: 0.999928] [G loss: 1.000014]\n",
            "2353 [D loss: 0.999948] [G loss: 1.000033]\n",
            "2354 [D loss: 0.999956] [G loss: 0.999991]\n",
            "2355 [D loss: 0.999968] [G loss: 1.000035]\n",
            "2356 [D loss: 0.999994] [G loss: 1.000025]\n",
            "2357 [D loss: 0.999998] [G loss: 1.000024]\n",
            "2358 [D loss: 0.999956] [G loss: 1.000007]\n",
            "2359 [D loss: 1.000006] [G loss: 1.000062]\n",
            "2360 [D loss: 0.999974] [G loss: 0.999994]\n",
            "2361 [D loss: 0.999971] [G loss: 1.000019]\n",
            "2362 [D loss: 0.999961] [G loss: 1.000045]\n",
            "2363 [D loss: 1.000022] [G loss: 0.999975]\n",
            "2364 [D loss: 0.999952] [G loss: 0.999992]\n",
            "2365 [D loss: 1.000034] [G loss: 0.999984]\n",
            "2366 [D loss: 0.999960] [G loss: 1.000014]\n",
            "2367 [D loss: 0.999927] [G loss: 0.999997]\n",
            "2368 [D loss: 0.999974] [G loss: 1.000015]\n",
            "2369 [D loss: 0.999925] [G loss: 1.000047]\n",
            "2370 [D loss: 0.999941] [G loss: 1.000014]\n",
            "2371 [D loss: 1.000015] [G loss: 1.000025]\n",
            "2372 [D loss: 0.999942] [G loss: 1.000010]\n",
            "2373 [D loss: 0.999967] [G loss: 1.000014]\n",
            "2374 [D loss: 0.999990] [G loss: 0.999968]\n",
            "2375 [D loss: 0.999943] [G loss: 0.999977]\n",
            "2376 [D loss: 0.999979] [G loss: 1.000036]\n",
            "2377 [D loss: 0.999962] [G loss: 1.000008]\n",
            "2378 [D loss: 0.999969] [G loss: 1.000003]\n",
            "2379 [D loss: 0.999980] [G loss: 1.000044]\n",
            "2380 [D loss: 0.999995] [G loss: 1.000000]\n",
            "2381 [D loss: 0.999958] [G loss: 1.000031]\n",
            "2382 [D loss: 1.000030] [G loss: 0.999961]\n",
            "2383 [D loss: 0.999992] [G loss: 1.000013]\n",
            "2384 [D loss: 0.999968] [G loss: 1.000076]\n",
            "2385 [D loss: 0.999979] [G loss: 1.000006]\n",
            "2386 [D loss: 0.999941] [G loss: 1.000036]\n",
            "2387 [D loss: 0.999964] [G loss: 1.000034]\n",
            "2388 [D loss: 0.999854] [G loss: 1.000033]\n",
            "2389 [D loss: 0.999967] [G loss: 1.000042]\n",
            "2390 [D loss: 0.999906] [G loss: 1.000004]\n",
            "2391 [D loss: 0.999995] [G loss: 1.000016]\n",
            "2392 [D loss: 0.999949] [G loss: 0.999997]\n",
            "2393 [D loss: 0.999972] [G loss: 1.000014]\n",
            "2394 [D loss: 0.999985] [G loss: 1.000047]\n",
            "2395 [D loss: 0.999991] [G loss: 0.999995]\n",
            "2396 [D loss: 0.999897] [G loss: 1.000040]\n",
            "2397 [D loss: 0.999965] [G loss: 0.999999]\n",
            "2398 [D loss: 0.999950] [G loss: 1.000000]\n",
            "2399 [D loss: 0.999963] [G loss: 0.999976]\n",
            "2400 [D loss: 1.000028] [G loss: 0.999984]\n",
            "2401 [D loss: 0.999970] [G loss: 1.000006]\n",
            "2402 [D loss: 0.999954] [G loss: 0.999946]\n",
            "2403 [D loss: 0.999962] [G loss: 0.999958]\n",
            "2404 [D loss: 0.999898] [G loss: 0.999979]\n",
            "2405 [D loss: 1.000016] [G loss: 0.999988]\n",
            "2406 [D loss: 0.999999] [G loss: 0.999961]\n",
            "2407 [D loss: 0.999965] [G loss: 1.000001]\n",
            "2408 [D loss: 0.999939] [G loss: 1.000027]\n",
            "2409 [D loss: 0.999989] [G loss: 1.000003]\n",
            "2410 [D loss: 1.000003] [G loss: 0.999965]\n",
            "2411 [D loss: 0.999970] [G loss: 1.000056]\n",
            "2412 [D loss: 0.999955] [G loss: 1.000054]\n",
            "2413 [D loss: 1.000008] [G loss: 0.999990]\n",
            "2414 [D loss: 1.000040] [G loss: 1.000022]\n",
            "2415 [D loss: 1.000003] [G loss: 1.000011]\n",
            "2416 [D loss: 1.000019] [G loss: 1.000021]\n",
            "2417 [D loss: 0.999965] [G loss: 1.000018]\n",
            "2418 [D loss: 1.000000] [G loss: 1.000023]\n",
            "2419 [D loss: 1.000007] [G loss: 0.999993]\n",
            "2420 [D loss: 0.999946] [G loss: 1.000041]\n",
            "2421 [D loss: 0.999982] [G loss: 1.000044]\n",
            "2422 [D loss: 1.000030] [G loss: 1.000016]\n",
            "2423 [D loss: 0.999979] [G loss: 1.000038]\n",
            "2424 [D loss: 1.000009] [G loss: 0.999977]\n",
            "2425 [D loss: 0.999896] [G loss: 1.000046]\n",
            "2426 [D loss: 0.999986] [G loss: 1.000067]\n",
            "2427 [D loss: 0.999918] [G loss: 1.000073]\n",
            "2428 [D loss: 0.999956] [G loss: 1.000074]\n",
            "2429 [D loss: 0.999974] [G loss: 1.000057]\n",
            "2430 [D loss: 1.000010] [G loss: 1.000025]\n",
            "2431 [D loss: 0.999948] [G loss: 1.000036]\n",
            "2432 [D loss: 0.999948] [G loss: 1.000048]\n",
            "2433 [D loss: 0.999930] [G loss: 1.000034]\n",
            "2434 [D loss: 0.999942] [G loss: 1.000006]\n",
            "2435 [D loss: 0.999992] [G loss: 1.000049]\n",
            "2436 [D loss: 0.999972] [G loss: 1.000008]\n",
            "2437 [D loss: 0.999974] [G loss: 1.000022]\n",
            "2438 [D loss: 0.999943] [G loss: 1.000045]\n",
            "2439 [D loss: 0.999937] [G loss: 1.000079]\n",
            "2440 [D loss: 0.999995] [G loss: 0.999992]\n",
            "2441 [D loss: 0.999916] [G loss: 0.999998]\n",
            "2442 [D loss: 0.999964] [G loss: 1.000005]\n",
            "2443 [D loss: 0.999963] [G loss: 1.000050]\n",
            "2444 [D loss: 0.999957] [G loss: 1.000016]\n",
            "2445 [D loss: 0.999956] [G loss: 1.000048]\n",
            "2446 [D loss: 0.999992] [G loss: 1.000033]\n",
            "2447 [D loss: 0.999978] [G loss: 1.000038]\n",
            "2448 [D loss: 1.000016] [G loss: 0.999984]\n",
            "2449 [D loss: 0.999976] [G loss: 1.000023]\n",
            "2450 [D loss: 0.999984] [G loss: 1.000086]\n",
            "2451 [D loss: 0.999950] [G loss: 0.999998]\n",
            "2452 [D loss: 0.999990] [G loss: 1.000008]\n",
            "2453 [D loss: 0.999977] [G loss: 0.999986]\n",
            "2454 [D loss: 1.000044] [G loss: 0.999956]\n",
            "2455 [D loss: 0.999935] [G loss: 1.000014]\n",
            "2456 [D loss: 0.999944] [G loss: 0.999995]\n",
            "2457 [D loss: 0.999966] [G loss: 1.000000]\n",
            "2458 [D loss: 0.999996] [G loss: 1.000055]\n",
            "2459 [D loss: 1.000018] [G loss: 0.999993]\n",
            "2460 [D loss: 0.999942] [G loss: 1.000031]\n",
            "2461 [D loss: 0.999938] [G loss: 1.000015]\n",
            "2462 [D loss: 0.999975] [G loss: 1.000028]\n",
            "2463 [D loss: 0.999996] [G loss: 1.000037]\n",
            "2464 [D loss: 0.999949] [G loss: 1.000009]\n",
            "2465 [D loss: 0.999964] [G loss: 1.000039]\n",
            "2466 [D loss: 1.000014] [G loss: 1.000016]\n",
            "2467 [D loss: 0.999950] [G loss: 1.000058]\n",
            "2468 [D loss: 0.999930] [G loss: 1.000059]\n",
            "2469 [D loss: 0.999989] [G loss: 1.000028]\n",
            "2470 [D loss: 0.999959] [G loss: 0.999988]\n",
            "2471 [D loss: 0.999945] [G loss: 1.000016]\n",
            "2472 [D loss: 0.999968] [G loss: 1.000012]\n",
            "2473 [D loss: 0.999954] [G loss: 1.000010]\n",
            "2474 [D loss: 0.999954] [G loss: 1.000040]\n",
            "2475 [D loss: 0.999960] [G loss: 1.000046]\n",
            "2476 [D loss: 0.999960] [G loss: 1.000031]\n",
            "2477 [D loss: 0.999985] [G loss: 1.000043]\n",
            "2478 [D loss: 0.999946] [G loss: 1.000046]\n",
            "2479 [D loss: 0.999985] [G loss: 1.000010]\n",
            "2480 [D loss: 0.999936] [G loss: 1.000042]\n",
            "2481 [D loss: 0.999972] [G loss: 1.000032]\n",
            "2482 [D loss: 0.999942] [G loss: 1.000026]\n",
            "2483 [D loss: 0.999986] [G loss: 1.000026]\n",
            "2484 [D loss: 0.999960] [G loss: 1.000015]\n",
            "2485 [D loss: 0.999959] [G loss: 1.000024]\n",
            "2486 [D loss: 0.999948] [G loss: 1.000062]\n",
            "2487 [D loss: 0.999947] [G loss: 1.000014]\n",
            "2488 [D loss: 0.999958] [G loss: 1.000022]\n",
            "2489 [D loss: 0.999970] [G loss: 1.000024]\n",
            "2490 [D loss: 0.999934] [G loss: 0.999986]\n",
            "2491 [D loss: 0.999960] [G loss: 1.000018]\n",
            "2492 [D loss: 0.999985] [G loss: 1.000002]\n",
            "2493 [D loss: 0.999951] [G loss: 1.000057]\n",
            "2494 [D loss: 0.999957] [G loss: 0.999990]\n",
            "2495 [D loss: 0.999930] [G loss: 1.000031]\n",
            "2496 [D loss: 0.999972] [G loss: 1.000008]\n",
            "2497 [D loss: 0.999962] [G loss: 1.000031]\n",
            "2498 [D loss: 0.999990] [G loss: 1.000009]\n",
            "2499 [D loss: 0.999957] [G loss: 1.000083]\n",
            "2500 [D loss: 1.000001] [G loss: 1.000038]\n",
            "2501 [D loss: 0.999957] [G loss: 1.000053]\n",
            "2502 [D loss: 0.999981] [G loss: 1.000021]\n",
            "2503 [D loss: 0.999987] [G loss: 1.000019]\n",
            "2504 [D loss: 1.000000] [G loss: 1.000038]\n",
            "2505 [D loss: 0.999983] [G loss: 1.000051]\n",
            "2506 [D loss: 0.999956] [G loss: 1.000035]\n",
            "2507 [D loss: 1.000003] [G loss: 1.000028]\n",
            "2508 [D loss: 0.999956] [G loss: 1.000037]\n",
            "2509 [D loss: 0.999979] [G loss: 1.000025]\n",
            "2510 [D loss: 0.999992] [G loss: 0.999989]\n",
            "2511 [D loss: 0.999917] [G loss: 1.000053]\n",
            "2512 [D loss: 0.999973] [G loss: 1.000029]\n",
            "2513 [D loss: 0.999993] [G loss: 1.000038]\n",
            "2514 [D loss: 0.999987] [G loss: 1.000018]\n",
            "2515 [D loss: 0.999952] [G loss: 1.000018]\n",
            "2516 [D loss: 0.999972] [G loss: 1.000046]\n",
            "2517 [D loss: 0.999997] [G loss: 1.000005]\n",
            "2518 [D loss: 0.999969] [G loss: 1.000040]\n",
            "2519 [D loss: 0.999952] [G loss: 1.000004]\n",
            "2520 [D loss: 0.999988] [G loss: 1.000048]\n",
            "2521 [D loss: 0.999965] [G loss: 1.000019]\n",
            "2522 [D loss: 0.999987] [G loss: 1.000039]\n",
            "2523 [D loss: 0.999976] [G loss: 1.000055]\n",
            "2524 [D loss: 1.000024] [G loss: 1.000018]\n",
            "2525 [D loss: 0.999960] [G loss: 1.000023]\n",
            "2526 [D loss: 0.999995] [G loss: 1.000037]\n",
            "2527 [D loss: 0.999968] [G loss: 1.000026]\n",
            "2528 [D loss: 0.999971] [G loss: 1.000045]\n",
            "2529 [D loss: 0.999967] [G loss: 1.000018]\n",
            "2530 [D loss: 0.999959] [G loss: 1.000045]\n",
            "2531 [D loss: 0.999914] [G loss: 1.000031]\n",
            "2532 [D loss: 0.999977] [G loss: 1.000075]\n",
            "2533 [D loss: 1.000017] [G loss: 1.000052]\n",
            "2534 [D loss: 1.000009] [G loss: 1.000028]\n",
            "2535 [D loss: 0.999945] [G loss: 1.000052]\n",
            "2536 [D loss: 0.999965] [G loss: 1.000054]\n",
            "2537 [D loss: 0.999987] [G loss: 1.000030]\n",
            "2538 [D loss: 0.999992] [G loss: 1.000030]\n",
            "2539 [D loss: 0.999948] [G loss: 1.000049]\n",
            "2540 [D loss: 1.000007] [G loss: 0.999989]\n",
            "2541 [D loss: 0.999984] [G loss: 1.000045]\n",
            "2542 [D loss: 0.999952] [G loss: 1.000045]\n",
            "2543 [D loss: 1.000032] [G loss: 1.000038]\n",
            "2544 [D loss: 0.999984] [G loss: 1.000039]\n",
            "2545 [D loss: 0.999984] [G loss: 1.000021]\n",
            "2546 [D loss: 0.999964] [G loss: 1.000013]\n",
            "2547 [D loss: 0.999959] [G loss: 1.000060]\n",
            "2548 [D loss: 0.999987] [G loss: 1.000026]\n",
            "2549 [D loss: 1.000008] [G loss: 0.999988]\n",
            "2550 [D loss: 0.999963] [G loss: 1.000026]\n",
            "2551 [D loss: 0.999964] [G loss: 1.000057]\n",
            "2552 [D loss: 0.999958] [G loss: 1.000072]\n",
            "2553 [D loss: 1.000000] [G loss: 1.000028]\n",
            "2554 [D loss: 0.999972] [G loss: 1.000036]\n",
            "2555 [D loss: 1.000007] [G loss: 1.000016]\n",
            "2556 [D loss: 0.999990] [G loss: 1.000014]\n",
            "2557 [D loss: 1.000008] [G loss: 1.000029]\n",
            "2558 [D loss: 0.999998] [G loss: 1.000001]\n",
            "2559 [D loss: 0.999967] [G loss: 1.000016]\n",
            "2560 [D loss: 1.000020] [G loss: 1.000004]\n",
            "2561 [D loss: 0.999975] [G loss: 1.000023]\n",
            "2562 [D loss: 0.999990] [G loss: 1.000017]\n",
            "2563 [D loss: 1.000012] [G loss: 1.000047]\n",
            "2564 [D loss: 0.999997] [G loss: 1.000016]\n",
            "2565 [D loss: 0.999967] [G loss: 0.999985]\n",
            "2566 [D loss: 0.999997] [G loss: 1.000009]\n",
            "2567 [D loss: 0.999954] [G loss: 1.000035]\n",
            "2568 [D loss: 0.999948] [G loss: 1.000033]\n",
            "2569 [D loss: 0.999992] [G loss: 1.000024]\n",
            "2570 [D loss: 0.999958] [G loss: 1.000009]\n",
            "2571 [D loss: 1.000010] [G loss: 1.000016]\n",
            "2572 [D loss: 0.999986] [G loss: 1.000026]\n",
            "2573 [D loss: 0.999980] [G loss: 1.000068]\n",
            "2574 [D loss: 1.000001] [G loss: 1.000010]\n",
            "2575 [D loss: 0.999970] [G loss: 0.999973]\n",
            "2576 [D loss: 0.999996] [G loss: 1.000045]\n",
            "2577 [D loss: 1.000007] [G loss: 1.000044]\n",
            "2578 [D loss: 0.999992] [G loss: 1.000011]\n",
            "2579 [D loss: 1.000037] [G loss: 1.000031]\n",
            "2580 [D loss: 1.000029] [G loss: 1.000017]\n",
            "2581 [D loss: 0.999943] [G loss: 1.000022]\n",
            "2582 [D loss: 0.999977] [G loss: 1.000044]\n",
            "2583 [D loss: 0.999987] [G loss: 0.999997]\n",
            "2584 [D loss: 1.000014] [G loss: 0.999996]\n",
            "2585 [D loss: 0.999988] [G loss: 0.999940]\n",
            "2586 [D loss: 1.000044] [G loss: 0.999972]\n",
            "2587 [D loss: 0.999978] [G loss: 0.999982]\n",
            "2588 [D loss: 0.999952] [G loss: 0.999971]\n",
            "2589 [D loss: 0.999974] [G loss: 0.999976]\n",
            "2590 [D loss: 1.000009] [G loss: 0.999992]\n",
            "2591 [D loss: 0.999933] [G loss: 1.000021]\n",
            "2592 [D loss: 0.999952] [G loss: 1.000012]\n",
            "2593 [D loss: 1.000116] [G loss: 1.000011]\n",
            "2594 [D loss: 1.000253] [G loss: 0.999935]\n",
            "2595 [D loss: 0.999959] [G loss: 1.000057]\n",
            "2596 [D loss: 1.000048] [G loss: 1.000080]\n",
            "2597 [D loss: 1.000088] [G loss: 1.000124]\n",
            "2598 [D loss: 0.999968] [G loss: 1.000145]\n",
            "2599 [D loss: 1.000099] [G loss: 1.000247]\n",
            "2600 [D loss: 1.000249] [G loss: 1.000090]\n",
            "2601 [D loss: 0.999932] [G loss: 1.000272]\n",
            "2602 [D loss: 1.000220] [G loss: 1.000104]\n",
            "2603 [D loss: 1.000006] [G loss: 1.000128]\n",
            "2604 [D loss: 1.000029] [G loss: 1.000255]\n",
            "2605 [D loss: 1.000077] [G loss: 1.000222]\n",
            "2606 [D loss: 1.000038] [G loss: 1.000160]\n",
            "2607 [D loss: 1.000056] [G loss: 1.000297]\n",
            "2608 [D loss: 1.000060] [G loss: 1.000273]\n",
            "2609 [D loss: 0.999963] [G loss: 1.000306]\n",
            "2610 [D loss: 0.999931] [G loss: 1.000517]\n",
            "2611 [D loss: 0.999661] [G loss: 1.000244]\n",
            "2612 [D loss: 1.000127] [G loss: 1.000281]\n",
            "2613 [D loss: 1.000334] [G loss: 1.000234]\n",
            "2614 [D loss: 0.999904] [G loss: 1.000278]\n",
            "2615 [D loss: 0.999954] [G loss: 1.000275]\n",
            "2616 [D loss: 0.999776] [G loss: 1.000541]\n",
            "2617 [D loss: 1.000080] [G loss: 1.000223]\n",
            "2618 [D loss: 0.999909] [G loss: 1.000229]\n",
            "2619 [D loss: 0.999879] [G loss: 1.000297]\n",
            "2620 [D loss: 1.000167] [G loss: 1.000191]\n",
            "2621 [D loss: 0.999936] [G loss: 1.000261]\n",
            "2622 [D loss: 1.000334] [G loss: 1.000221]\n",
            "2623 [D loss: 0.999848] [G loss: 1.000146]\n",
            "2624 [D loss: 0.999764] [G loss: 1.000239]\n",
            "2625 [D loss: 0.999945] [G loss: 1.000084]\n",
            "2626 [D loss: 1.000106] [G loss: 0.999973]\n",
            "2627 [D loss: 1.000049] [G loss: 1.000036]\n",
            "2628 [D loss: 1.000086] [G loss: 0.999877]\n",
            "2629 [D loss: 0.999948] [G loss: 0.999899]\n",
            "2630 [D loss: 0.999878] [G loss: 0.999858]\n",
            "2631 [D loss: 0.999950] [G loss: 0.999861]\n",
            "2632 [D loss: 1.000109] [G loss: 0.999860]\n",
            "2633 [D loss: 0.999995] [G loss: 0.999817]\n",
            "2634 [D loss: 0.999914] [G loss: 0.999917]\n",
            "2635 [D loss: 0.999835] [G loss: 0.999828]\n",
            "2636 [D loss: 1.000098] [G loss: 0.999828]\n",
            "2637 [D loss: 0.999929] [G loss: 0.999854]\n",
            "2638 [D loss: 0.999985] [G loss: 0.999893]\n",
            "2639 [D loss: 1.000063] [G loss: 0.999777]\n",
            "2640 [D loss: 0.999876] [G loss: 0.999889]\n",
            "2641 [D loss: 1.000053] [G loss: 0.999828]\n",
            "2642 [D loss: 0.999967] [G loss: 0.999828]\n",
            "2643 [D loss: 1.000023] [G loss: 0.999819]\n",
            "2644 [D loss: 0.999996] [G loss: 0.999760]\n",
            "2645 [D loss: 0.999975] [G loss: 0.999805]\n",
            "2646 [D loss: 0.999982] [G loss: 0.999808]\n",
            "2647 [D loss: 1.000102] [G loss: 0.999785]\n",
            "2648 [D loss: 1.000132] [G loss: 0.999824]\n",
            "2649 [D loss: 0.999984] [G loss: 0.999866]\n",
            "2650 [D loss: 1.000133] [G loss: 0.999895]\n",
            "2651 [D loss: 1.000057] [G loss: 0.999970]\n",
            "2652 [D loss: 1.000113] [G loss: 0.999891]\n",
            "2653 [D loss: 1.000031] [G loss: 0.999920]\n",
            "2654 [D loss: 1.000020] [G loss: 1.000143]\n",
            "2655 [D loss: 1.000144] [G loss: 0.999904]\n",
            "2656 [D loss: 1.000037] [G loss: 1.000152]\n",
            "2657 [D loss: 1.000181] [G loss: 1.000118]\n",
            "2658 [D loss: 1.000183] [G loss: 1.000255]\n",
            "2659 [D loss: 1.000045] [G loss: 1.000049]\n",
            "2660 [D loss: 0.999857] [G loss: 1.000185]\n",
            "2661 [D loss: 1.000193] [G loss: 1.000027]\n",
            "2662 [D loss: 1.000276] [G loss: 0.999976]\n",
            "2663 [D loss: 1.000157] [G loss: 0.999970]\n",
            "2664 [D loss: 1.000109] [G loss: 1.000003]\n",
            "2665 [D loss: 1.000038] [G loss: 1.000175]\n",
            "2666 [D loss: 1.000031] [G loss: 0.999949]\n",
            "2667 [D loss: 1.000082] [G loss: 0.999945]\n",
            "2668 [D loss: 1.000221] [G loss: 0.999702]\n",
            "2669 [D loss: 1.000153] [G loss: 1.000001]\n",
            "2670 [D loss: 1.000169] [G loss: 0.999933]\n",
            "2671 [D loss: 1.000070] [G loss: 0.999993]\n",
            "2672 [D loss: 1.000234] [G loss: 0.999686]\n",
            "2673 [D loss: 1.000155] [G loss: 0.999989]\n",
            "2674 [D loss: 0.999956] [G loss: 0.999899]\n",
            "2675 [D loss: 1.000144] [G loss: 1.000027]\n",
            "2676 [D loss: 1.000028] [G loss: 1.000068]\n",
            "2677 [D loss: 0.999867] [G loss: 1.000215]\n",
            "2678 [D loss: 0.999914] [G loss: 1.000143]\n",
            "2679 [D loss: 0.999907] [G loss: 1.000083]\n",
            "2680 [D loss: 1.000146] [G loss: 1.000187]\n",
            "2681 [D loss: 0.999966] [G loss: 1.000196]\n",
            "2682 [D loss: 0.999987] [G loss: 1.000285]\n",
            "2683 [D loss: 0.999923] [G loss: 1.000422]\n",
            "2684 [D loss: 0.999844] [G loss: 1.000362]\n",
            "2685 [D loss: 0.999891] [G loss: 1.000400]\n",
            "2686 [D loss: 0.999906] [G loss: 1.000395]\n",
            "2687 [D loss: 0.999924] [G loss: 1.000335]\n",
            "2688 [D loss: 0.999949] [G loss: 1.000242]\n",
            "2689 [D loss: 0.999953] [G loss: 1.000279]\n",
            "2690 [D loss: 0.999946] [G loss: 1.000202]\n",
            "2691 [D loss: 0.999965] [G loss: 1.000121]\n",
            "2692 [D loss: 0.999987] [G loss: 1.000207]\n",
            "2693 [D loss: 0.999958] [G loss: 1.000197]\n",
            "2694 [D loss: 0.999982] [G loss: 1.000173]\n",
            "2695 [D loss: 1.000026] [G loss: 1.000086]\n",
            "2696 [D loss: 0.999980] [G loss: 1.000091]\n",
            "2697 [D loss: 0.999989] [G loss: 1.000049]\n",
            "2698 [D loss: 1.000014] [G loss: 0.999965]\n",
            "2699 [D loss: 0.999978] [G loss: 0.999943]\n",
            "2700 [D loss: 1.000022] [G loss: 0.999902]\n",
            "2701 [D loss: 1.000053] [G loss: 0.999828]\n",
            "2702 [D loss: 0.999947] [G loss: 0.999934]\n",
            "2703 [D loss: 0.999926] [G loss: 0.999964]\n",
            "2704 [D loss: 0.999976] [G loss: 0.999886]\n",
            "2705 [D loss: 1.000017] [G loss: 0.999914]\n",
            "2706 [D loss: 1.000026] [G loss: 0.999861]\n",
            "2707 [D loss: 0.999984] [G loss: 0.999858]\n",
            "2708 [D loss: 0.999968] [G loss: 0.999910]\n",
            "2709 [D loss: 0.999999] [G loss: 0.999911]\n",
            "2710 [D loss: 0.999960] [G loss: 0.999923]\n",
            "2711 [D loss: 0.999992] [G loss: 0.999917]\n",
            "2712 [D loss: 0.999933] [G loss: 0.999930]\n",
            "2713 [D loss: 0.999943] [G loss: 0.999976]\n",
            "2714 [D loss: 0.999968] [G loss: 0.999858]\n",
            "2715 [D loss: 0.999890] [G loss: 0.999974]\n",
            "2716 [D loss: 1.000018] [G loss: 0.999899]\n",
            "2717 [D loss: 0.999970] [G loss: 1.000075]\n",
            "2718 [D loss: 0.999905] [G loss: 1.000073]\n",
            "2719 [D loss: 0.999975] [G loss: 1.000017]\n",
            "2720 [D loss: 0.999963] [G loss: 1.000051]\n",
            "2721 [D loss: 0.999932] [G loss: 1.000079]\n",
            "2722 [D loss: 0.999963] [G loss: 1.000081]\n",
            "2723 [D loss: 0.999980] [G loss: 1.000080]\n",
            "2724 [D loss: 0.999978] [G loss: 1.000068]\n",
            "2725 [D loss: 0.999904] [G loss: 1.000145]\n",
            "2726 [D loss: 0.999967] [G loss: 1.000142]\n",
            "2727 [D loss: 0.999925] [G loss: 1.000158]\n",
            "2728 [D loss: 0.999920] [G loss: 1.000159]\n",
            "2729 [D loss: 0.999937] [G loss: 1.000117]\n",
            "2730 [D loss: 0.999959] [G loss: 1.000099]\n",
            "2731 [D loss: 0.999929] [G loss: 1.000122]\n",
            "2732 [D loss: 0.999974] [G loss: 1.000091]\n",
            "2733 [D loss: 0.999938] [G loss: 1.000083]\n",
            "2734 [D loss: 0.999921] [G loss: 1.000095]\n",
            "2735 [D loss: 0.999975] [G loss: 1.000134]\n",
            "2736 [D loss: 0.999953] [G loss: 1.000104]\n",
            "2737 [D loss: 0.999975] [G loss: 1.000077]\n",
            "2738 [D loss: 0.999967] [G loss: 1.000092]\n",
            "2739 [D loss: 0.999973] [G loss: 1.000073]\n",
            "2740 [D loss: 0.999962] [G loss: 1.000082]\n",
            "2741 [D loss: 0.999949] [G loss: 1.000085]\n",
            "2742 [D loss: 0.999953] [G loss: 1.000085]\n",
            "2743 [D loss: 0.999954] [G loss: 1.000065]\n",
            "2744 [D loss: 0.999986] [G loss: 1.000080]\n",
            "2745 [D loss: 0.999948] [G loss: 1.000080]\n",
            "2746 [D loss: 0.999934] [G loss: 1.000084]\n",
            "2747 [D loss: 0.999958] [G loss: 1.000086]\n",
            "2748 [D loss: 0.999943] [G loss: 1.000052]\n",
            "2749 [D loss: 0.999936] [G loss: 1.000045]\n",
            "2750 [D loss: 0.999943] [G loss: 1.000048]\n",
            "2751 [D loss: 0.999982] [G loss: 1.000019]\n",
            "2752 [D loss: 0.999962] [G loss: 1.000061]\n",
            "2753 [D loss: 0.999950] [G loss: 1.000046]\n",
            "2754 [D loss: 0.999959] [G loss: 1.000026]\n",
            "2755 [D loss: 0.999941] [G loss: 1.000057]\n",
            "2756 [D loss: 0.999960] [G loss: 1.000030]\n",
            "2757 [D loss: 0.999958] [G loss: 1.000026]\n",
            "2758 [D loss: 0.999959] [G loss: 1.000035]\n",
            "2759 [D loss: 0.999977] [G loss: 1.000000]\n",
            "2760 [D loss: 0.999951] [G loss: 1.000028]\n",
            "2761 [D loss: 0.999973] [G loss: 1.000022]\n",
            "2762 [D loss: 0.999965] [G loss: 1.000039]\n",
            "2763 [D loss: 0.999970] [G loss: 1.000017]\n",
            "2764 [D loss: 0.999955] [G loss: 1.000031]\n",
            "2765 [D loss: 0.999974] [G loss: 0.999994]\n",
            "2766 [D loss: 0.999968] [G loss: 0.999983]\n",
            "2767 [D loss: 0.999952] [G loss: 0.999993]\n",
            "2768 [D loss: 0.999960] [G loss: 0.999994]\n",
            "2769 [D loss: 0.999980] [G loss: 0.999978]\n",
            "2770 [D loss: 0.999981] [G loss: 1.000018]\n",
            "2771 [D loss: 0.999959] [G loss: 0.999969]\n",
            "2772 [D loss: 0.999936] [G loss: 1.000017]\n",
            "2773 [D loss: 0.999971] [G loss: 1.000017]\n",
            "2774 [D loss: 0.999939] [G loss: 1.000011]\n",
            "2775 [D loss: 0.999970] [G loss: 0.999996]\n",
            "2776 [D loss: 0.999971] [G loss: 1.000011]\n",
            "2777 [D loss: 0.999959] [G loss: 1.000014]\n",
            "2778 [D loss: 0.999956] [G loss: 1.000023]\n",
            "2779 [D loss: 0.999954] [G loss: 1.000017]\n",
            "2780 [D loss: 0.999964] [G loss: 1.000006]\n",
            "2781 [D loss: 0.999967] [G loss: 1.000005]\n",
            "2782 [D loss: 0.999953] [G loss: 1.000035]\n",
            "2783 [D loss: 0.999977] [G loss: 1.000011]\n",
            "2784 [D loss: 0.999958] [G loss: 1.000021]\n",
            "2785 [D loss: 0.999985] [G loss: 0.999991]\n",
            "2786 [D loss: 0.999977] [G loss: 1.000019]\n",
            "2787 [D loss: 0.999976] [G loss: 1.000021]\n",
            "2788 [D loss: 0.999964] [G loss: 1.000038]\n",
            "2789 [D loss: 0.999972] [G loss: 1.000018]\n",
            "2790 [D loss: 0.999986] [G loss: 1.000018]\n",
            "2791 [D loss: 0.999960] [G loss: 1.000027]\n",
            "2792 [D loss: 0.999972] [G loss: 1.000023]\n",
            "2793 [D loss: 0.999949] [G loss: 1.000024]\n",
            "2794 [D loss: 0.999957] [G loss: 1.000019]\n",
            "2795 [D loss: 0.999967] [G loss: 1.000047]\n",
            "2796 [D loss: 0.999975] [G loss: 1.000039]\n",
            "2797 [D loss: 0.999956] [G loss: 1.000036]\n",
            "2798 [D loss: 0.999959] [G loss: 1.000045]\n",
            "2799 [D loss: 0.999977] [G loss: 1.000021]\n",
            "2800 [D loss: 0.999958] [G loss: 1.000037]\n",
            "2801 [D loss: 0.999978] [G loss: 1.000051]\n",
            "2802 [D loss: 0.999957] [G loss: 1.000040]\n",
            "2803 [D loss: 0.999960] [G loss: 1.000056]\n",
            "2804 [D loss: 0.999967] [G loss: 1.000031]\n",
            "2805 [D loss: 0.999994] [G loss: 1.000008]\n",
            "2806 [D loss: 0.999989] [G loss: 1.000027]\n",
            "2807 [D loss: 0.999968] [G loss: 1.000060]\n",
            "2808 [D loss: 0.999987] [G loss: 1.000027]\n",
            "2809 [D loss: 0.999970] [G loss: 1.000055]\n",
            "2810 [D loss: 0.999992] [G loss: 1.000042]\n",
            "2811 [D loss: 0.999957] [G loss: 1.000056]\n",
            "2812 [D loss: 0.999974] [G loss: 1.000051]\n",
            "2813 [D loss: 0.999957] [G loss: 1.000056]\n",
            "2814 [D loss: 0.999969] [G loss: 1.000058]\n",
            "2815 [D loss: 0.999979] [G loss: 1.000044]\n",
            "2816 [D loss: 0.999980] [G loss: 1.000041]\n",
            "2817 [D loss: 0.999997] [G loss: 1.000028]\n",
            "2818 [D loss: 0.999983] [G loss: 1.000047]\n",
            "2819 [D loss: 0.999975] [G loss: 1.000045]\n",
            "2820 [D loss: 0.999974] [G loss: 1.000041]\n",
            "2821 [D loss: 0.999995] [G loss: 1.000017]\n",
            "2822 [D loss: 0.999983] [G loss: 1.000040]\n",
            "2823 [D loss: 1.000002] [G loss: 1.000010]\n",
            "2824 [D loss: 0.999969] [G loss: 1.000031]\n",
            "2825 [D loss: 0.999976] [G loss: 1.000028]\n",
            "2826 [D loss: 0.999970] [G loss: 1.000050]\n",
            "2827 [D loss: 0.999969] [G loss: 1.000052]\n",
            "2828 [D loss: 0.999966] [G loss: 1.000044]\n",
            "2829 [D loss: 0.999968] [G loss: 1.000041]\n",
            "2830 [D loss: 0.999965] [G loss: 1.000057]\n",
            "2831 [D loss: 0.999958] [G loss: 1.000053]\n",
            "2832 [D loss: 0.999985] [G loss: 1.000016]\n",
            "2833 [D loss: 0.999977] [G loss: 1.000044]\n",
            "2834 [D loss: 0.999965] [G loss: 1.000037]\n",
            "2835 [D loss: 0.999974] [G loss: 1.000045]\n",
            "2836 [D loss: 0.999968] [G loss: 1.000053]\n",
            "2837 [D loss: 0.999963] [G loss: 1.000043]\n",
            "2838 [D loss: 0.999972] [G loss: 1.000053]\n",
            "2839 [D loss: 0.999969] [G loss: 1.000047]\n",
            "2840 [D loss: 0.999973] [G loss: 1.000031]\n",
            "2841 [D loss: 0.999956] [G loss: 1.000045]\n",
            "2842 [D loss: 0.999963] [G loss: 1.000062]\n",
            "2843 [D loss: 0.999966] [G loss: 1.000057]\n",
            "2844 [D loss: 0.999971] [G loss: 1.000055]\n",
            "2845 [D loss: 0.999977] [G loss: 1.000048]\n",
            "2846 [D loss: 0.999950] [G loss: 1.000040]\n",
            "2847 [D loss: 0.999963] [G loss: 1.000038]\n",
            "2848 [D loss: 0.999980] [G loss: 1.000019]\n",
            "2849 [D loss: 0.999967] [G loss: 1.000025]\n",
            "2850 [D loss: 0.999985] [G loss: 1.000017]\n",
            "2851 [D loss: 0.999963] [G loss: 1.000039]\n",
            "2852 [D loss: 0.999973] [G loss: 1.000040]\n",
            "2853 [D loss: 0.999987] [G loss: 1.000009]\n",
            "2854 [D loss: 0.999987] [G loss: 1.000012]\n",
            "2855 [D loss: 0.999979] [G loss: 1.000043]\n",
            "2856 [D loss: 0.999971] [G loss: 1.000036]\n",
            "2857 [D loss: 0.999980] [G loss: 1.000014]\n",
            "2858 [D loss: 0.999984] [G loss: 1.000027]\n",
            "2859 [D loss: 0.999970] [G loss: 1.000042]\n",
            "2860 [D loss: 0.999988] [G loss: 1.000035]\n",
            "2861 [D loss: 0.999978] [G loss: 1.000035]\n",
            "2862 [D loss: 0.999997] [G loss: 1.000002]\n",
            "2863 [D loss: 0.999995] [G loss: 1.000030]\n",
            "2864 [D loss: 0.999987] [G loss: 1.000049]\n",
            "2865 [D loss: 1.000003] [G loss: 1.000004]\n",
            "2866 [D loss: 1.000027] [G loss: 1.000018]\n",
            "2867 [D loss: 0.999995] [G loss: 1.000048]\n",
            "2868 [D loss: 0.999997] [G loss: 1.000022]\n",
            "2869 [D loss: 0.999986] [G loss: 1.000055]\n",
            "2870 [D loss: 0.999984] [G loss: 1.000031]\n",
            "2871 [D loss: 1.000013] [G loss: 1.000041]\n",
            "2872 [D loss: 1.000000] [G loss: 1.000018]\n",
            "2873 [D loss: 1.000010] [G loss: 0.999996]\n",
            "2874 [D loss: 1.000017] [G loss: 1.000047]\n",
            "2875 [D loss: 1.000066] [G loss: 0.999965]\n",
            "2876 [D loss: 1.000029] [G loss: 1.000048]\n",
            "2877 [D loss: 1.000045] [G loss: 1.000024]\n",
            "2878 [D loss: 1.000025] [G loss: 1.000023]\n",
            "2879 [D loss: 1.000007] [G loss: 1.000010]\n",
            "2880 [D loss: 1.000016] [G loss: 1.000059]\n",
            "2881 [D loss: 1.000007] [G loss: 1.000124]\n",
            "2882 [D loss: 0.999964] [G loss: 1.000065]\n",
            "2883 [D loss: 1.000003] [G loss: 1.000075]\n",
            "2884 [D loss: 0.999980] [G loss: 1.000116]\n",
            "2885 [D loss: 1.000027] [G loss: 1.000084]\n",
            "2886 [D loss: 0.999944] [G loss: 1.000082]\n",
            "2887 [D loss: 1.000064] [G loss: 1.000057]\n",
            "2888 [D loss: 0.999998] [G loss: 1.000129]\n",
            "2889 [D loss: 1.000005] [G loss: 1.000098]\n",
            "2890 [D loss: 1.000018] [G loss: 1.000118]\n",
            "2891 [D loss: 0.999999] [G loss: 1.000121]\n",
            "2892 [D loss: 1.000005] [G loss: 1.000126]\n",
            "2893 [D loss: 0.999972] [G loss: 1.000120]\n",
            "2894 [D loss: 0.999928] [G loss: 1.000157]\n",
            "2895 [D loss: 0.999926] [G loss: 1.000135]\n",
            "2896 [D loss: 1.000013] [G loss: 1.000077]\n",
            "2897 [D loss: 1.000156] [G loss: 1.000034]\n",
            "2898 [D loss: 0.999932] [G loss: 1.000057]\n",
            "2899 [D loss: 0.999956] [G loss: 1.000013]\n",
            "2900 [D loss: 1.000003] [G loss: 1.000033]\n",
            "2901 [D loss: 0.999982] [G loss: 0.999947]\n",
            "2902 [D loss: 1.000140] [G loss: 0.999841]\n",
            "2903 [D loss: 1.000032] [G loss: 0.999841]\n",
            "2904 [D loss: 1.000065] [G loss: 0.999871]\n",
            "2905 [D loss: 0.999911] [G loss: 0.999928]\n",
            "2906 [D loss: 0.999966] [G loss: 0.999917]\n",
            "2907 [D loss: 0.999962] [G loss: 0.999904]\n",
            "2908 [D loss: 0.999975] [G loss: 0.999957]\n",
            "2909 [D loss: 0.999976] [G loss: 0.999946]\n",
            "2910 [D loss: 0.999955] [G loss: 0.999951]\n",
            "2911 [D loss: 0.999966] [G loss: 0.999932]\n",
            "2912 [D loss: 0.999948] [G loss: 0.999943]\n",
            "2913 [D loss: 0.999958] [G loss: 0.999913]\n",
            "2914 [D loss: 0.999972] [G loss: 0.999908]\n",
            "2915 [D loss: 0.999993] [G loss: 0.999903]\n",
            "2916 [D loss: 0.999971] [G loss: 0.999906]\n",
            "2917 [D loss: 0.999964] [G loss: 0.999925]\n",
            "2918 [D loss: 1.000001] [G loss: 0.999912]\n",
            "2919 [D loss: 1.000022] [G loss: 0.999905]\n",
            "2920 [D loss: 0.999992] [G loss: 0.999886]\n",
            "2921 [D loss: 0.999983] [G loss: 0.999894]\n",
            "2922 [D loss: 0.999991] [G loss: 0.999925]\n",
            "2923 [D loss: 0.999976] [G loss: 0.999922]\n",
            "2924 [D loss: 0.999991] [G loss: 0.999895]\n",
            "2925 [D loss: 0.999943] [G loss: 0.999884]\n",
            "2926 [D loss: 0.999978] [G loss: 0.999876]\n",
            "2927 [D loss: 0.999994] [G loss: 0.999886]\n",
            "2928 [D loss: 0.999967] [G loss: 0.999859]\n",
            "2929 [D loss: 1.000024] [G loss: 0.999875]\n",
            "2930 [D loss: 1.000029] [G loss: 0.999856]\n",
            "2931 [D loss: 0.999996] [G loss: 0.999864]\n",
            "2932 [D loss: 0.999997] [G loss: 0.999908]\n",
            "2933 [D loss: 0.999985] [G loss: 0.999892]\n",
            "2934 [D loss: 0.999955] [G loss: 0.999894]\n",
            "2935 [D loss: 0.999996] [G loss: 0.999930]\n",
            "2936 [D loss: 0.999984] [G loss: 0.999876]\n",
            "2937 [D loss: 0.999980] [G loss: 0.999900]\n",
            "2938 [D loss: 0.999995] [G loss: 0.999848]\n",
            "2939 [D loss: 1.000002] [G loss: 0.999863]\n",
            "2940 [D loss: 0.999982] [G loss: 0.999839]\n",
            "2941 [D loss: 0.999979] [G loss: 0.999846]\n",
            "2942 [D loss: 1.000024] [G loss: 0.999864]\n",
            "2943 [D loss: 0.999947] [G loss: 0.999870]\n",
            "2944 [D loss: 1.000058] [G loss: 0.999838]\n",
            "2945 [D loss: 0.999989] [G loss: 0.999933]\n",
            "2946 [D loss: 1.000004] [G loss: 0.999920]\n",
            "2947 [D loss: 0.999969] [G loss: 0.999901]\n",
            "2948 [D loss: 0.999962] [G loss: 0.999917]\n",
            "2949 [D loss: 0.999965] [G loss: 0.999885]\n",
            "2950 [D loss: 0.999960] [G loss: 0.999828]\n",
            "2951 [D loss: 0.999988] [G loss: 0.999850]\n",
            "2952 [D loss: 0.999999] [G loss: 0.999847]\n",
            "2953 [D loss: 0.999965] [G loss: 0.999917]\n",
            "2954 [D loss: 0.999996] [G loss: 0.999876]\n",
            "2955 [D loss: 0.999983] [G loss: 0.999908]\n",
            "2956 [D loss: 0.999965] [G loss: 0.999868]\n",
            "2957 [D loss: 0.999959] [G loss: 0.999919]\n",
            "2958 [D loss: 0.999948] [G loss: 0.999903]\n",
            "2959 [D loss: 0.999987] [G loss: 0.999891]\n",
            "2960 [D loss: 0.999967] [G loss: 0.999878]\n",
            "2961 [D loss: 1.000007] [G loss: 0.999876]\n",
            "2962 [D loss: 0.999963] [G loss: 0.999888]\n",
            "2963 [D loss: 0.999960] [G loss: 0.999902]\n",
            "2964 [D loss: 0.999949] [G loss: 0.999909]\n",
            "2965 [D loss: 0.999951] [G loss: 0.999931]\n",
            "2966 [D loss: 0.999978] [G loss: 0.999897]\n",
            "2967 [D loss: 0.999970] [G loss: 0.999903]\n",
            "2968 [D loss: 0.999945] [G loss: 0.999930]\n",
            "2969 [D loss: 0.999973] [G loss: 0.999934]\n",
            "2970 [D loss: 0.999977] [G loss: 0.999933]\n",
            "2971 [D loss: 0.999951] [G loss: 0.999961]\n",
            "2972 [D loss: 0.999940] [G loss: 0.999989]\n",
            "2973 [D loss: 0.999952] [G loss: 0.999987]\n",
            "2974 [D loss: 0.999962] [G loss: 0.999929]\n",
            "2975 [D loss: 0.999953] [G loss: 0.999956]\n",
            "2976 [D loss: 0.999970] [G loss: 0.999959]\n",
            "2977 [D loss: 0.999968] [G loss: 0.999944]\n",
            "2978 [D loss: 0.999972] [G loss: 0.999930]\n",
            "2979 [D loss: 0.999954] [G loss: 0.999931]\n",
            "2980 [D loss: 0.999961] [G loss: 0.999931]\n",
            "2981 [D loss: 0.999984] [G loss: 0.999906]\n",
            "2982 [D loss: 0.999963] [G loss: 0.999935]\n",
            "2983 [D loss: 0.999966] [G loss: 0.999930]\n",
            "2984 [D loss: 0.999945] [G loss: 0.999952]\n",
            "2985 [D loss: 0.999961] [G loss: 0.999942]\n",
            "2986 [D loss: 0.999983] [G loss: 0.999918]\n",
            "2987 [D loss: 0.999960] [G loss: 0.999957]\n",
            "2988 [D loss: 0.999970] [G loss: 0.999949]\n",
            "2989 [D loss: 0.999953] [G loss: 0.999944]\n",
            "2990 [D loss: 0.999981] [G loss: 0.999963]\n",
            "2991 [D loss: 0.999979] [G loss: 0.999963]\n",
            "2992 [D loss: 0.999993] [G loss: 0.999942]\n",
            "2993 [D loss: 0.999960] [G loss: 0.999992]\n",
            "2994 [D loss: 0.999974] [G loss: 0.999970]\n",
            "2995 [D loss: 0.999989] [G loss: 0.999938]\n",
            "2996 [D loss: 0.999989] [G loss: 0.999976]\n",
            "2997 [D loss: 0.999989] [G loss: 0.999959]\n",
            "2998 [D loss: 0.999968] [G loss: 0.999963]\n",
            "2999 [D loss: 0.999986] [G loss: 0.999967]\n",
            "3000 [D loss: 0.999975] [G loss: 0.999953]\n",
            "3001 [D loss: 1.000104] [G loss: 0.999954]\n",
            "3002 [D loss: 0.999984] [G loss: 0.999977]\n",
            "3003 [D loss: 1.000056] [G loss: 0.999965]\n",
            "3004 [D loss: 1.000067] [G loss: 0.999972]\n",
            "3005 [D loss: 1.000191] [G loss: 0.999883]\n",
            "3006 [D loss: 1.000237] [G loss: 0.999886]\n",
            "3007 [D loss: 1.000233] [G loss: 0.999916]\n",
            "3008 [D loss: 1.000286] [G loss: 0.999895]\n",
            "3009 [D loss: 1.000216] [G loss: 0.999902]\n",
            "3010 [D loss: 1.000481] [G loss: 0.999798]\n",
            "3011 [D loss: 1.000400] [G loss: 0.999861]\n",
            "3012 [D loss: 1.000281] [G loss: 0.999881]\n",
            "3013 [D loss: 1.000413] [G loss: 0.999847]\n",
            "3014 [D loss: 1.000324] [G loss: 0.999907]\n",
            "3015 [D loss: 1.000181] [G loss: 1.000055]\n",
            "3016 [D loss: 1.000378] [G loss: 1.000050]\n",
            "3017 [D loss: 1.000506] [G loss: 0.999778]\n",
            "3018 [D loss: 1.000103] [G loss: 1.000098]\n",
            "3019 [D loss: 0.999955] [G loss: 1.000117]\n",
            "3020 [D loss: 1.000094] [G loss: 1.000235]\n",
            "3021 [D loss: 1.000388] [G loss: 0.999916]\n",
            "3022 [D loss: 0.999827] [G loss: 1.000237]\n",
            "3023 [D loss: 1.000279] [G loss: 1.000769]\n",
            "3024 [D loss: 0.999883] [G loss: 1.000523]\n",
            "3025 [D loss: 1.000166] [G loss: 1.000308]\n",
            "3026 [D loss: 1.000036] [G loss: 1.000270]\n",
            "3027 [D loss: 1.000250] [G loss: 1.000323]\n",
            "3028 [D loss: 1.000016] [G loss: 1.000272]\n",
            "3029 [D loss: 1.000147] [G loss: 1.000081]\n",
            "3030 [D loss: 0.999724] [G loss: 1.000213]\n",
            "3031 [D loss: 0.999903] [G loss: 1.000054]\n",
            "3032 [D loss: 0.999720] [G loss: 0.999998]\n",
            "3033 [D loss: 0.999850] [G loss: 1.000164]\n",
            "3034 [D loss: 0.999964] [G loss: 1.000047]\n",
            "3035 [D loss: 0.999893] [G loss: 1.000044]\n",
            "3036 [D loss: 1.000010] [G loss: 0.999914]\n",
            "3037 [D loss: 1.000211] [G loss: 0.999937]\n",
            "3038 [D loss: 0.999940] [G loss: 0.999912]\n",
            "3039 [D loss: 0.999991] [G loss: 0.999892]\n",
            "3040 [D loss: 0.999986] [G loss: 0.999903]\n",
            "3041 [D loss: 0.999972] [G loss: 0.999965]\n",
            "3042 [D loss: 1.000093] [G loss: 0.999856]\n",
            "3043 [D loss: 0.999943] [G loss: 0.999917]\n",
            "3044 [D loss: 0.999996] [G loss: 0.999871]\n",
            "3045 [D loss: 0.999943] [G loss: 0.999944]\n",
            "3046 [D loss: 1.000082] [G loss: 0.999834]\n",
            "3047 [D loss: 0.999947] [G loss: 0.999932]\n",
            "3048 [D loss: 0.999991] [G loss: 0.999865]\n",
            "3049 [D loss: 1.000058] [G loss: 0.999879]\n",
            "3050 [D loss: 0.999995] [G loss: 0.999862]\n",
            "3051 [D loss: 1.000022] [G loss: 0.999794]\n",
            "3052 [D loss: 1.000036] [G loss: 0.999892]\n",
            "3053 [D loss: 1.000047] [G loss: 0.999849]\n",
            "3054 [D loss: 1.000020] [G loss: 0.999764]\n",
            "3055 [D loss: 1.000048] [G loss: 0.999907]\n",
            "3056 [D loss: 1.000025] [G loss: 0.999720]\n",
            "3057 [D loss: 1.000088] [G loss: 0.999658]\n",
            "3058 [D loss: 1.000017] [G loss: 0.999786]\n",
            "3059 [D loss: 1.000091] [G loss: 0.999780]\n",
            "3060 [D loss: 1.000020] [G loss: 0.999823]\n",
            "3061 [D loss: 1.000074] [G loss: 0.999728]\n",
            "3062 [D loss: 1.000106] [G loss: 0.999675]\n",
            "3063 [D loss: 1.000074] [G loss: 0.999624]\n",
            "3064 [D loss: 1.000122] [G loss: 0.999680]\n",
            "3065 [D loss: 1.000046] [G loss: 0.999693]\n",
            "3066 [D loss: 1.000164] [G loss: 0.999623]\n",
            "3067 [D loss: 1.000157] [G loss: 0.999649]\n",
            "3068 [D loss: 1.000086] [G loss: 0.999638]\n",
            "3069 [D loss: 1.000135] [G loss: 0.999686]\n",
            "3070 [D loss: 1.000042] [G loss: 0.999674]\n",
            "3071 [D loss: 0.999856] [G loss: 0.999866]\n",
            "3072 [D loss: 0.999987] [G loss: 0.999876]\n",
            "3073 [D loss: 1.000035] [G loss: 0.999804]\n",
            "3074 [D loss: 0.999980] [G loss: 0.999950]\n",
            "3075 [D loss: 0.999987] [G loss: 0.999918]\n",
            "3076 [D loss: 0.999975] [G loss: 1.000028]\n",
            "3077 [D loss: 0.999975] [G loss: 1.000020]\n",
            "3078 [D loss: 0.999932] [G loss: 1.000122]\n",
            "3079 [D loss: 0.999959] [G loss: 1.000037]\n",
            "3080 [D loss: 1.000035] [G loss: 1.000072]\n",
            "3081 [D loss: 0.999896] [G loss: 1.000080]\n",
            "3082 [D loss: 0.999944] [G loss: 1.000042]\n",
            "3083 [D loss: 0.999930] [G loss: 1.000054]\n",
            "3084 [D loss: 0.999957] [G loss: 0.999974]\n",
            "3085 [D loss: 0.999955] [G loss: 1.000028]\n",
            "3086 [D loss: 0.999962] [G loss: 1.000011]\n",
            "3087 [D loss: 0.999975] [G loss: 1.000018]\n",
            "3088 [D loss: 0.999949] [G loss: 0.999981]\n",
            "3089 [D loss: 0.999970] [G loss: 0.999986]\n",
            "3090 [D loss: 0.999943] [G loss: 1.000001]\n",
            "3091 [D loss: 0.999982] [G loss: 0.999901]\n",
            "3092 [D loss: 0.999967] [G loss: 1.000000]\n",
            "3093 [D loss: 0.999940] [G loss: 0.999927]\n",
            "3094 [D loss: 0.999996] [G loss: 0.999990]\n",
            "3095 [D loss: 0.999937] [G loss: 0.999951]\n",
            "3096 [D loss: 0.999959] [G loss: 0.999982]\n",
            "3097 [D loss: 0.999945] [G loss: 1.000000]\n",
            "3098 [D loss: 0.999944] [G loss: 1.000025]\n",
            "3099 [D loss: 0.999980] [G loss: 0.999934]\n",
            "3100 [D loss: 0.999965] [G loss: 0.999983]\n",
            "3101 [D loss: 0.999925] [G loss: 0.999953]\n",
            "3102 [D loss: 0.999934] [G loss: 1.000002]\n",
            "3103 [D loss: 0.999948] [G loss: 0.999969]\n",
            "3104 [D loss: 0.999957] [G loss: 0.999951]\n",
            "3105 [D loss: 0.999955] [G loss: 1.000002]\n",
            "3106 [D loss: 0.999977] [G loss: 0.999977]\n",
            "3107 [D loss: 0.999963] [G loss: 0.999994]\n",
            "3108 [D loss: 1.000012] [G loss: 0.999974]\n",
            "3109 [D loss: 0.999969] [G loss: 0.999996]\n",
            "3110 [D loss: 0.999965] [G loss: 0.999986]\n",
            "3111 [D loss: 0.999984] [G loss: 1.000015]\n",
            "3112 [D loss: 0.999984] [G loss: 0.999974]\n",
            "3113 [D loss: 0.999988] [G loss: 1.000042]\n",
            "3114 [D loss: 1.000000] [G loss: 1.000072]\n",
            "3115 [D loss: 0.999917] [G loss: 1.000180]\n",
            "3116 [D loss: 0.999999] [G loss: 1.000087]\n",
            "3117 [D loss: 0.999956] [G loss: 1.000071]\n",
            "3118 [D loss: 1.000031] [G loss: 1.000066]\n",
            "3119 [D loss: 0.999959] [G loss: 1.000063]\n",
            "3120 [D loss: 0.999993] [G loss: 0.999992]\n",
            "3121 [D loss: 0.999984] [G loss: 0.999988]\n",
            "3122 [D loss: 0.999993] [G loss: 1.000007]\n",
            "3123 [D loss: 0.999942] [G loss: 0.999964]\n",
            "3124 [D loss: 0.999968] [G loss: 0.999972]\n",
            "3125 [D loss: 0.999996] [G loss: 0.999945]\n",
            "3126 [D loss: 0.999967] [G loss: 0.999946]\n",
            "3127 [D loss: 0.999998] [G loss: 0.999918]\n",
            "3128 [D loss: 0.999957] [G loss: 0.999935]\n",
            "3129 [D loss: 0.999962] [G loss: 1.000009]\n",
            "3130 [D loss: 0.999969] [G loss: 0.999962]\n",
            "3131 [D loss: 0.999975] [G loss: 0.999950]\n",
            "3132 [D loss: 0.999985] [G loss: 0.999998]\n",
            "3133 [D loss: 0.999989] [G loss: 0.999996]\n",
            "3134 [D loss: 0.999964] [G loss: 0.999988]\n",
            "3135 [D loss: 0.999993] [G loss: 1.000024]\n",
            "3136 [D loss: 0.999980] [G loss: 1.000031]\n",
            "3137 [D loss: 0.999965] [G loss: 0.999975]\n",
            "3138 [D loss: 0.999952] [G loss: 0.999978]\n",
            "3139 [D loss: 0.999973] [G loss: 1.000015]\n",
            "3140 [D loss: 0.999947] [G loss: 1.000034]\n",
            "3141 [D loss: 0.999978] [G loss: 1.000026]\n",
            "3142 [D loss: 0.999971] [G loss: 1.000053]\n",
            "3143 [D loss: 0.999944] [G loss: 1.000032]\n",
            "3144 [D loss: 0.999973] [G loss: 1.000019]\n",
            "3145 [D loss: 0.999944] [G loss: 1.000049]\n",
            "3146 [D loss: 0.999947] [G loss: 1.000079]\n",
            "3147 [D loss: 0.999948] [G loss: 1.000069]\n",
            "3148 [D loss: 0.999936] [G loss: 1.000059]\n",
            "3149 [D loss: 0.999973] [G loss: 1.000051]\n",
            "3150 [D loss: 0.999981] [G loss: 1.000031]\n",
            "3151 [D loss: 0.999982] [G loss: 0.999993]\n",
            "3152 [D loss: 0.999966] [G loss: 1.000040]\n",
            "3153 [D loss: 0.999943] [G loss: 1.000072]\n",
            "3154 [D loss: 0.999970] [G loss: 1.000022]\n",
            "3155 [D loss: 0.999966] [G loss: 1.000025]\n",
            "3156 [D loss: 0.999961] [G loss: 1.000005]\n",
            "3157 [D loss: 0.999964] [G loss: 1.000016]\n",
            "3158 [D loss: 0.999975] [G loss: 1.000030]\n",
            "3159 [D loss: 0.999982] [G loss: 1.000014]\n",
            "3160 [D loss: 0.999985] [G loss: 1.000014]\n",
            "3161 [D loss: 0.999991] [G loss: 1.000019]\n",
            "3162 [D loss: 0.999974] [G loss: 1.000022]\n",
            "3163 [D loss: 0.999964] [G loss: 0.999997]\n",
            "3164 [D loss: 0.999965] [G loss: 1.000020]\n",
            "3165 [D loss: 0.999962] [G loss: 1.000017]\n",
            "3166 [D loss: 0.999966] [G loss: 1.000013]\n",
            "3167 [D loss: 0.999966] [G loss: 0.999991]\n",
            "3168 [D loss: 0.999969] [G loss: 1.000002]\n",
            "3169 [D loss: 0.999978] [G loss: 0.999998]\n",
            "3170 [D loss: 0.999981] [G loss: 1.000015]\n",
            "3171 [D loss: 0.999956] [G loss: 1.000013]\n",
            "3172 [D loss: 0.999963] [G loss: 1.000021]\n",
            "3173 [D loss: 0.999984] [G loss: 1.000016]\n",
            "3174 [D loss: 0.999970] [G loss: 1.000011]\n",
            "3175 [D loss: 0.999966] [G loss: 1.000023]\n",
            "3176 [D loss: 0.999947] [G loss: 1.000037]\n",
            "3177 [D loss: 0.999970] [G loss: 1.000032]\n",
            "3178 [D loss: 0.999945] [G loss: 1.000031]\n",
            "3179 [D loss: 0.999955] [G loss: 1.000040]\n",
            "3180 [D loss: 0.999962] [G loss: 1.000025]\n",
            "3181 [D loss: 0.999975] [G loss: 1.000013]\n",
            "3182 [D loss: 0.999951] [G loss: 1.000039]\n",
            "3183 [D loss: 0.999964] [G loss: 1.000054]\n",
            "3184 [D loss: 0.999973] [G loss: 1.000030]\n",
            "3185 [D loss: 0.999976] [G loss: 1.000022]\n",
            "3186 [D loss: 0.999964] [G loss: 1.000020]\n",
            "3187 [D loss: 0.999961] [G loss: 1.000018]\n",
            "3188 [D loss: 0.999965] [G loss: 1.000047]\n",
            "3189 [D loss: 0.999967] [G loss: 1.000023]\n",
            "3190 [D loss: 0.999970] [G loss: 1.000010]\n",
            "3191 [D loss: 0.999956] [G loss: 1.000033]\n",
            "3192 [D loss: 0.999967] [G loss: 1.000019]\n",
            "3193 [D loss: 0.999969] [G loss: 1.000015]\n",
            "3194 [D loss: 0.999965] [G loss: 1.000036]\n",
            "3195 [D loss: 0.999967] [G loss: 1.000030]\n",
            "3196 [D loss: 0.999973] [G loss: 1.000034]\n",
            "3197 [D loss: 0.999963] [G loss: 1.000033]\n",
            "3198 [D loss: 0.999957] [G loss: 1.000034]\n",
            "3199 [D loss: 0.999966] [G loss: 1.000044]\n",
            "3200 [D loss: 0.999965] [G loss: 1.000027]\n",
            "3201 [D loss: 0.999966] [G loss: 1.000033]\n",
            "3202 [D loss: 0.999961] [G loss: 1.000037]\n",
            "3203 [D loss: 0.999967] [G loss: 1.000045]\n",
            "3204 [D loss: 0.999970] [G loss: 1.000037]\n",
            "3205 [D loss: 0.999965] [G loss: 1.000045]\n",
            "3206 [D loss: 0.999962] [G loss: 1.000040]\n",
            "3207 [D loss: 0.999972] [G loss: 1.000047]\n",
            "3208 [D loss: 0.999971] [G loss: 1.000033]\n",
            "3209 [D loss: 0.999960] [G loss: 1.000051]\n",
            "3210 [D loss: 0.999969] [G loss: 1.000035]\n",
            "3211 [D loss: 0.999970] [G loss: 1.000032]\n",
            "3212 [D loss: 0.999968] [G loss: 1.000035]\n",
            "3213 [D loss: 0.999964] [G loss: 1.000027]\n",
            "3214 [D loss: 0.999958] [G loss: 1.000040]\n",
            "3215 [D loss: 0.999966] [G loss: 1.000037]\n",
            "3216 [D loss: 0.999965] [G loss: 1.000036]\n",
            "3217 [D loss: 0.999967] [G loss: 1.000034]\n",
            "3218 [D loss: 0.999959] [G loss: 1.000029]\n",
            "3219 [D loss: 0.999964] [G loss: 1.000028]\n",
            "3220 [D loss: 0.999965] [G loss: 1.000016]\n",
            "3221 [D loss: 0.999966] [G loss: 1.000026]\n",
            "3222 [D loss: 0.999959] [G loss: 1.000033]\n",
            "3223 [D loss: 0.999962] [G loss: 1.000023]\n",
            "3224 [D loss: 0.999969] [G loss: 1.000024]\n",
            "3225 [D loss: 0.999976] [G loss: 1.000032]\n",
            "3226 [D loss: 0.999968] [G loss: 1.000028]\n",
            "3227 [D loss: 0.999976] [G loss: 1.000032]\n",
            "3228 [D loss: 0.999972] [G loss: 1.000041]\n",
            "3229 [D loss: 0.999956] [G loss: 1.000049]\n",
            "3230 [D loss: 0.999966] [G loss: 1.000020]\n",
            "3231 [D loss: 0.999973] [G loss: 1.000026]\n",
            "3232 [D loss: 0.999964] [G loss: 1.000041]\n",
            "3233 [D loss: 0.999970] [G loss: 1.000038]\n",
            "3234 [D loss: 0.999970] [G loss: 1.000038]\n",
            "3235 [D loss: 0.999963] [G loss: 1.000035]\n",
            "3236 [D loss: 0.999966] [G loss: 1.000038]\n",
            "3237 [D loss: 0.999972] [G loss: 1.000014]\n",
            "3238 [D loss: 0.999974] [G loss: 1.000026]\n",
            "3239 [D loss: 0.999965] [G loss: 1.000028]\n",
            "3240 [D loss: 0.999970] [G loss: 1.000035]\n",
            "3241 [D loss: 0.999973] [G loss: 1.000013]\n",
            "3242 [D loss: 0.999963] [G loss: 1.000037]\n",
            "3243 [D loss: 0.999971] [G loss: 1.000022]\n",
            "3244 [D loss: 0.999969] [G loss: 1.000036]\n",
            "3245 [D loss: 0.999976] [G loss: 1.000013]\n",
            "3246 [D loss: 0.999979] [G loss: 1.000014]\n",
            "3247 [D loss: 0.999970] [G loss: 1.000027]\n",
            "3248 [D loss: 0.999969] [G loss: 1.000021]\n",
            "3249 [D loss: 0.999968] [G loss: 1.000020]\n",
            "3250 [D loss: 0.999967] [G loss: 1.000032]\n",
            "3251 [D loss: 0.999970] [G loss: 1.000023]\n",
            "3252 [D loss: 0.999964] [G loss: 1.000016]\n",
            "3253 [D loss: 0.999975] [G loss: 1.000025]\n",
            "3254 [D loss: 0.999964] [G loss: 1.000018]\n",
            "3255 [D loss: 0.999961] [G loss: 1.000035]\n",
            "3256 [D loss: 0.999961] [G loss: 1.000026]\n",
            "3257 [D loss: 0.999973] [G loss: 1.000022]\n",
            "3258 [D loss: 0.999973] [G loss: 1.000017]\n",
            "3259 [D loss: 0.999969] [G loss: 1.000028]\n",
            "3260 [D loss: 0.999959] [G loss: 1.000019]\n",
            "3261 [D loss: 0.999959] [G loss: 1.000018]\n",
            "3262 [D loss: 0.999969] [G loss: 1.000012]\n",
            "3263 [D loss: 0.999971] [G loss: 1.000009]\n",
            "3264 [D loss: 0.999957] [G loss: 1.000017]\n",
            "3265 [D loss: 0.999954] [G loss: 1.000023]\n",
            "3266 [D loss: 0.999958] [G loss: 1.000021]\n",
            "3267 [D loss: 0.999973] [G loss: 1.000018]\n",
            "3268 [D loss: 0.999963] [G loss: 1.000021]\n",
            "3269 [D loss: 0.999966] [G loss: 1.000026]\n",
            "3270 [D loss: 0.999966] [G loss: 1.000028]\n",
            "3271 [D loss: 0.999961] [G loss: 1.000037]\n",
            "3272 [D loss: 0.999964] [G loss: 1.000018]\n",
            "3273 [D loss: 0.999973] [G loss: 1.000028]\n",
            "3274 [D loss: 0.999966] [G loss: 1.000021]\n",
            "3275 [D loss: 0.999970] [G loss: 1.000018]\n",
            "3276 [D loss: 0.999966] [G loss: 1.000026]\n",
            "3277 [D loss: 0.999959] [G loss: 1.000028]\n",
            "3278 [D loss: 0.999967] [G loss: 1.000019]\n",
            "3279 [D loss: 0.999970] [G loss: 1.000022]\n",
            "3280 [D loss: 0.999957] [G loss: 1.000026]\n",
            "3281 [D loss: 0.999966] [G loss: 1.000027]\n",
            "3282 [D loss: 0.999963] [G loss: 1.000031]\n",
            "3283 [D loss: 0.999958] [G loss: 1.000030]\n",
            "3284 [D loss: 0.999971] [G loss: 1.000037]\n",
            "3285 [D loss: 0.999967] [G loss: 1.000033]\n",
            "3286 [D loss: 0.999973] [G loss: 1.000023]\n",
            "3287 [D loss: 0.999970] [G loss: 1.000011]\n",
            "3288 [D loss: 0.999969] [G loss: 1.000020]\n",
            "3289 [D loss: 0.999968] [G loss: 1.000025]\n",
            "3290 [D loss: 0.999970] [G loss: 1.000029]\n",
            "3291 [D loss: 0.999967] [G loss: 1.000033]\n",
            "3292 [D loss: 0.999964] [G loss: 1.000037]\n",
            "3293 [D loss: 0.999967] [G loss: 1.000029]\n",
            "3294 [D loss: 0.999961] [G loss: 1.000034]\n",
            "3295 [D loss: 0.999964] [G loss: 1.000033]\n",
            "3296 [D loss: 0.999969] [G loss: 1.000039]\n",
            "3297 [D loss: 0.999968] [G loss: 1.000034]\n",
            "3298 [D loss: 0.999969] [G loss: 1.000035]\n",
            "3299 [D loss: 0.999970] [G loss: 1.000037]\n",
            "3300 [D loss: 0.999972] [G loss: 1.000037]\n",
            "3301 [D loss: 0.999964] [G loss: 1.000038]\n",
            "3302 [D loss: 0.999973] [G loss: 1.000043]\n",
            "3303 [D loss: 0.999967] [G loss: 1.000035]\n",
            "3304 [D loss: 0.999959] [G loss: 1.000043]\n",
            "3305 [D loss: 0.999964] [G loss: 1.000041]\n",
            "3306 [D loss: 0.999972] [G loss: 1.000039]\n",
            "3307 [D loss: 0.999970] [G loss: 1.000040]\n",
            "3308 [D loss: 0.999968] [G loss: 1.000039]\n",
            "3309 [D loss: 0.999971] [G loss: 1.000046]\n",
            "3310 [D loss: 0.999975] [G loss: 1.000036]\n",
            "3311 [D loss: 0.999968] [G loss: 1.000038]\n",
            "3312 [D loss: 0.999967] [G loss: 1.000034]\n",
            "3313 [D loss: 0.999969] [G loss: 1.000050]\n",
            "3314 [D loss: 0.999963] [G loss: 1.000044]\n",
            "3315 [D loss: 0.999968] [G loss: 1.000038]\n",
            "3316 [D loss: 0.999968] [G loss: 1.000032]\n",
            "3317 [D loss: 0.999967] [G loss: 1.000035]\n",
            "3318 [D loss: 0.999965] [G loss: 1.000036]\n",
            "3319 [D loss: 0.999966] [G loss: 1.000045]\n",
            "3320 [D loss: 0.999972] [G loss: 1.000038]\n",
            "3321 [D loss: 0.999967] [G loss: 1.000047]\n",
            "3322 [D loss: 0.999968] [G loss: 1.000047]\n",
            "3323 [D loss: 0.999968] [G loss: 1.000035]\n",
            "3324 [D loss: 0.999970] [G loss: 1.000049]\n",
            "3325 [D loss: 0.999968] [G loss: 1.000045]\n",
            "3326 [D loss: 0.999967] [G loss: 1.000047]\n",
            "3327 [D loss: 0.999965] [G loss: 1.000039]\n",
            "3328 [D loss: 0.999963] [G loss: 1.000047]\n",
            "3329 [D loss: 0.999963] [G loss: 1.000052]\n",
            "3330 [D loss: 0.999972] [G loss: 1.000047]\n",
            "3331 [D loss: 0.999970] [G loss: 1.000046]\n",
            "3332 [D loss: 0.999973] [G loss: 1.000033]\n",
            "3333 [D loss: 0.999972] [G loss: 1.000041]\n",
            "3334 [D loss: 0.999970] [G loss: 1.000045]\n",
            "3335 [D loss: 0.999968] [G loss: 1.000031]\n",
            "3336 [D loss: 0.999975] [G loss: 1.000047]\n",
            "3337 [D loss: 0.999966] [G loss: 1.000041]\n",
            "3338 [D loss: 0.999975] [G loss: 1.000053]\n",
            "3339 [D loss: 0.999970] [G loss: 1.000052]\n",
            "3340 [D loss: 0.999975] [G loss: 1.000052]\n",
            "3341 [D loss: 0.999967] [G loss: 1.000044]\n",
            "3342 [D loss: 0.999968] [G loss: 1.000039]\n",
            "3343 [D loss: 0.999962] [G loss: 1.000040]\n",
            "3344 [D loss: 0.999968] [G loss: 1.000046]\n",
            "3345 [D loss: 0.999968] [G loss: 1.000047]\n",
            "3346 [D loss: 0.999972] [G loss: 1.000052]\n",
            "3347 [D loss: 0.999973] [G loss: 1.000045]\n",
            "3348 [D loss: 0.999967] [G loss: 1.000053]\n",
            "3349 [D loss: 0.999969] [G loss: 1.000050]\n",
            "3350 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3351 [D loss: 0.999971] [G loss: 1.000052]\n",
            "3352 [D loss: 0.999970] [G loss: 1.000055]\n",
            "3353 [D loss: 0.999970] [G loss: 1.000054]\n",
            "3354 [D loss: 0.999969] [G loss: 1.000052]\n",
            "3355 [D loss: 0.999968] [G loss: 1.000052]\n",
            "3356 [D loss: 0.999964] [G loss: 1.000049]\n",
            "3357 [D loss: 0.999969] [G loss: 1.000053]\n",
            "3358 [D loss: 0.999969] [G loss: 1.000054]\n",
            "3359 [D loss: 0.999966] [G loss: 1.000055]\n",
            "3360 [D loss: 0.999971] [G loss: 1.000052]\n",
            "3361 [D loss: 0.999972] [G loss: 1.000046]\n",
            "3362 [D loss: 0.999972] [G loss: 1.000053]\n",
            "3363 [D loss: 0.999969] [G loss: 1.000054]\n",
            "3364 [D loss: 0.999976] [G loss: 1.000051]\n",
            "3365 [D loss: 0.999970] [G loss: 1.000047]\n",
            "3366 [D loss: 0.999968] [G loss: 1.000041]\n",
            "3367 [D loss: 0.999969] [G loss: 1.000050]\n",
            "3368 [D loss: 0.999968] [G loss: 1.000051]\n",
            "3369 [D loss: 0.999972] [G loss: 1.000043]\n",
            "3370 [D loss: 0.999972] [G loss: 1.000054]\n",
            "3371 [D loss: 0.999971] [G loss: 1.000055]\n",
            "3372 [D loss: 0.999967] [G loss: 1.000053]\n",
            "3373 [D loss: 0.999963] [G loss: 1.000059]\n",
            "3374 [D loss: 0.999965] [G loss: 1.000053]\n",
            "3375 [D loss: 0.999975] [G loss: 1.000058]\n",
            "3376 [D loss: 0.999963] [G loss: 1.000058]\n",
            "3377 [D loss: 0.999969] [G loss: 1.000061]\n",
            "3378 [D loss: 0.999974] [G loss: 1.000048]\n",
            "3379 [D loss: 0.999966] [G loss: 1.000058]\n",
            "3380 [D loss: 0.999962] [G loss: 1.000041]\n",
            "3381 [D loss: 0.999972] [G loss: 1.000047]\n",
            "3382 [D loss: 0.999977] [G loss: 1.000055]\n",
            "3383 [D loss: 0.999970] [G loss: 1.000059]\n",
            "3384 [D loss: 0.999972] [G loss: 1.000051]\n",
            "3385 [D loss: 0.999965] [G loss: 1.000054]\n",
            "3386 [D loss: 0.999968] [G loss: 1.000053]\n",
            "3387 [D loss: 0.999962] [G loss: 1.000058]\n",
            "3388 [D loss: 0.999964] [G loss: 1.000047]\n",
            "3389 [D loss: 0.999966] [G loss: 1.000057]\n",
            "3390 [D loss: 0.999971] [G loss: 1.000059]\n",
            "3391 [D loss: 0.999972] [G loss: 1.000054]\n",
            "3392 [D loss: 0.999972] [G loss: 1.000054]\n",
            "3393 [D loss: 0.999966] [G loss: 1.000060]\n",
            "3394 [D loss: 0.999972] [G loss: 1.000060]\n",
            "3395 [D loss: 0.999969] [G loss: 1.000060]\n",
            "3396 [D loss: 0.999973] [G loss: 1.000051]\n",
            "3397 [D loss: 0.999968] [G loss: 1.000056]\n",
            "3398 [D loss: 0.999968] [G loss: 1.000055]\n",
            "3399 [D loss: 0.999970] [G loss: 1.000056]\n",
            "3400 [D loss: 0.999968] [G loss: 1.000056]\n",
            "3401 [D loss: 0.999974] [G loss: 1.000043]\n",
            "3402 [D loss: 0.999971] [G loss: 1.000052]\n",
            "3403 [D loss: 0.999977] [G loss: 1.000051]\n",
            "3404 [D loss: 0.999969] [G loss: 1.000057]\n",
            "3405 [D loss: 0.999966] [G loss: 1.000059]\n",
            "3406 [D loss: 0.999965] [G loss: 1.000054]\n",
            "3407 [D loss: 0.999969] [G loss: 1.000045]\n",
            "3408 [D loss: 0.999971] [G loss: 1.000060]\n",
            "3409 [D loss: 0.999965] [G loss: 1.000059]\n",
            "3410 [D loss: 0.999973] [G loss: 1.000053]\n",
            "3411 [D loss: 0.999966] [G loss: 1.000058]\n",
            "3412 [D loss: 0.999971] [G loss: 1.000057]\n",
            "3413 [D loss: 0.999972] [G loss: 1.000044]\n",
            "3414 [D loss: 0.999978] [G loss: 1.000051]\n",
            "3415 [D loss: 0.999968] [G loss: 1.000053]\n",
            "3416 [D loss: 0.999971] [G loss: 1.000051]\n",
            "3417 [D loss: 0.999969] [G loss: 1.000051]\n",
            "3418 [D loss: 0.999962] [G loss: 1.000063]\n",
            "3419 [D loss: 0.999972] [G loss: 1.000057]\n",
            "3420 [D loss: 0.999966] [G loss: 1.000057]\n",
            "3421 [D loss: 0.999970] [G loss: 1.000056]\n",
            "3422 [D loss: 0.999967] [G loss: 1.000065]\n",
            "3423 [D loss: 0.999965] [G loss: 1.000060]\n",
            "3424 [D loss: 0.999969] [G loss: 1.000061]\n",
            "3425 [D loss: 0.999971] [G loss: 1.000062]\n",
            "3426 [D loss: 0.999970] [G loss: 1.000057]\n",
            "3427 [D loss: 0.999968] [G loss: 1.000060]\n",
            "3428 [D loss: 0.999970] [G loss: 1.000058]\n",
            "3429 [D loss: 0.999969] [G loss: 1.000056]\n",
            "3430 [D loss: 0.999974] [G loss: 1.000056]\n",
            "3431 [D loss: 0.999970] [G loss: 1.000055]\n",
            "3432 [D loss: 0.999969] [G loss: 1.000055]\n",
            "3433 [D loss: 0.999969] [G loss: 1.000057]\n",
            "3434 [D loss: 0.999967] [G loss: 1.000060]\n",
            "3435 [D loss: 0.999966] [G loss: 1.000059]\n",
            "3436 [D loss: 0.999969] [G loss: 1.000062]\n",
            "3437 [D loss: 0.999966] [G loss: 1.000056]\n",
            "3438 [D loss: 0.999971] [G loss: 1.000058]\n",
            "3439 [D loss: 0.999972] [G loss: 1.000051]\n",
            "3440 [D loss: 0.999968] [G loss: 1.000061]\n",
            "3441 [D loss: 0.999968] [G loss: 1.000053]\n",
            "3442 [D loss: 0.999965] [G loss: 1.000055]\n",
            "3443 [D loss: 0.999967] [G loss: 1.000058]\n",
            "3444 [D loss: 0.999973] [G loss: 1.000063]\n",
            "3445 [D loss: 0.999974] [G loss: 1.000063]\n",
            "3446 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3447 [D loss: 0.999972] [G loss: 1.000062]\n",
            "3448 [D loss: 0.999973] [G loss: 1.000057]\n",
            "3449 [D loss: 0.999971] [G loss: 1.000055]\n",
            "3450 [D loss: 0.999966] [G loss: 1.000047]\n",
            "3451 [D loss: 0.999972] [G loss: 1.000058]\n",
            "3452 [D loss: 0.999971] [G loss: 1.000062]\n",
            "3453 [D loss: 0.999975] [G loss: 1.000062]\n",
            "3454 [D loss: 0.999971] [G loss: 1.000056]\n",
            "3455 [D loss: 0.999967] [G loss: 1.000056]\n",
            "3456 [D loss: 0.999968] [G loss: 1.000054]\n",
            "3457 [D loss: 0.999973] [G loss: 1.000054]\n",
            "3458 [D loss: 0.999969] [G loss: 1.000048]\n",
            "3459 [D loss: 0.999974] [G loss: 1.000051]\n",
            "3460 [D loss: 0.999970] [G loss: 1.000057]\n",
            "3461 [D loss: 0.999972] [G loss: 1.000054]\n",
            "3462 [D loss: 0.999968] [G loss: 1.000055]\n",
            "3463 [D loss: 0.999974] [G loss: 1.000054]\n",
            "3464 [D loss: 0.999967] [G loss: 1.000048]\n",
            "3465 [D loss: 0.999976] [G loss: 1.000045]\n",
            "3466 [D loss: 0.999970] [G loss: 1.000058]\n",
            "3467 [D loss: 0.999970] [G loss: 1.000056]\n",
            "3468 [D loss: 0.999974] [G loss: 1.000045]\n",
            "3469 [D loss: 0.999968] [G loss: 1.000066]\n",
            "3470 [D loss: 0.999970] [G loss: 1.000049]\n",
            "3471 [D loss: 0.999976] [G loss: 1.000058]\n",
            "3472 [D loss: 0.999979] [G loss: 1.000048]\n",
            "3473 [D loss: 0.999968] [G loss: 1.000057]\n",
            "3474 [D loss: 0.999959] [G loss: 1.000062]\n",
            "3475 [D loss: 0.999970] [G loss: 1.000060]\n",
            "3476 [D loss: 0.999974] [G loss: 1.000047]\n",
            "3477 [D loss: 0.999966] [G loss: 1.000058]\n",
            "3478 [D loss: 0.999969] [G loss: 1.000056]\n",
            "3479 [D loss: 0.999970] [G loss: 1.000050]\n",
            "3480 [D loss: 0.999967] [G loss: 1.000059]\n",
            "3481 [D loss: 0.999969] [G loss: 1.000052]\n",
            "3482 [D loss: 0.999966] [G loss: 1.000057]\n",
            "3483 [D loss: 0.999974] [G loss: 1.000060]\n",
            "3484 [D loss: 0.999972] [G loss: 1.000063]\n",
            "3485 [D loss: 0.999969] [G loss: 1.000064]\n",
            "3486 [D loss: 0.999969] [G loss: 1.000050]\n",
            "3487 [D loss: 0.999970] [G loss: 1.000057]\n",
            "3488 [D loss: 0.999974] [G loss: 1.000056]\n",
            "3489 [D loss: 0.999975] [G loss: 1.000059]\n",
            "3490 [D loss: 0.999977] [G loss: 1.000054]\n",
            "3491 [D loss: 0.999967] [G loss: 1.000061]\n",
            "3492 [D loss: 0.999971] [G loss: 1.000057]\n",
            "3493 [D loss: 0.999969] [G loss: 1.000055]\n",
            "3494 [D loss: 0.999973] [G loss: 1.000051]\n",
            "3495 [D loss: 0.999966] [G loss: 1.000049]\n",
            "3496 [D loss: 0.999970] [G loss: 1.000057]\n",
            "3497 [D loss: 0.999961] [G loss: 1.000059]\n",
            "3498 [D loss: 0.999967] [G loss: 1.000053]\n",
            "3499 [D loss: 0.999970] [G loss: 1.000063]\n",
            "3500 [D loss: 0.999971] [G loss: 1.000054]\n",
            "3501 [D loss: 0.999970] [G loss: 1.000054]\n",
            "3502 [D loss: 0.999968] [G loss: 1.000059]\n",
            "3503 [D loss: 0.999969] [G loss: 1.000059]\n",
            "3504 [D loss: 0.999967] [G loss: 1.000062]\n",
            "3505 [D loss: 0.999968] [G loss: 1.000064]\n",
            "3506 [D loss: 0.999968] [G loss: 1.000059]\n",
            "3507 [D loss: 0.999969] [G loss: 1.000060]\n",
            "3508 [D loss: 0.999964] [G loss: 1.000061]\n",
            "3509 [D loss: 0.999968] [G loss: 1.000059]\n",
            "3510 [D loss: 0.999971] [G loss: 1.000050]\n",
            "3511 [D loss: 0.999979] [G loss: 1.000057]\n",
            "3512 [D loss: 0.999976] [G loss: 1.000052]\n",
            "3513 [D loss: 0.999965] [G loss: 1.000070]\n",
            "3514 [D loss: 0.999968] [G loss: 1.000058]\n",
            "3515 [D loss: 0.999969] [G loss: 1.000061]\n",
            "3516 [D loss: 0.999963] [G loss: 1.000054]\n",
            "3517 [D loss: 0.999974] [G loss: 1.000064]\n",
            "3518 [D loss: 0.999967] [G loss: 1.000062]\n",
            "3519 [D loss: 0.999969] [G loss: 1.000061]\n",
            "3520 [D loss: 0.999969] [G loss: 1.000061]\n",
            "3521 [D loss: 0.999968] [G loss: 1.000058]\n",
            "3522 [D loss: 0.999972] [G loss: 1.000055]\n",
            "3523 [D loss: 0.999966] [G loss: 1.000052]\n",
            "3524 [D loss: 0.999975] [G loss: 1.000063]\n",
            "3525 [D loss: 0.999962] [G loss: 1.000057]\n",
            "3526 [D loss: 0.999961] [G loss: 1.000057]\n",
            "3527 [D loss: 0.999970] [G loss: 1.000062]\n",
            "3528 [D loss: 0.999974] [G loss: 1.000056]\n",
            "3529 [D loss: 0.999969] [G loss: 1.000062]\n",
            "3530 [D loss: 0.999967] [G loss: 1.000057]\n",
            "3531 [D loss: 0.999971] [G loss: 1.000062]\n",
            "3532 [D loss: 0.999971] [G loss: 1.000069]\n",
            "3533 [D loss: 0.999976] [G loss: 1.000056]\n",
            "3534 [D loss: 0.999968] [G loss: 1.000062]\n",
            "3535 [D loss: 0.999967] [G loss: 1.000065]\n",
            "3536 [D loss: 0.999968] [G loss: 1.000058]\n",
            "3537 [D loss: 0.999962] [G loss: 1.000055]\n",
            "3538 [D loss: 0.999959] [G loss: 1.000059]\n",
            "3539 [D loss: 0.999973] [G loss: 1.000060]\n",
            "3540 [D loss: 0.999971] [G loss: 1.000054]\n",
            "3541 [D loss: 0.999969] [G loss: 1.000066]\n",
            "3542 [D loss: 0.999976] [G loss: 1.000061]\n",
            "3543 [D loss: 0.999970] [G loss: 1.000060]\n",
            "3544 [D loss: 0.999974] [G loss: 1.000055]\n",
            "3545 [D loss: 0.999963] [G loss: 1.000060]\n",
            "3546 [D loss: 0.999969] [G loss: 1.000059]\n",
            "3547 [D loss: 0.999967] [G loss: 1.000059]\n",
            "3548 [D loss: 0.999970] [G loss: 1.000057]\n",
            "3549 [D loss: 0.999969] [G loss: 1.000054]\n",
            "3550 [D loss: 0.999973] [G loss: 1.000061]\n",
            "3551 [D loss: 0.999968] [G loss: 1.000059]\n",
            "3552 [D loss: 0.999970] [G loss: 1.000052]\n",
            "3553 [D loss: 0.999972] [G loss: 1.000062]\n",
            "3554 [D loss: 0.999970] [G loss: 1.000060]\n",
            "3555 [D loss: 0.999967] [G loss: 1.000056]\n",
            "3556 [D loss: 0.999966] [G loss: 1.000058]\n",
            "3557 [D loss: 0.999973] [G loss: 1.000062]\n",
            "3558 [D loss: 0.999968] [G loss: 1.000058]\n",
            "3559 [D loss: 0.999969] [G loss: 1.000059]\n",
            "3560 [D loss: 0.999969] [G loss: 1.000062]\n",
            "3561 [D loss: 0.999966] [G loss: 1.000058]\n",
            "3562 [D loss: 0.999962] [G loss: 1.000060]\n",
            "3563 [D loss: 0.999970] [G loss: 1.000064]\n",
            "3564 [D loss: 0.999973] [G loss: 1.000062]\n",
            "3565 [D loss: 0.999972] [G loss: 1.000060]\n",
            "3566 [D loss: 0.999970] [G loss: 1.000053]\n",
            "3567 [D loss: 0.999970] [G loss: 1.000047]\n",
            "3568 [D loss: 0.999968] [G loss: 1.000058]\n",
            "3569 [D loss: 0.999966] [G loss: 1.000058]\n",
            "3570 [D loss: 0.999971] [G loss: 1.000062]\n",
            "3571 [D loss: 0.999967] [G loss: 1.000053]\n",
            "3572 [D loss: 0.999971] [G loss: 1.000064]\n",
            "3573 [D loss: 0.999971] [G loss: 1.000061]\n",
            "3574 [D loss: 0.999972] [G loss: 1.000052]\n",
            "3575 [D loss: 0.999974] [G loss: 1.000065]\n",
            "3576 [D loss: 0.999968] [G loss: 1.000064]\n",
            "3577 [D loss: 0.999967] [G loss: 1.000059]\n",
            "3578 [D loss: 0.999967] [G loss: 1.000063]\n",
            "3579 [D loss: 0.999965] [G loss: 1.000059]\n",
            "3580 [D loss: 0.999969] [G loss: 1.000059]\n",
            "3581 [D loss: 0.999970] [G loss: 1.000061]\n",
            "3582 [D loss: 0.999967] [G loss: 1.000059]\n",
            "3583 [D loss: 0.999970] [G loss: 1.000068]\n",
            "3584 [D loss: 0.999973] [G loss: 1.000060]\n",
            "3585 [D loss: 0.999970] [G loss: 1.000059]\n",
            "3586 [D loss: 0.999969] [G loss: 1.000061]\n",
            "3587 [D loss: 0.999971] [G loss: 1.000063]\n",
            "3588 [D loss: 0.999970] [G loss: 1.000064]\n",
            "3589 [D loss: 0.999972] [G loss: 1.000058]\n",
            "3590 [D loss: 0.999972] [G loss: 1.000054]\n",
            "3591 [D loss: 0.999973] [G loss: 1.000058]\n",
            "3592 [D loss: 0.999968] [G loss: 1.000061]\n",
            "3593 [D loss: 0.999967] [G loss: 1.000058]\n",
            "3594 [D loss: 0.999975] [G loss: 1.000067]\n",
            "3595 [D loss: 0.999970] [G loss: 1.000052]\n",
            "3596 [D loss: 0.999970] [G loss: 1.000055]\n",
            "3597 [D loss: 0.999967] [G loss: 1.000061]\n",
            "3598 [D loss: 0.999968] [G loss: 1.000053]\n",
            "3599 [D loss: 0.999972] [G loss: 1.000048]\n",
            "3600 [D loss: 0.999964] [G loss: 1.000057]\n",
            "3601 [D loss: 0.999972] [G loss: 1.000058]\n",
            "3602 [D loss: 0.999970] [G loss: 1.000059]\n",
            "3603 [D loss: 0.999969] [G loss: 1.000056]\n",
            "3604 [D loss: 0.999969] [G loss: 1.000057]\n",
            "3605 [D loss: 0.999967] [G loss: 1.000048]\n",
            "3606 [D loss: 0.999971] [G loss: 1.000055]\n",
            "3607 [D loss: 0.999966] [G loss: 1.000052]\n",
            "3608 [D loss: 0.999970] [G loss: 1.000056]\n",
            "3609 [D loss: 0.999967] [G loss: 1.000057]\n",
            "3610 [D loss: 0.999968] [G loss: 1.000058]\n",
            "3611 [D loss: 0.999965] [G loss: 1.000052]\n",
            "3612 [D loss: 0.999965] [G loss: 1.000051]\n",
            "3613 [D loss: 0.999972] [G loss: 1.000069]\n",
            "3614 [D loss: 0.999973] [G loss: 1.000066]\n",
            "3615 [D loss: 0.999972] [G loss: 1.000052]\n",
            "3616 [D loss: 0.999972] [G loss: 1.000063]\n",
            "3617 [D loss: 0.999971] [G loss: 1.000050]\n",
            "3618 [D loss: 0.999977] [G loss: 1.000058]\n",
            "3619 [D loss: 0.999978] [G loss: 1.000060]\n",
            "3620 [D loss: 0.999973] [G loss: 1.000057]\n",
            "3621 [D loss: 0.999967] [G loss: 1.000057]\n",
            "3622 [D loss: 0.999968] [G loss: 1.000054]\n",
            "3623 [D loss: 0.999968] [G loss: 1.000062]\n",
            "3624 [D loss: 0.999974] [G loss: 1.000055]\n",
            "3625 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3626 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3627 [D loss: 0.999972] [G loss: 1.000057]\n",
            "3628 [D loss: 0.999969] [G loss: 1.000052]\n",
            "3629 [D loss: 0.999972] [G loss: 1.000056]\n",
            "3630 [D loss: 0.999970] [G loss: 1.000052]\n",
            "3631 [D loss: 0.999975] [G loss: 1.000062]\n",
            "3632 [D loss: 0.999966] [G loss: 1.000057]\n",
            "3633 [D loss: 0.999970] [G loss: 1.000051]\n",
            "3634 [D loss: 0.999971] [G loss: 1.000053]\n",
            "3635 [D loss: 0.999970] [G loss: 1.000047]\n",
            "3636 [D loss: 0.999972] [G loss: 1.000055]\n",
            "3637 [D loss: 0.999968] [G loss: 1.000049]\n",
            "3638 [D loss: 0.999965] [G loss: 1.000060]\n",
            "3639 [D loss: 0.999972] [G loss: 1.000045]\n",
            "3640 [D loss: 0.999972] [G loss: 1.000049]\n",
            "3641 [D loss: 0.999966] [G loss: 1.000047]\n",
            "3642 [D loss: 0.999967] [G loss: 1.000047]\n",
            "3643 [D loss: 0.999971] [G loss: 1.000053]\n",
            "3644 [D loss: 0.999976] [G loss: 1.000052]\n",
            "3645 [D loss: 0.999974] [G loss: 1.000048]\n",
            "3646 [D loss: 0.999969] [G loss: 1.000056]\n",
            "3647 [D loss: 0.999973] [G loss: 1.000053]\n",
            "3648 [D loss: 0.999970] [G loss: 1.000053]\n",
            "3649 [D loss: 0.999963] [G loss: 1.000073]\n",
            "3650 [D loss: 0.999972] [G loss: 1.000068]\n",
            "3651 [D loss: 0.999967] [G loss: 1.000063]\n",
            "3652 [D loss: 0.999967] [G loss: 1.000060]\n",
            "3653 [D loss: 0.999970] [G loss: 1.000056]\n",
            "3654 [D loss: 0.999965] [G loss: 1.000046]\n",
            "3655 [D loss: 0.999968] [G loss: 1.000056]\n",
            "3656 [D loss: 0.999968] [G loss: 1.000057]\n",
            "3657 [D loss: 0.999971] [G loss: 1.000047]\n",
            "3658 [D loss: 0.999977] [G loss: 1.000069]\n",
            "3659 [D loss: 0.999972] [G loss: 1.000057]\n",
            "3660 [D loss: 0.999968] [G loss: 1.000061]\n",
            "3661 [D loss: 0.999973] [G loss: 1.000052]\n",
            "3662 [D loss: 0.999973] [G loss: 1.000054]\n",
            "3663 [D loss: 0.999965] [G loss: 1.000067]\n",
            "3664 [D loss: 0.999969] [G loss: 1.000057]\n",
            "3665 [D loss: 0.999967] [G loss: 1.000055]\n",
            "3666 [D loss: 0.999975] [G loss: 1.000057]\n",
            "3667 [D loss: 0.999968] [G loss: 1.000059]\n",
            "3668 [D loss: 0.999975] [G loss: 1.000056]\n",
            "3669 [D loss: 0.999962] [G loss: 1.000058]\n",
            "3670 [D loss: 0.999974] [G loss: 1.000044]\n",
            "3671 [D loss: 0.999969] [G loss: 1.000059]\n",
            "3672 [D loss: 0.999966] [G loss: 1.000048]\n",
            "3673 [D loss: 0.999969] [G loss: 1.000055]\n",
            "3674 [D loss: 0.999969] [G loss: 1.000065]\n",
            "3675 [D loss: 0.999975] [G loss: 1.000065]\n",
            "3676 [D loss: 0.999971] [G loss: 1.000061]\n",
            "3677 [D loss: 0.999969] [G loss: 1.000062]\n",
            "3678 [D loss: 0.999967] [G loss: 1.000056]\n",
            "3679 [D loss: 0.999970] [G loss: 1.000049]\n",
            "3680 [D loss: 0.999967] [G loss: 1.000052]\n",
            "3681 [D loss: 0.999966] [G loss: 1.000057]\n",
            "3682 [D loss: 0.999972] [G loss: 1.000060]\n",
            "3683 [D loss: 0.999972] [G loss: 1.000062]\n",
            "3684 [D loss: 0.999972] [G loss: 1.000059]\n",
            "3685 [D loss: 0.999968] [G loss: 1.000060]\n",
            "3686 [D loss: 0.999970] [G loss: 1.000056]\n",
            "3687 [D loss: 0.999967] [G loss: 1.000061]\n",
            "3688 [D loss: 0.999972] [G loss: 1.000057]\n",
            "3689 [D loss: 0.999972] [G loss: 1.000054]\n",
            "3690 [D loss: 0.999966] [G loss: 1.000054]\n",
            "3691 [D loss: 0.999970] [G loss: 1.000054]\n",
            "3692 [D loss: 0.999969] [G loss: 1.000063]\n",
            "3693 [D loss: 0.999971] [G loss: 1.000055]\n",
            "3694 [D loss: 0.999966] [G loss: 1.000058]\n",
            "3695 [D loss: 0.999966] [G loss: 1.000055]\n",
            "3696 [D loss: 0.999965] [G loss: 1.000059]\n",
            "3697 [D loss: 0.999963] [G loss: 1.000053]\n",
            "3698 [D loss: 0.999973] [G loss: 1.000055]\n",
            "3699 [D loss: 0.999969] [G loss: 1.000067]\n",
            "3700 [D loss: 0.999968] [G loss: 1.000062]\n",
            "3701 [D loss: 0.999972] [G loss: 1.000056]\n",
            "3702 [D loss: 0.999967] [G loss: 1.000059]\n",
            "3703 [D loss: 0.999970] [G loss: 1.000060]\n",
            "3704 [D loss: 0.999963] [G loss: 1.000059]\n",
            "3705 [D loss: 0.999971] [G loss: 1.000063]\n",
            "3706 [D loss: 0.999970] [G loss: 1.000059]\n",
            "3707 [D loss: 0.999961] [G loss: 1.000064]\n",
            "3708 [D loss: 0.999971] [G loss: 1.000055]\n",
            "3709 [D loss: 0.999970] [G loss: 1.000059]\n",
            "3710 [D loss: 0.999971] [G loss: 1.000055]\n",
            "3711 [D loss: 0.999973] [G loss: 1.000058]\n",
            "3712 [D loss: 0.999970] [G loss: 1.000059]\n",
            "3713 [D loss: 0.999974] [G loss: 1.000054]\n",
            "3714 [D loss: 0.999965] [G loss: 1.000064]\n",
            "3715 [D loss: 0.999970] [G loss: 1.000061]\n",
            "3716 [D loss: 0.999971] [G loss: 1.000063]\n",
            "3717 [D loss: 0.999976] [G loss: 1.000061]\n",
            "3718 [D loss: 0.999970] [G loss: 1.000061]\n",
            "3719 [D loss: 0.999968] [G loss: 1.000062]\n",
            "3720 [D loss: 0.999967] [G loss: 1.000064]\n",
            "3721 [D loss: 0.999970] [G loss: 1.000064]\n",
            "3722 [D loss: 0.999967] [G loss: 1.000061]\n",
            "3723 [D loss: 0.999968] [G loss: 1.000057]\n",
            "3724 [D loss: 0.999971] [G loss: 1.000059]\n",
            "3725 [D loss: 0.999973] [G loss: 1.000060]\n",
            "3726 [D loss: 0.999968] [G loss: 1.000064]\n",
            "3727 [D loss: 0.999969] [G loss: 1.000060]\n",
            "3728 [D loss: 0.999968] [G loss: 1.000057]\n",
            "3729 [D loss: 0.999974] [G loss: 1.000062]\n",
            "3730 [D loss: 0.999972] [G loss: 1.000062]\n",
            "3731 [D loss: 0.999978] [G loss: 1.000052]\n",
            "3732 [D loss: 0.999967] [G loss: 1.000062]\n",
            "3733 [D loss: 0.999970] [G loss: 1.000062]\n",
            "3734 [D loss: 0.999969] [G loss: 1.000065]\n",
            "3735 [D loss: 0.999972] [G loss: 1.000059]\n",
            "3736 [D loss: 0.999972] [G loss: 1.000050]\n",
            "3737 [D loss: 0.999970] [G loss: 1.000060]\n",
            "3738 [D loss: 0.999963] [G loss: 1.000069]\n",
            "3739 [D loss: 0.999971] [G loss: 1.000058]\n",
            "3740 [D loss: 0.999967] [G loss: 1.000065]\n",
            "3741 [D loss: 0.999976] [G loss: 1.000064]\n",
            "3742 [D loss: 0.999974] [G loss: 1.000065]\n",
            "3743 [D loss: 0.999969] [G loss: 1.000062]\n",
            "3744 [D loss: 0.999968] [G loss: 1.000052]\n",
            "3745 [D loss: 0.999973] [G loss: 1.000054]\n",
            "3746 [D loss: 0.999976] [G loss: 1.000057]\n",
            "3747 [D loss: 0.999972] [G loss: 1.000055]\n",
            "3748 [D loss: 0.999968] [G loss: 1.000061]\n",
            "3749 [D loss: 0.999970] [G loss: 1.000062]\n",
            "3750 [D loss: 0.999965] [G loss: 1.000060]\n",
            "3751 [D loss: 0.999974] [G loss: 1.000062]\n",
            "3752 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3753 [D loss: 0.999971] [G loss: 1.000064]\n",
            "3754 [D loss: 0.999973] [G loss: 1.000063]\n",
            "3755 [D loss: 0.999973] [G loss: 1.000061]\n",
            "3756 [D loss: 0.999968] [G loss: 1.000062]\n",
            "3757 [D loss: 0.999970] [G loss: 1.000055]\n",
            "3758 [D loss: 0.999970] [G loss: 1.000063]\n",
            "3759 [D loss: 0.999967] [G loss: 1.000057]\n",
            "3760 [D loss: 0.999971] [G loss: 1.000060]\n",
            "3761 [D loss: 0.999968] [G loss: 1.000065]\n",
            "3762 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3763 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3764 [D loss: 0.999973] [G loss: 1.000064]\n",
            "3765 [D loss: 0.999970] [G loss: 1.000059]\n",
            "3766 [D loss: 0.999971] [G loss: 1.000053]\n",
            "3767 [D loss: 0.999971] [G loss: 1.000058]\n",
            "3768 [D loss: 0.999972] [G loss: 1.000056]\n",
            "3769 [D loss: 0.999970] [G loss: 1.000058]\n",
            "3770 [D loss: 0.999971] [G loss: 1.000060]\n",
            "3771 [D loss: 0.999973] [G loss: 1.000054]\n",
            "3772 [D loss: 0.999969] [G loss: 1.000056]\n",
            "3773 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3774 [D loss: 0.999971] [G loss: 1.000056]\n",
            "3775 [D loss: 0.999972] [G loss: 1.000056]\n",
            "3776 [D loss: 0.999964] [G loss: 1.000063]\n",
            "3777 [D loss: 0.999963] [G loss: 1.000058]\n",
            "3778 [D loss: 0.999972] [G loss: 1.000064]\n",
            "3779 [D loss: 0.999969] [G loss: 1.000058]\n",
            "3780 [D loss: 0.999967] [G loss: 1.000059]\n",
            "3781 [D loss: 0.999971] [G loss: 1.000050]\n",
            "3782 [D loss: 0.999971] [G loss: 1.000058]\n",
            "3783 [D loss: 0.999969] [G loss: 1.000061]\n",
            "3784 [D loss: 0.999973] [G loss: 1.000061]\n",
            "3785 [D loss: 0.999970] [G loss: 1.000055]\n",
            "3786 [D loss: 0.999969] [G loss: 1.000056]\n",
            "3787 [D loss: 0.999972] [G loss: 1.000061]\n",
            "3788 [D loss: 0.999966] [G loss: 1.000057]\n",
            "3789 [D loss: 0.999966] [G loss: 1.000062]\n",
            "3790 [D loss: 0.999972] [G loss: 1.000060]\n",
            "3791 [D loss: 0.999975] [G loss: 1.000059]\n",
            "3792 [D loss: 0.999976] [G loss: 1.000053]\n",
            "3793 [D loss: 0.999966] [G loss: 1.000048]\n",
            "3794 [D loss: 0.999966] [G loss: 1.000035]\n",
            "3795 [D loss: 0.999972] [G loss: 1.000046]\n",
            "3796 [D loss: 0.999968] [G loss: 1.000063]\n",
            "3797 [D loss: 0.999970] [G loss: 1.000053]\n",
            "3798 [D loss: 0.999975] [G loss: 1.000050]\n",
            "3799 [D loss: 0.999974] [G loss: 1.000050]\n",
            "3800 [D loss: 0.999972] [G loss: 1.000058]\n",
            "3801 [D loss: 0.999969] [G loss: 1.000066]\n",
            "3802 [D loss: 0.999974] [G loss: 1.000057]\n",
            "3803 [D loss: 0.999973] [G loss: 1.000065]\n",
            "3804 [D loss: 0.999973] [G loss: 1.000050]\n",
            "3805 [D loss: 0.999968] [G loss: 1.000052]\n",
            "3806 [D loss: 0.999967] [G loss: 1.000058]\n",
            "3807 [D loss: 0.999973] [G loss: 1.000059]\n",
            "3808 [D loss: 0.999968] [G loss: 1.000055]\n",
            "3809 [D loss: 0.999971] [G loss: 1.000057]\n",
            "3810 [D loss: 0.999963] [G loss: 1.000054]\n",
            "3811 [D loss: 0.999973] [G loss: 1.000059]\n",
            "3812 [D loss: 0.999968] [G loss: 1.000064]\n",
            "3813 [D loss: 0.999970] [G loss: 1.000056]\n",
            "3814 [D loss: 0.999967] [G loss: 1.000058]\n",
            "3815 [D loss: 0.999972] [G loss: 1.000059]\n",
            "3816 [D loss: 0.999975] [G loss: 1.000051]\n",
            "3817 [D loss: 0.999972] [G loss: 1.000049]\n",
            "3818 [D loss: 0.999972] [G loss: 1.000050]\n",
            "3819 [D loss: 0.999966] [G loss: 1.000052]\n",
            "3820 [D loss: 0.999963] [G loss: 1.000052]\n",
            "3821 [D loss: 0.999972] [G loss: 1.000058]\n",
            "3822 [D loss: 0.999969] [G loss: 1.000062]\n",
            "3823 [D loss: 0.999960] [G loss: 1.000056]\n",
            "3824 [D loss: 0.999965] [G loss: 1.000057]\n",
            "3825 [D loss: 0.999970] [G loss: 1.000064]\n",
            "3826 [D loss: 0.999971] [G loss: 1.000055]\n",
            "3827 [D loss: 0.999974] [G loss: 1.000056]\n",
            "3828 [D loss: 0.999972] [G loss: 1.000043]\n",
            "3829 [D loss: 0.999970] [G loss: 1.000055]\n",
            "3830 [D loss: 0.999968] [G loss: 1.000065]\n",
            "3831 [D loss: 0.999964] [G loss: 1.000061]\n",
            "3832 [D loss: 0.999966] [G loss: 1.000061]\n",
            "3833 [D loss: 0.999973] [G loss: 1.000059]\n",
            "3834 [D loss: 0.999967] [G loss: 1.000052]\n",
            "3835 [D loss: 0.999970] [G loss: 1.000048]\n",
            "3836 [D loss: 0.999971] [G loss: 1.000056]\n",
            "3837 [D loss: 0.999985] [G loss: 1.000053]\n",
            "3838 [D loss: 0.999969] [G loss: 1.000065]\n",
            "3839 [D loss: 0.999976] [G loss: 1.000053]\n",
            "3840 [D loss: 0.999966] [G loss: 1.000057]\n",
            "3841 [D loss: 0.999977] [G loss: 1.000052]\n",
            "3842 [D loss: 0.999966] [G loss: 1.000055]\n",
            "3843 [D loss: 0.999972] [G loss: 1.000048]\n",
            "3844 [D loss: 0.999971] [G loss: 1.000057]\n",
            "3845 [D loss: 0.999978] [G loss: 1.000051]\n",
            "3846 [D loss: 0.999970] [G loss: 1.000071]\n",
            "3847 [D loss: 0.999973] [G loss: 1.000057]\n",
            "3848 [D loss: 0.999974] [G loss: 1.000047]\n",
            "3849 [D loss: 0.999973] [G loss: 1.000054]\n",
            "3850 [D loss: 0.999971] [G loss: 1.000055]\n",
            "3851 [D loss: 0.999975] [G loss: 1.000048]\n",
            "3852 [D loss: 0.999970] [G loss: 1.000051]\n",
            "3853 [D loss: 0.999973] [G loss: 1.000059]\n",
            "3854 [D loss: 0.999970] [G loss: 1.000057]\n",
            "3855 [D loss: 0.999974] [G loss: 1.000056]\n",
            "3856 [D loss: 0.999970] [G loss: 1.000047]\n",
            "3857 [D loss: 0.999972] [G loss: 1.000059]\n",
            "3858 [D loss: 0.999968] [G loss: 1.000062]\n",
            "3859 [D loss: 0.999972] [G loss: 1.000057]\n",
            "3860 [D loss: 0.999969] [G loss: 1.000048]\n",
            "3861 [D loss: 0.999972] [G loss: 1.000050]\n",
            "3862 [D loss: 0.999968] [G loss: 1.000054]\n",
            "3863 [D loss: 0.999962] [G loss: 1.000060]\n",
            "3864 [D loss: 0.999977] [G loss: 1.000045]\n",
            "3865 [D loss: 0.999965] [G loss: 1.000055]\n",
            "3866 [D loss: 0.999973] [G loss: 1.000052]\n",
            "3867 [D loss: 0.999976] [G loss: 1.000053]\n",
            "3868 [D loss: 0.999968] [G loss: 1.000051]\n",
            "3869 [D loss: 0.999969] [G loss: 1.000056]\n",
            "3870 [D loss: 0.999972] [G loss: 1.000061]\n",
            "3871 [D loss: 0.999968] [G loss: 1.000065]\n",
            "3872 [D loss: 0.999979] [G loss: 1.000055]\n",
            "3873 [D loss: 0.999977] [G loss: 1.000044]\n",
            "3874 [D loss: 0.999972] [G loss: 1.000064]\n",
            "3875 [D loss: 0.999962] [G loss: 1.000059]\n",
            "3876 [D loss: 0.999970] [G loss: 1.000063]\n",
            "3877 [D loss: 0.999974] [G loss: 1.000057]\n",
            "3878 [D loss: 0.999965] [G loss: 1.000048]\n",
            "3879 [D loss: 0.999979] [G loss: 1.000052]\n",
            "3880 [D loss: 0.999970] [G loss: 1.000043]\n",
            "3881 [D loss: 0.999973] [G loss: 1.000043]\n",
            "3882 [D loss: 0.999969] [G loss: 1.000044]\n",
            "3883 [D loss: 0.999966] [G loss: 1.000063]\n",
            "3884 [D loss: 0.999965] [G loss: 1.000051]\n",
            "3885 [D loss: 0.999977] [G loss: 1.000061]\n",
            "3886 [D loss: 0.999974] [G loss: 1.000061]\n",
            "3887 [D loss: 0.999973] [G loss: 1.000044]\n",
            "3888 [D loss: 0.999973] [G loss: 1.000065]\n",
            "3889 [D loss: 0.999971] [G loss: 1.000051]\n",
            "3890 [D loss: 0.999966] [G loss: 1.000058]\n",
            "3891 [D loss: 0.999964] [G loss: 1.000054]\n",
            "3892 [D loss: 0.999967] [G loss: 1.000050]\n",
            "3893 [D loss: 0.999970] [G loss: 1.000048]\n",
            "3894 [D loss: 0.999975] [G loss: 1.000043]\n",
            "3895 [D loss: 0.999967] [G loss: 1.000050]\n",
            "3896 [D loss: 0.999968] [G loss: 1.000063]\n",
            "3897 [D loss: 0.999979] [G loss: 1.000036]\n",
            "3898 [D loss: 0.999975] [G loss: 1.000047]\n",
            "3899 [D loss: 0.999975] [G loss: 1.000056]\n",
            "3900 [D loss: 0.999968] [G loss: 1.000044]\n",
            "3901 [D loss: 0.999971] [G loss: 1.000048]\n",
            "3902 [D loss: 0.999974] [G loss: 1.000059]\n",
            "3903 [D loss: 0.999969] [G loss: 1.000038]\n",
            "3904 [D loss: 0.999979] [G loss: 1.000055]\n",
            "3905 [D loss: 0.999968] [G loss: 1.000056]\n",
            "3906 [D loss: 0.999973] [G loss: 1.000058]\n",
            "3907 [D loss: 0.999972] [G loss: 1.000050]\n",
            "3908 [D loss: 0.999968] [G loss: 1.000054]\n",
            "3909 [D loss: 0.999968] [G loss: 1.000055]\n",
            "3910 [D loss: 0.999973] [G loss: 1.000051]\n",
            "3911 [D loss: 0.999974] [G loss: 1.000060]\n",
            "3912 [D loss: 0.999975] [G loss: 1.000061]\n",
            "3913 [D loss: 0.999967] [G loss: 1.000065]\n",
            "3914 [D loss: 0.999979] [G loss: 1.000058]\n",
            "3915 [D loss: 0.999971] [G loss: 1.000048]\n",
            "3916 [D loss: 0.999963] [G loss: 1.000049]\n",
            "3917 [D loss: 0.999969] [G loss: 1.000051]\n",
            "3918 [D loss: 0.999970] [G loss: 1.000047]\n",
            "3919 [D loss: 0.999975] [G loss: 1.000051]\n",
            "3920 [D loss: 0.999964] [G loss: 1.000046]\n",
            "3921 [D loss: 0.999969] [G loss: 1.000063]\n",
            "3922 [D loss: 0.999971] [G loss: 1.000053]\n",
            "3923 [D loss: 0.999971] [G loss: 1.000050]\n",
            "3924 [D loss: 0.999972] [G loss: 1.000060]\n",
            "3925 [D loss: 0.999965] [G loss: 1.000057]\n",
            "3926 [D loss: 0.999973] [G loss: 1.000056]\n",
            "3927 [D loss: 0.999968] [G loss: 1.000052]\n",
            "3928 [D loss: 0.999974] [G loss: 1.000054]\n",
            "3929 [D loss: 0.999966] [G loss: 1.000057]\n",
            "3930 [D loss: 0.999971] [G loss: 1.000061]\n",
            "3931 [D loss: 0.999972] [G loss: 1.000065]\n",
            "3932 [D loss: 0.999976] [G loss: 1.000037]\n",
            "3933 [D loss: 0.999970] [G loss: 1.000057]\n",
            "3934 [D loss: 0.999967] [G loss: 1.000060]\n",
            "3935 [D loss: 0.999973] [G loss: 1.000051]\n",
            "3936 [D loss: 0.999972] [G loss: 1.000063]\n",
            "3937 [D loss: 0.999969] [G loss: 1.000055]\n",
            "3938 [D loss: 0.999974] [G loss: 1.000051]\n",
            "3939 [D loss: 0.999959] [G loss: 1.000055]\n",
            "3940 [D loss: 0.999965] [G loss: 1.000061]\n",
            "3941 [D loss: 0.999969] [G loss: 1.000046]\n",
            "3942 [D loss: 0.999968] [G loss: 1.000051]\n",
            "3943 [D loss: 0.999965] [G loss: 1.000051]\n",
            "3944 [D loss: 0.999968] [G loss: 1.000050]\n",
            "3945 [D loss: 0.999972] [G loss: 1.000046]\n",
            "3946 [D loss: 0.999973] [G loss: 1.000046]\n",
            "3947 [D loss: 0.999969] [G loss: 1.000054]\n",
            "3948 [D loss: 0.999965] [G loss: 1.000058]\n",
            "3949 [D loss: 0.999969] [G loss: 1.000062]\n",
            "3950 [D loss: 0.999979] [G loss: 1.000055]\n",
            "3951 [D loss: 0.999961] [G loss: 1.000054]\n",
            "3952 [D loss: 0.999970] [G loss: 1.000059]\n",
            "3953 [D loss: 0.999964] [G loss: 1.000066]\n",
            "3954 [D loss: 0.999970] [G loss: 1.000054]\n",
            "3955 [D loss: 0.999975] [G loss: 1.000046]\n",
            "3956 [D loss: 0.999970] [G loss: 1.000056]\n",
            "3957 [D loss: 0.999969] [G loss: 1.000052]\n",
            "3958 [D loss: 0.999972] [G loss: 1.000058]\n",
            "3959 [D loss: 0.999979] [G loss: 1.000046]\n",
            "3960 [D loss: 0.999971] [G loss: 1.000057]\n",
            "3961 [D loss: 0.999971] [G loss: 1.000054]\n",
            "3962 [D loss: 0.999959] [G loss: 1.000055]\n",
            "3963 [D loss: 0.999964] [G loss: 1.000062]\n",
            "3964 [D loss: 0.999964] [G loss: 1.000056]\n",
            "3965 [D loss: 0.999977] [G loss: 1.000050]\n",
            "3966 [D loss: 0.999973] [G loss: 1.000052]\n",
            "3967 [D loss: 0.999978] [G loss: 1.000058]\n",
            "3968 [D loss: 0.999971] [G loss: 1.000059]\n",
            "3969 [D loss: 0.999976] [G loss: 1.000048]\n",
            "3970 [D loss: 0.999974] [G loss: 1.000042]\n",
            "3971 [D loss: 0.999966] [G loss: 1.000048]\n",
            "3972 [D loss: 0.999971] [G loss: 1.000052]\n",
            "3973 [D loss: 0.999963] [G loss: 1.000050]\n",
            "3974 [D loss: 0.999972] [G loss: 1.000060]\n",
            "3975 [D loss: 0.999966] [G loss: 1.000056]\n",
            "3976 [D loss: 0.999977] [G loss: 1.000048]\n",
            "3977 [D loss: 0.999969] [G loss: 1.000046]\n",
            "3978 [D loss: 0.999978] [G loss: 1.000043]\n",
            "3979 [D loss: 0.999969] [G loss: 1.000033]\n",
            "3980 [D loss: 0.999961] [G loss: 1.000036]\n",
            "3981 [D loss: 0.999981] [G loss: 1.000040]\n",
            "3982 [D loss: 0.999970] [G loss: 1.000050]\n",
            "3983 [D loss: 0.999973] [G loss: 1.000038]\n",
            "3984 [D loss: 0.999975] [G loss: 1.000054]\n",
            "3985 [D loss: 0.999963] [G loss: 1.000053]\n",
            "3986 [D loss: 0.999967] [G loss: 1.000051]\n",
            "3987 [D loss: 0.999979] [G loss: 1.000057]\n",
            "3988 [D loss: 0.999980] [G loss: 1.000045]\n",
            "3989 [D loss: 0.999968] [G loss: 1.000055]\n",
            "3990 [D loss: 0.999970] [G loss: 1.000042]\n",
            "3991 [D loss: 0.999965] [G loss: 1.000057]\n",
            "3992 [D loss: 0.999966] [G loss: 1.000051]\n",
            "3993 [D loss: 0.999963] [G loss: 1.000062]\n",
            "3994 [D loss: 0.999974] [G loss: 1.000050]\n",
            "3995 [D loss: 0.999973] [G loss: 1.000041]\n",
            "3996 [D loss: 0.999972] [G loss: 1.000050]\n",
            "3997 [D loss: 0.999973] [G loss: 1.000060]\n",
            "3998 [D loss: 0.999969] [G loss: 1.000061]\n",
            "3999 [D loss: 0.999970] [G loss: 1.000056]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il_TrRdC1_nW"
      },
      "source": [
        "r, c = 5, 5\n",
        "noise = np.random.normal(0, 1, (r * c,100))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "231LY4MwPxYb",
        "outputId": "0023a596-887f-49ee-fb1d-35ae4c003dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "gen_imgs = wgan.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "fig, axs = plt.subplots(r, c)\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "        for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "fig.savefig(\"/content/drive/My Drive/image_%d.png\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUwDpE-9P9VE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}